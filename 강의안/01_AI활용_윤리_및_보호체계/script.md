# [1차시] AI 활용 윤리 및 보호체계 - 강사 스크립트

## 강의 정보
- **차시**: 1차시 (25분)
- **유형**: 이론
- **대상**: AI 기초체력훈련 수강생 (비전공자/입문자)

---

## 도입 (3분)

### 인사 및 과정 소개 [1분]

> 안녕하세요, AI 기초체력훈련 과정에 오신 것을 환영합니다.
>
> 저는 이 과정을 진행할 (강사명)입니다.
>
> 앞으로 25차시에 걸쳐 여러분과 함께 AI 어플리케이션 개발자로의 첫걸음을 함께 걷게 되어 기쁩니다.

### 동기유발 - 뉴스 사례 [1분]

> 시작하기 전에 최근 뉴스 하나를 소개해드릴게요.
>
> 삼성전자에서 ChatGPT를 업무에 활용하다가 반도체 설계 관련 기밀 정보가 외부로 유출되는 사고가 발생했습니다. 이 사건 이후 삼성을 포함한 많은 기업들이 생성형 AI 사용을 제한했죠.
>
> 이처럼 AI 기술은 강력하지만, 잘못 사용하면 큰 문제가 될 수 있습니다.
>
> 그래서 오늘 첫 시간에는 AI를 안전하고 윤리적으로 활용하는 방법에 대해 알아보겠습니다.

### 학습목표 안내 [1분]

> 오늘 수업을 마치면 여러분은 다음 세 가지를 할 수 있게 됩니다.
>
> 첫째, AI 윤리의 기본 원칙과 그 중요성을 설명할 수 있습니다.
> 둘째, 데이터 보안 사고의 유형과 예방 방법을 이해할 수 있습니다.
> 셋째, AI 결과물의 저작권 이슈를 파악할 수 있습니다.
>
> 이 세 가지는 AI 개발자로서 반드시 알아야 할 기본 소양입니다.

---

## 전개 (19분)

### 섹션 1: AI 윤리 4대 원칙 (7분)

#### 왜 AI 윤리가 중요한가? [2분]

> AI 기술은 양면성을 가지고 있습니다.
>
> 긍정적인 면을 보면, 생산성 향상, 품질 개선, 반복 업무 자동화 같은 장점이 있죠.
>
> 하지만 부정적인 면도 있습니다. 일자리 대체 우려, 편향된 판단, 책임 소재 불명확, 프라이버시 침해 등의 문제가 발생할 수 있습니다.
>
> **[질문]** 여러분은 AI 때문에 발생한 문제를 뉴스에서 본 적 있으신가요? 어떤 사례가 있었나요?
>
> *(잠시 수강생 반응 대기)*
>
> 네, 그런 문제들을 예방하기 위해 AI 윤리가 필요한 것입니다.

#### 4대 원칙 설명 [5분]

> AI 윤리에는 크게 4가지 핵심 원칙이 있습니다.
>
> **첫 번째, 공정성입니다.**
> AI 시스템은 모든 사용자를 공평하게 대우해야 합니다. 성별, 인종, 나이에 따른 차별이 있으면 안 됩니다.
>
> 제조 현장 예시를 들어볼까요? 만약 품질 검사 AI가 특정 생산 라인의 제품만 더 엄격하게 판정한다면, 그건 불공정한 거죠. 그 라인의 작업자는 억울하겠죠?
>
> **두 번째, 투명성입니다.**
> AI의 의사결정 과정이 설명 가능해야 합니다. 흔히 "블랙박스"라고 하죠, AI가 왜 그런 결정을 내렸는지 알 수 없는 상태를 말합니다.
>
> 예를 들어, 불량 판정 AI가 "이 제품은 불량입니다"라고만 하면 작업자는 뭘 고쳐야 할지 모르겠죠? "이 부분의 스크래치 때문에 불량입니다"라고 설명할 수 있어야 합니다.
>
> **세 번째, 책임성입니다.**
> AI 시스템의 결과에 대한 책임 주체가 명확해야 합니다.
>
> 여러분, 자율주행 트럭이 사고를 냈다면 누구 책임일까요? 차량 제조사? AI 개발사? 운전자? 화물 운송사? 이게 아직 명확하지 않아서 많은 논쟁이 있습니다.
>
> **네 번째, 프라이버시입니다.**
> 개인정보와 기업 비밀을 보호해야 합니다.
>
> 예를 들어, 작업자 동작 분석 AI가 개인의 행동 패턴을 수집해서 동의 없이 인사 평가에 활용한다면? 그건 심각한 프라이버시 침해입니다.

---

### 섹션 2: 데이터 보안 (6분)

#### 기업 데이터 유출 사례 [2분]

> 이제 데이터 보안에 대해 알아보겠습니다.
>
> 먼저 실제 사례를 살펴볼까요?
>
> 2023년 삼성전자에서 반도체 설계 데이터가 유출되었습니다. ChatGPT에 코드 검토를 맡기면서 기밀 정보가 외부 서버로 전송된 거죠.
>
> 2022년에는 LG에너지솔루션에서 배터리 기술 유출 시도가 있었고, 2021년에는 현대자동차 협력사를 통해 설계 도면이 유출됐습니다.
>
> 공통 원인이 뭘까요? 내부자에 의한 유출, 협력사 보안 취약점, 그리고 AI/클라우드 도구 오용입니다.

#### 보안 유형별 설명 [4분]

> 데이터 보안은 크게 세 가지로 나눌 수 있습니다.
>
> **첫째, 개인정보 보호입니다.**
>
> 개인정보보호법에 따르면, 수집 시 명확한 동의가 필요하고, 목적 외 사용은 금지됩니다. 보유 기간이 지나면 즉시 파기해야 하고, 위반 시 과태료가 최대 5천만원입니다.
>
> AI 개발할 때 주의하셔야 할 점은, 주민등록번호나 연락처 같은 개인정보를 직접 다루지 말고, 반드시 비식별화 처리를 해야 합니다.
>
> **둘째, 기업 비밀 보호입니다.**
>
> 생산 공정 데이터, 품질 검사 기준, 설비 운영 파라미터, 고객사 정보 등은 모두 기업 비밀입니다.
>
> 특히 중요한 점! 외부 AI 서비스, 예를 들어 ChatGPT, Claude, Gemini 같은 서비스에 기업 데이터를 입력하면 유출 위험이 있습니다. 반드시 사내에서 승인받은 도구만 사용하세요.
>
> **셋째, 접근 권한 관리입니다.**
>
> "최소 권한 원칙"이라고 합니다. 업무에 필요한 최소한의 데이터만 접근할 수 있게 해야 합니다.
>
> 예를 들어, 현장 작업자는 본인 담당 라인 데이터만, 품질 관리자는 전체 품질 데이터를, 데이터 분석가는 비식별화된 분석 데이터만 볼 수 있게 권한을 설정하는 거죠.

---

### 섹션 3: AI와 저작권 (6분)

#### AI 생성물 저작권 [3분]

> 이제 많은 분들이 궁금해하시는 AI와 저작권에 대해 알아보겠습니다.
>
> **[질문]** 여러분, AI가 그린 그림이나 AI가 쓴 코드의 저작권은 누구 것일까요?
>
> *(잠시 수강생 반응 대기)*
>
> 사실 이건 아직 명확하게 정해지지 않았습니다.
>
> 한국은 현재 관련 법률이 없고 논의 중입니다. 미국은 AI가 단독으로 만든 창작물은 저작권을 인정하지 않습니다. EU는 AI 생성물에 표시 의무를 부과하는 방향으로 가고 있고요.
>
> 그래서 AI 생성물을 업무에 사용할 때는 주의가 필요합니다. 특히 저작권 분쟁이 발생할 수 있는 이미지나 디자인 같은 것들이요.

#### 학습 데이터 저작권 [3분]

> 또 다른 이슈는 AI 학습 데이터의 저작권입니다.
>
> 이미지 생성 AI들이 인터넷의 이미지로 학습했는데, 원작자 동의 없이 학습 데이터로 사용한 거죠. 그래서 Getty Images 같은 회사가 Stability AI를 상대로 소송을 제기했습니다.
>
> 제조 현장에서 주의할 점을 정리해드릴게요.
>
> 첫째, GitHub Copilot 같은 코드 생성 AI를 사용할 때 오픈소스 라이선스를 확인하세요. GPL 코드가 포함되면 전체 코드를 공개해야 할 수도 있습니다.
>
> 둘째, AI로 기술 문서를 작성할 때는 출처를 표시하고 내용을 검증해야 합니다.
>
> 셋째, AI 도움으로 개발한 기술의 특허를 출원할 때 발명자를 누구로 적을지 법무팀과 상의하세요.

---

## 정리 (3분)

### 핵심 내용 요약 [1.5분]

> 오늘 배운 내용을 정리하겠습니다.
>
> **첫째, AI 윤리 4대 원칙**을 배웠습니다.
> 공정성, 투명성, 책임성, 프라이버시. 이 네 가지를 항상 기억해주세요.
>
> **둘째, 데이터 보안**에 대해 알아봤습니다.
> 개인정보 보호, 기업 비밀 보호, 접근 권한 관리가 중요합니다. 특히 외부 AI 서비스 사용 시 주의하세요.
>
> **셋째, AI와 저작권** 이슈를 살펴봤습니다.
> AI 생성물의 저작권은 아직 불명확합니다. 코드 생성 AI, 문서 작성 AI 사용 시 라이선스를 확인하세요.

### 다음 차시 예고 [1분]

> 다음 2차시에서는 본격적으로 Python 환경을 구축하고 기초 문법을 배우겠습니다.
>
> Anaconda 설치, Jupyter Notebook 사용법, 그리고 변수, 조건문, 반복문 같은 기본 문법을 다룰 예정입니다.
>
> 다음 시간까지 개인 노트북을 준비해주시고, Windows 10 이상을 권장드립니다. 인터넷 연결이 원활한 환경이면 좋겠습니다.

### 마무리 인사 [0.5분]

> 오늘 AI 윤리와 보안에 대해 함께 알아봤습니다.
>
> AI 개발자로서 기술만큼이나 윤리 의식도 중요합니다. 오늘 배운 내용을 실무에서 꼭 기억해주세요.
>
> 질문이 있으시면 언제든 말씀해주세요.
>
> 수고하셨습니다. 다음 시간에 뵙겠습니다!

---

## 강의 노트

### 준비물
- PPT 슬라이드 (slides.md → PDF/PPTX 변환)
- 뉴스 사례 자료 (삼성 ChatGPT 유출 사건 등)

### 주의사항
- 법률 관련 내용은 2025년 기준이므로, 최신 법령 변경 여부 확인 필요
- 수강생 소속 기업의 보안 정책과 상충되지 않도록 일반적인 내용 위주로 설명

### 예상 질문
1. "우리 회사에서 ChatGPT 사용해도 되나요?"
   → 소속 기업의 보안 정책 확인 권유, 일반적으로 기밀 정보 입력은 금지

2. "AI가 만든 코드도 내가 저작권을 가지나요?"
   → 현재 법적으로 불명확, 회사 법무팀 확인 권유

3. "개인정보 비식별화는 어떻게 하나요?"
   → 2차시 이후 실습에서 다룰 예정, 해싱/마스킹 기법 간단 소개
