"""
[25ì°¨ì‹œ] ëª¨ë¸ ì €ì¥ê³¼ ì‹¤ë¬´ ë°°í¬ ì¤€ë¹„ - ì‹¤ìŠµ ì½”ë“œ
í•™ìŠµëª©í‘œ: joblibìœ¼ë¡œ ëª¨ë¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°, ë²„ì „ ê´€ë¦¬, ë°°í¬ ì¤€ë¹„
"""

import numpy as np
import pandas as pd
from datetime import datetime

# ============================================================
# 1. ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ í•™ìŠµ
# ============================================================
print("=" * 50)
print("[25ì°¨ì‹œ] ëª¨ë¸ ì €ì¥ê³¼ ì‹¤ë¬´ ë°°í¬ ì¤€ë¹„")
print("=" * 50)

print("\nâ–¶ 1. ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ í•™ìŠµ")
print("-" * 50)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ì œì¡° ë°ì´í„° ìƒì„±
np.random.seed(42)
n_samples = 500

data = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n_samples),
    'humidity': np.random.normal(50, 8, n_samples),
    'speed': np.random.normal(100, 10, n_samples),
    'pressure': np.random.normal(1.0, 0.1, n_samples)
})

defect_prob = (
    0.1 +
    0.3 * ((data['temperature'] - 85) / 10) +
    0.2 * ((data['humidity'] - 50) / 16)
)
data['defect'] = (defect_prob > 0.3).astype(int)

feature_names = ['temperature', 'humidity', 'speed', 'pressure']
X = data[feature_names]
y = data['defect']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ì „ì²˜ë¦¬
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ëª¨ë¸ í•™ìŠµ
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

accuracy = accuracy_score(y_test, model.predict(X_test_scaled))
print(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.3f}")

# ============================================================
# 2. joblibìœ¼ë¡œ ëª¨ë¸ ì €ì¥
# ============================================================
print("\n" + "=" * 50)
print("2. joblibìœ¼ë¡œ ëª¨ë¸ ì €ì¥")
print("=" * 50)

import joblib

print("""
â–¶ joblibì´ë€?
   - scikit-learn ê³µì‹ ê¶Œì¥ ì €ì¥ ë°©ë²•
   - NumPy ë°°ì—´ì— ìµœì í™”
   - pickleë³´ë‹¤ ëŒ€ìš©ëŸ‰ ëª¨ë¸ì— íš¨ìœ¨ì 
""")

# ëª¨ë¸ ì €ì¥
joblib.dump(model, 'model.pkl')
print("â–¶ ëª¨ë¸ ì €ì¥: model.pkl")

# ì „ì²˜ë¦¬ê¸° ì €ì¥
joblib.dump(scaler, 'scaler.pkl')
print("â–¶ ì „ì²˜ë¦¬ê¸° ì €ì¥: scaler.pkl")

# íŒŒì¼ í¬ê¸° í™•ì¸
import os
model_size = os.path.getsize('model.pkl') / 1024  # KB
scaler_size = os.path.getsize('scaler.pkl') / 1024  # KB
print(f"\nâ–¶ íŒŒì¼ í¬ê¸°:")
print(f"   model.pkl: {model_size:.1f} KB")
print(f"   scaler.pkl: {scaler_size:.1f} KB")

# ============================================================
# 3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜ˆì¸¡
# ============================================================
print("\n" + "=" * 50)
print("3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜ˆì¸¡")
print("=" * 50)

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
loaded_model = joblib.load('model.pkl')
loaded_scaler = joblib.load('scaler.pkl')

print("â–¶ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# ìƒˆ ë°ì´í„°ë¡œ ì˜ˆì¸¡
new_data = np.array([
    [90, 55, 100, 1.0],   # ë†’ì€ ì˜¨ë„, ìŠµë„
    [82, 48, 100, 1.0],   # ì •ìƒ ë²”ìœ„
    [95, 65, 100, 1.0],   # ë§¤ìš° ë†’ìŒ
])

new_data_scaled = loaded_scaler.transform(new_data)
predictions = loaded_model.predict(new_data_scaled)

print("\nâ–¶ ì˜ˆì¸¡ ê²°ê³¼:")
for i, (data, pred) in enumerate(zip(new_data, predictions)):
    result = "ë¶ˆëŸ‰" if pred == 1 else "ì •ìƒ"
    print(f"   ë°ì´í„° {i+1}: ì˜¨ë„={data[0]}, ìŠµë„={data[1]} â†’ {result}")

# ============================================================
# 4. íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í•œë²ˆì— ì €ì¥
# ============================================================
print("\n" + "=" * 50)
print("4. íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í•œë²ˆì— ì €ì¥")
print("=" * 50)

from sklearn.pipeline import Pipeline

# íŒŒì´í”„ë¼ì¸ ìƒì„±
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier(n_estimators=100, random_state=42))
])

# íŒŒì´í”„ë¼ì¸ í•™ìŠµ (ì›ë³¸ ë°ì´í„° ì‚¬ìš©)
pipeline.fit(X_train, y_train)

# íŒŒì´í”„ë¼ì¸ ì €ì¥
joblib.dump(pipeline, 'pipeline.pkl')
print("â–¶ íŒŒì´í”„ë¼ì¸ ì €ì¥: pipeline.pkl")

# íŒŒì´í”„ë¼ì¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜ˆì¸¡
loaded_pipeline = joblib.load('pipeline.pkl')
pipeline_predictions = loaded_pipeline.predict(new_data)

print("\nâ–¶ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ ê²°ê³¼:")
for i, (data, pred) in enumerate(zip(new_data, pipeline_predictions)):
    result = "ë¶ˆëŸ‰" if pred == 1 else "ì •ìƒ"
    print(f"   ë°ì´í„° {i+1}: {result}")

print("""
âœ… íŒŒì´í”„ë¼ì¸ì˜ ì¥ì :
   - ì „ì²˜ë¦¬ + ëª¨ë¸ì„ í•˜ë‚˜ë¡œ ê´€ë¦¬
   - íŒŒì¼ 1ê°œë§Œ ì €ì¥/ë¡œë“œ
   - ì‹¤ìˆ˜ ë°©ì§€ (ìŠ¤ì¼€ì¼ëŸ¬ ëˆ„ë½ ë“±)
""")

# ============================================================
# 5. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
# ============================================================
print("\n" + "=" * 50)
print("5. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥")
print("=" * 50)

# ëª¨ë¸ íŒ¨í‚¤ì§€ ìƒì„±
model_package = {
    'model': model,
    'scaler': scaler,
    'feature_names': feature_names,
    'version': '1.0.0',
    'trained_date': datetime.now().isoformat(),
    'accuracy': accuracy,
    'n_samples': len(X_train),
    'description': 'ì œì¡° í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸'
}

# ì €ì¥
joblib.dump(model_package, 'model_package.pkl')
print("â–¶ ëª¨ë¸ íŒ¨í‚¤ì§€ ì €ì¥: model_package.pkl")

# ë¶ˆëŸ¬ì™€ì„œ ì •ë³´ í™•ì¸
loaded_package = joblib.load('model_package.pkl')
print("\nâ–¶ ëª¨ë¸ ì •ë³´:")
print(f"   ë²„ì „: {loaded_package['version']}")
print(f"   í•™ìŠµ ì¼ì‹œ: {loaded_package['trained_date']}")
print(f"   ì •í™•ë„: {loaded_package['accuracy']:.3f}")
print(f"   í•™ìŠµ ë°ì´í„° ìˆ˜: {loaded_package['n_samples']}")
print(f"   ì„¤ëª…: {loaded_package['description']}")
print(f"   íŠ¹ì„±: {loaded_package['feature_names']}")

# íŒ¨í‚¤ì§€ì—ì„œ ëª¨ë¸ ì¶”ì¶œí•´ì„œ ì˜ˆì¸¡
pkg_model = loaded_package['model']
pkg_scaler = loaded_package['scaler']
pkg_predictions = pkg_model.predict(pkg_scaler.transform(new_data))
print(f"\nâ–¶ íŒ¨í‚¤ì§€ ëª¨ë¸ ì˜ˆì¸¡: {pkg_predictions}")

# ============================================================
# 6. pickle vs joblib ë¹„êµ
# ============================================================
print("\n" + "=" * 50)
print("6. pickle vs joblib ë¹„êµ")
print("=" * 50)

import pickle
import time

# pickle ì €ì¥
start = time.time()
with open('model_pickle.pkl', 'wb') as f:
    pickle.dump(model, f)
pickle_save_time = time.time() - start

# joblib ì €ì¥
start = time.time()
joblib.dump(model, 'model_joblib.pkl')
joblib_save_time = time.time() - start

print(f"""
â–¶ ì €ì¥ ì‹œê°„ ë¹„êµ:
   pickle: {pickle_save_time:.4f}ì´ˆ
   joblib: {joblib_save_time:.4f}ì´ˆ

â–¶ ê¶Œì¥ì‚¬í•­:
   - ML ëª¨ë¸: joblib ì‚¬ìš©
   - ì¼ë°˜ Python ê°ì²´: pickle ì‚¬ìš©
   - ëŒ€ìš©ëŸ‰ NumPy ë°°ì—´: joblib ì••ë„ì  ìš°ìœ„
""")

# ============================================================
# 7. ë²„ì „ ê´€ë¦¬ íŒ¨í„´
# ============================================================
print("\n" + "=" * 50)
print("7. ë²„ì „ ê´€ë¦¬ íŒ¨í„´")
print("=" * 50)

print("""
â–¶ íŒŒì¼ëª… ê·œì¹™ ì˜ˆì‹œ:
   quality_model_v1.0_20260101.pkl
   quality_model_v1.1_20260115.pkl
   quality_model_v2.0_20260201.pkl

â–¶ í´ë” êµ¬ì¡°:
   models/
   â”œâ”€â”€ production/
   â”‚   â””â”€â”€ current_model.pkl       # í˜„ì¬ ì‚¬ìš© ì¤‘
   â”œâ”€â”€ staging/
   â”‚   â””â”€â”€ candidate_model.pkl     # í…ŒìŠ¤íŠ¸ ì¤‘
   â””â”€â”€ archive/
       â”œâ”€â”€ model_v1.0.pkl          # ì´ì „ ë²„ì „
       â””â”€â”€ model_v1.1.pkl
""")

# ë²„ì „ì´ í¬í•¨ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
version = "1.0"
date_str = datetime.now().strftime("%Y%m%d")
versioned_filename = f"quality_model_v{version}_{date_str}.pkl"
joblib.dump(model, versioned_filename)
print(f"â–¶ ë²„ì „ í¬í•¨ ì €ì¥: {versioned_filename}")

# ============================================================
# 8. ì‹¤ë¬´ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
# ============================================================
print("\n" + "=" * 50)
print("8. ì‹¤ë¬´ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸")
print("=" * 50)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â–¶ ëª¨ë¸ ê²€ì¦                                        â”‚
â”‚     â–¡ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥ í™•ì¸ (ì •í™•ë„, F1 ë“±)       â”‚
â”‚     â–¡ ë‹¤ì–‘í•œ ì…ë ¥ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸                     â”‚
â”‚     â–¡ ì—ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (NULL, ì´ìƒì¹˜ ë“±)            â”‚
â”‚                                                      â”‚
â”‚  â–¶ íŒŒì¼ í™•ì¸                                        â”‚
â”‚     â–¡ ëª¨ë¸ íŒŒì¼ ì¡´ì¬ (model.pkl)                    â”‚
â”‚     â–¡ ì „ì²˜ë¦¬ê¸° íŒŒì¼ ì¡´ì¬ (scaler.pkl)               â”‚
â”‚     â–¡ ë©”íƒ€ë°ì´í„° ê¸°ë¡ (ë²„ì „, ë‚ ì§œ, ì„±ëŠ¥)            â”‚
â”‚                                                      â”‚
â”‚  â–¶ í™˜ê²½ í™•ì¸                                        â”‚
â”‚     â–¡ Python ë²„ì „ ì¼ì¹˜                              â”‚
â”‚     â–¡ scikit-learn ë²„ì „ ì¼ì¹˜                        â”‚
â”‚     â–¡ requirements.txt ì‘ì„±                         â”‚
â”‚                                                      â”‚
â”‚  â–¶ ì½”ë“œ í™•ì¸                                        â”‚
â”‚     â–¡ ëª¨ë¸ ë¡œë“œ ì½”ë“œ í…ŒìŠ¤íŠ¸                         â”‚
â”‚     â–¡ ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„                           â”‚
â”‚     â–¡ ë¡œê¹… ì„¤ì •                                     â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# 9. requirements.txt ìƒì„±
# ============================================================
print("\n" + "=" * 50)
print("9. requirements.txt ì˜ˆì‹œ")
print("=" * 50)

requirements_content = """# AI ê¸°ì´ˆì²´ë ¥í›ˆë ¨ - ëª¨ë¸ ë°°í¬ìš© íŒ¨í‚¤ì§€
scikit-learn==1.3.0
numpy==1.24.0
pandas==2.0.0
joblib==1.3.0
fastapi==0.100.0
uvicorn==0.23.0
pydantic==2.0.0
"""

print("â–¶ requirements.txt ë‚´ìš©:")
print(requirements_content)

# íŒŒì¼ë¡œ ì €ì¥
with open('requirements_example.txt', 'w') as f:
    f.write(requirements_content)
print("â–¶ íŒŒì¼ ì €ì¥: requirements_example.txt")

print("""
â–¶ ëª…ë ¹ì–´:
   pip freeze > requirements.txt   # í˜„ì¬ í™˜ê²½ ì €ì¥
   pip install -r requirements.txt # í™˜ê²½ ë³µì›
""")

# ============================================================
# 10. API ì„œë²„ ì½”ë“œ ì˜ˆì‹œ
# ============================================================
print("\n" + "=" * 50)
print("10. FastAPI ì„œë²„ ì½”ë“œ ì˜ˆì‹œ")
print("=" * 50)

api_code = '''
# main.py
from fastapi import FastAPI
import joblib
import numpy as np

app = FastAPI(title="í’ˆì§ˆ ì˜ˆì¸¡ API", version="1.0")

# ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ
model_package = joblib.load("model_package.pkl")
model = model_package["model"]
scaler = model_package["scaler"]

@app.get("/health")
def health():
    return {"status": "healthy", "version": model_package["version"]}

@app.post("/predict")
def predict(temperature: float, humidity: float, speed: float, pressure: float):
    features = np.array([[temperature, humidity, speed, pressure]])
    scaled = scaler.transform(features)
    prediction = model.predict(scaled)[0]
    return {
        "prediction": int(prediction),
        "label": "ë¶ˆëŸ‰" if prediction == 1 else "ì •ìƒ"
    }

# ì‹¤í–‰: uvicorn main:app --reload
'''

print(api_code)

# ============================================================
# 11. ì •ë¦¬ ë° íŒŒì¼ ì •ë¦¬
# ============================================================
print("\n" + "=" * 50)
print("11. ìƒì„±ëœ íŒŒì¼ ì •ë¦¬")
print("=" * 50)

created_files = [
    'model.pkl',
    'scaler.pkl',
    'pipeline.pkl',
    'model_package.pkl',
    'model_pickle.pkl',
    'model_joblib.pkl',
    versioned_filename,
    'requirements_example.txt'
]

print("â–¶ ì´ë²ˆ ì‹¤ìŠµì—ì„œ ìƒì„±ëœ íŒŒì¼:")
for f in created_files:
    if os.path.exists(f):
        size = os.path.getsize(f) / 1024
        print(f"   {f}: {size:.1f} KB")

# ============================================================
# 12. í•µì‹¬ ìš”ì•½
# ============================================================
print("\n" + "=" * 50)
print("12. í•µì‹¬ ìš”ì•½")
print("=" * 50)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ëª¨ë¸ ì €ì¥ê³¼ ë°°í¬ í•µì‹¬ ì •ë¦¬                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  â–¶ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°                                       â”‚
â”‚     joblib.dump(model, 'model.pkl')                   â”‚
â”‚     model = joblib.load('model.pkl')                  â”‚
â”‚                                                        â”‚
â”‚  â–¶ ì „ì²˜ë¦¬ê¸°ë„ í•¨ê»˜ ì €ì¥                               â”‚
â”‚     joblib.dump(scaler, 'scaler.pkl')                 â”‚
â”‚     ë˜ëŠ” Pipeline ì‚¬ìš©                                 â”‚
â”‚                                                        â”‚
â”‚  â–¶ ë©”íƒ€ë°ì´í„° ê´€ë¦¬                                    â”‚
â”‚     model_info = {'model': model, 'version': '1.0'}   â”‚
â”‚     joblib.dump(model_info, 'package.pkl')            â”‚
â”‚                                                        â”‚
â”‚  â–¶ ë²„ì „ ê´€ë¦¬                                          â”‚
â”‚     íŒŒì¼ëª…ì— ë²„ì „, ë‚ ì§œ í¬í•¨                           â”‚
â”‚     requirements.txtë¡œ í™˜ê²½ ê³ ì •                       â”‚
â”‚                                                        â”‚
â”‚  â–¶ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸                                    â”‚
â”‚     ì„±ëŠ¥ ê²€ì¦, íŒŒì¼ í™•ì¸, í™˜ê²½ ì¼ì¹˜ í™•ì¸              â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ‰ 25ì°¨ì‹œ AI ê¸°ì´ˆì²´ë ¥í›ˆë ¨ì„ ëª¨ë‘ ë§ˆì³¤ìŠµë‹ˆë‹¤!

   ë°ì´í„° ë¶„ì„ â†’ ëª¨ë¸ í•™ìŠµ â†’ í‰ê°€ â†’ í•´ì„ â†’ ë°°í¬
   ì „ì²´ ML ì›Œí¬í”Œë¡œìš°ë¥¼ ê²½í—˜í–ˆìŠµë‹ˆë‹¤.

   ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!
""")
