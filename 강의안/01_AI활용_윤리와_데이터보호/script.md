# [1차시] AI 활용 윤리와 데이터 보호 - 강사 스크립트

## 강의 정보
- **차시**: 1차시 (25-30분)
- **유형**: 이론 + 실습
- **구성**: 이론 10분 + 실습 15-20분
- **대상**: 비전공자, AI 입문자, 제조업 종사자

---

## 이론편 (10분)

### 도입 (2분)

#### 인사 및 과정 소개 [1분]

> 안녕하세요, '제조데이터를 활용한 AI 이해와 예측 모델 구축' 과정에 오신 것을 환영합니다.
>
> 앞으로 26차시에 걸쳐 제조 현장에서 AI를 활용하는 방법을 함께 배워보겠습니다.
>
> 우리 과정의 목표는 단순히 AI 도구를 사용하는 수준을 넘어, 실제로 AI 예측 모델을 만들고 서비스화할 수 있는 역량을 기르는 것입니다.

#### 학습목표 안내 [1분]

> 오늘 첫 시간에는 AI를 안전하고 올바르게 사용하는 방법을 배웁니다.
>
> 수업을 마치면 여러분은:
> - 첫째, AI 윤리의 기본 원칙을 설명할 수 있습니다.
> - 둘째, 데이터 보안 사고 유형과 예방법을 이해할 수 있습니다.
> - 셋째, AI 저작권 문제를 파악할 수 있습니다.
>
> 기술만큼이나 중요한 윤리와 보안, 지금부터 시작합니다.

---

### 핵심 내용 (8분)

#### AI 윤리 4대 원칙 [4분]

> 먼저 AI 윤리의 4가지 핵심 원칙을 알아보겠습니다.
>
> **첫 번째, 공정성입니다.**
> AI는 모든 사용자를 공평하게 대우해야 합니다.
> 예를 들어, 품질 검사 AI가 A라인 제품만 더 엄격하게 판정한다면 어떨까요? 그 라인 작업자는 억울하겠죠. 이건 학습 데이터의 편향 때문일 수 있습니다.
>
> **두 번째, 투명성입니다.**
> AI가 왜 그런 결정을 내렸는지 설명할 수 있어야 합니다.
> 불량 판정 AI가 "이 제품은 불량입니다"라고만 하면 작업자는 뭘 고쳐야 할지 모릅니다. "스크래치가 0.5mm 이상이라 불량입니다"라고 설명해줘야 합니다.
>
> **세 번째, 책임성입니다.**
> AI 시스템의 결과에 대한 책임 주체가 명확해야 합니다.
> AI가 잘못 판단해서 불량품이 출하되었다면 누구 책임일까요? 개발사? 도입 기업? 담당자? 이걸 미리 정해두어야 합니다.
>
> **네 번째, 안전성입니다.**
> 개인정보와 기업 비밀을 보호해야 합니다.
> 작업자 동작 분석 AI가 개인 행동 패턴을 수집해서 동의 없이 인사 평가에 사용한다면? 심각한 프라이버시 침해입니다.

#### 데이터 보안과 저작권 [4분]

> 다음은 데이터 보안입니다.
>
> 실제 사례를 보면, 2023년 S전자에서 ChatGPT에 반도체 코드를 입력했다가 외부 유출 사고가 발생했습니다. 공통 원인은 외부 AI 서비스 무분별 사용입니다.
>
> 데이터 보안은 세 가지로 나눕니다.
> - **개인정보 보호**: 작업자 정보는 비식별화 필수
> - **기업 비밀 보호**: 공정 데이터, 파라미터는 암호화
> - **접근 권한 관리**: 최소 권한 원칙 적용
>
> 특히 중요한 점! ChatGPT, Claude 같은 외부 AI 서비스에 기업 데이터를 입력하면 외부 서버로 전송됩니다. 반드시 사내 승인 도구만 사용하세요.
>
> 마지막으로 AI 저작권입니다.
> AI가 만든 결과물의 저작권은 아직 법적으로 불명확합니다. 코드 생성 AI를 사용할 때는 오픈소스 라이선스를 확인하세요.

---

## 실습편 (15-20분)

### 실습 소개 [2분]

> 이제 실습 시간입니다. 오늘은 AI 프로젝트 시작 전 윤리 체크리스트를 작성해보겠습니다.
>
> **실습 시나리오**를 보겠습니다.
> 여러분이 스마트공장에 품질 예측 AI를 도입하려고 합니다. 센서 데이터(온도, 압력, 진동, 습도)로 불량 발생을 사전에 예측하는 시스템입니다.
>
> 이 프로젝트를 시작하기 전에 윤리와 보안 점검을 해볼 겁니다.

### 실습 1: 윤리 체크리스트 점검 [5분]

> 첫 번째 실습입니다. 윤리 체크리스트를 점검해봅시다.
>
> 슬라이드에 있는 체크리스트를 보세요.
>
> **공정성 점검**
> - 학습 데이터에 특정 라인이나 시간대 편향이 없는가?
> - 모든 생산 조건에서 공평하게 예측하는가?
>
> 우리 품질 예측 AI가 A라인 데이터만 많이 학습하면 어떻게 될까요? B라인 예측이 부정확해질 겁니다.
>
> **투명성 점검**
> - 예측 결과의 근거를 설명할 수 있는가?
> - 작업자가 결과를 이해할 수 있는가?
>
> 단순히 "불량 예상"이라고만 하면 작업자는 어디를 점검해야 할지 모릅니다.
>
> **책임성 점검**
> - AI 오류 시 책임자가 지정되어 있는가?
> - 수동 점검 프로세스가 있는가?
>
> AI가 "정상"이라고 했는데 불량이 나왔다면, 누가 책임질까요?

### 실습 2: 데이터 보안 위험 평가 [4분]

> 두 번째 실습입니다. 데이터별 보안 등급을 분류해봅시다.
>
> 표를 같이 보겠습니다.
>
> | 데이터 유형 | 보안 등급 | 처리 방안 |
> |------------|----------|----------|
> | 센서 측정값 | 중 | 익명화 후 분석 |
> | 설비 파라미터 | 상 | 암호화 저장 |
> | 작업자 정보 | 상 | 비식별화 필수 |
> | 고객사 정보 | 최고 | 분리 저장 |
>
> 센서값은 상대적으로 민감도가 낮지만, 설비 파라미터나 고객사 정보는 유출되면 큰 문제가 됩니다.
>
> 여러분 프로젝트에서는 어떤 데이터가 가장 민감할까요? 미리 분류해두면 사고를 예방할 수 있습니다.

### 실습 3: 외부 AI 서비스 사용 가이드 [4분]

> 세 번째 실습입니다. 외부 AI 서비스 사용 가능/불가능을 판단해봅시다.
>
> **안전한 사용**
> - 일반적인 Python 문법 질문: O
> - 공개된 알고리즘 설명 요청: O
> - 오픈소스 라이브러리 사용법: O
>
> **위험한 사용**
> - 실제 센서 데이터 입력: X
> - 품질 기준 파라미터 공유: X
> - 설비 운영 코드 검토 요청: X
> - 고객사 관련 정보 언급: X
>
> "이 코드가 뭐가 문제인지 봐줘"라고 할 때, 그 코드에 회사 기밀이 포함되어 있으면 안 됩니다.

### 실습 4: 윤리 점검 문서 작성 [4분]

> 마지막 실습입니다. 프로젝트 윤리 점검서를 작성해봅시다.
>
> 슬라이드의 양식을 보세요.
>
> ```markdown
> ## AI 프로젝트 윤리 점검서
>
> ### 1. 프로젝트 개요
> - 프로젝트명: 스마트공장 품질 예측 AI
> - 목적: 불량 발생 사전 예측
> - 사용 데이터: 센서 측정값, 품질 결과
>
> ### 2. 윤리 점검 결과
> - 공정성: O
> - 투명성: 주의 (설명 가능성 보완 필요)
> - 책임성: O
> - 안전성: O
>
> ### 3. 식별된 위험 및 대응 방안
> - 위험: 특정 설비 데이터 편향
> - 대응: 전체 설비 균등 수집
> ```
>
> 이런 문서를 프로젝트 시작 전에 작성해두면, 나중에 문제가 발생했을 때 대응이 수월합니다.

---

### 정리 (3분)

#### 핵심 요약 [1.5분]

> 오늘 배운 내용을 정리하겠습니다.
>
> **첫째, AI 윤리 4대 원칙**
> 공정성, 투명성, 책임성, 안전성. 이 네 가지를 항상 기억하세요.
>
> **둘째, 데이터 보안 3대 영역**
> 개인정보 보호, 기업 비밀 보호, 접근 권한 관리입니다.
>
> **셋째, 실무 적용**
> 체크리스트와 점검서로 프로젝트 시작 전에 점검하세요.

#### 다음 차시 예고 [1분]

> 다음 2차시에서는 Python 환경을 구축하고 기초 문법을 배웁니다.
>
> Anaconda 설치, Jupyter Notebook 사용법, 변수, 조건문, 반복문을 다룰 예정입니다.
>
> 개인 PC를 준비해주시고, Windows 10 이상을 권장드립니다.

#### 마무리 [0.5분]

> AI 개발자로서 기술만큼이나 윤리 의식도 중요합니다.
>
> 오늘 배운 내용을 실무에서 꼭 적용해주세요.
>
> 수고하셨습니다. 다음 시간에 뵙겠습니다!

---

## 강의 노트

### 준비물
- PPT 슬라이드 (slides.md)
- 윤리 체크리스트 양식 (실습용)

### 주의사항
- 법률 관련 내용은 2025년 기준이므로 최신 법령 확인 필요
- 특정 기업 사례 언급 시 일반화하여 설명

### 예상 질문
1. "우리 회사에서 ChatGPT 사용해도 되나요?"
   → 소속 기업의 보안 정책 확인 권유, 일반적으로 기밀 정보 입력은 금지

2. "AI가 만든 코드도 내가 저작권을 가지나요?"
   → 현재 법적으로 불명확, 회사 법무팀 확인 권유

3. "개인정보 비식별화는 어떻게 하나요?"
   → 추후 데이터 전처리 차시에서 상세히 다룰 예정
