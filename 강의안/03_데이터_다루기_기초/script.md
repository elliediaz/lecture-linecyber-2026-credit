# [3차시] 데이터 다루기 기초 - 강사 스크립트

## 강의 정보
- **차시**: 3차시 (25분)
- **유형**: 이론 + 실습
- **대상**: AI 기초체력훈련 수강생 (비전공자/입문자)

---

## 도입 (3분)

### 인사 및 지난 시간 복습 [1분]

> 안녕하세요, 3차시를 시작하겠습니다.
>
> 지난 시간에 Python 기본 문법을 배웠죠? 변수, 리스트, 딕셔너리, 조건문, 반복문.
>
> 오늘부터는 이 기본기를 바탕으로 실제 데이터를 다루는 방법을 배웁니다.

### 동기유발 [1분]

> 여러분, 엑셀에서 10만 개 행의 데이터를 분석해본 적 있으신가요?
>
> 엑셀은 느리고, 복잡한 분석은 수식이 너무 길어집니다. 그리고 같은 분석을 반복하려면 처음부터 다시 해야 하죠.
>
> Python의 NumPy와 Pandas를 사용하면 이런 문제가 해결됩니다. 100만 개 데이터도 빠르게 처리하고, 코드를 저장해두면 언제든 재사용할 수 있어요.
>
> 오늘 이 두 가지 핵심 도구를 배워보겠습니다.

### 학습목표 안내 [1분]

> 오늘 수업을 마치면 다음 세 가지를 할 수 있습니다.
>
> 첫째, NumPy 배열의 개념과 기본 연산을 이해합니다.
> 둘째, Pandas DataFrame으로 표 형태 데이터를 다룰 수 있습니다.
> 셋째, CSV 파일을 불러오고 기본 탐색을 수행할 수 있습니다.
>
> 이 두 라이브러리는 앞으로 모든 데이터 분석과 AI 개발의 기초가 됩니다.

---

## 전개 (19분)

### 섹션 1: NumPy 기초 (7분)

#### NumPy 소개 [1분]

> 먼저 **NumPy**입니다. Numerical Python의 줄임말이에요.
>
> NumPy는 수치 계산을 위한 핵심 라이브러리입니다. Python 리스트로도 계산할 수 있지만, NumPy를 쓰면 코드가 간단해지고 속도가 최대 100배까지 빨라집니다.
>
> 왜 빠르냐면, NumPy는 C 언어로 최적화되어 있기 때문입니다. 우리는 Python으로 쉽게 쓰지만, 내부에서는 C가 열심히 계산하고 있는 거죠.

#### 배열 생성 [2분]

> NumPy의 핵심은 **배열(array)**입니다.
>
> *(코드 시연)*
>
> ```python
> import numpy as np
>
> # 리스트에서 배열 만들기
> temps = np.array([82, 85, 88, 95, 84])
> print(temps)
> ```
>
> `import numpy as np`로 불러오고, `np.array()`로 배열을 만듭니다. np는 관례적인 별명이에요.
>
> 2차원 배열도 만들 수 있습니다.
>
> ```python
> sensor = np.array([
>     [82, 45, 1.2],
>     [85, 48, 1.1]
> ])
> print(sensor.shape)  # (2, 3) - 2행 3열
> ```
>
> `.shape`로 배열의 크기를 확인할 수 있습니다.

#### NumPy 연산 [2분]

> NumPy의 강력한 점은 **벡터화 연산**입니다.
>
> *(코드 시연)*
>
> ```python
> temps = np.array([82, 85, 88, 95, 84])
>
> # 모든 요소에 한 번에 연산
> temps_plus = temps + 10  # [92, 95, 98, 105, 94]
> temps_double = temps * 2  # [164, 170, 176, 190, 168]
> ```
>
> 반복문 없이 한 줄로 모든 요소에 연산이 적용됩니다. 이게 NumPy가 빠른 이유예요.
>
> 조건 연산도 됩니다.
>
> ```python
> high_temp = temps > 90
> print(high_temp)  # [False, False, False, True, False]
> print(temps[high_temp])  # [95] - 조건을 만족하는 값만 추출
> ```

#### NumPy 통계 함수 [2분]

> NumPy에는 통계 함수가 내장되어 있습니다.
>
> *(코드 시연)*
>
> ```python
> data = np.array([1200, 1150, 1300, 1180, 1250])
>
> print(np.sum(data))    # 합계: 6080
> print(np.mean(data))   # 평균: 1216
> print(np.std(data))    # 표준편차: 53.45
> print(np.max(data))    # 최대값: 1300
> print(np.min(data))    # 최소값: 1150
> ```
>
> 2차원 배열에서는 `axis` 파라미터로 방향을 지정할 수 있어요.
>
> ```python
> # axis=0: 열 방향(세로), axis=1: 행 방향(가로)
> data_2d = np.array([[100, 200], [150, 250]])
> np.mean(data_2d, axis=0)  # 열별 평균
> np.mean(data_2d, axis=1)  # 행별 평균
> ```

---

### 섹션 2: Pandas DataFrame (8분)

#### Pandas 소개 [1분]

> 이제 **Pandas**를 배워봅시다.
>
> Pandas는 표 형태 데이터를 다루는 도구입니다. 엑셀 시트를 생각하시면 됩니다. 행과 열이 있고, 각 열에 이름이 붙어 있는 구조죠.
>
> 이 표를 Pandas에서는 **DataFrame**이라고 부릅니다.

#### DataFrame 생성 [1.5분]

> DataFrame을 만드는 가장 일반적인 방법은 딕셔너리에서 만드는 것입니다.
>
> *(코드 시연)*
>
> ```python
> import pandas as pd
>
> data = {
>     "제품코드": ["A001", "A002", "A003"],
>     "생산량": [1200, 1150, 1300],
>     "불량수": [24, 35, 26]
> }
>
> df = pd.DataFrame(data)
> print(df)
> ```
>
> 딕셔너리의 키가 열 이름이 되고, 값 리스트가 각 열의 데이터가 됩니다.

#### CSV 파일 읽기/쓰기 [1.5분]

> 실무에서는 CSV 파일을 가장 많이 사용합니다.
>
> *(코드 시연)*
>
> ```python
> # CSV 파일 읽기
> df = pd.read_csv("production_data.csv")
>
> # 한글 파일이면 인코딩 지정
> df = pd.read_csv("data.csv", encoding="utf-8")
> # 또는 Windows에서 만든 파일이면
> df = pd.read_csv("data.csv", encoding="cp949")
>
> # 저장
> df.to_csv("output.csv", index=False)
> ```
>
> `index=False`를 넣으면 행 번호가 파일에 저장되지 않습니다.

#### 데이터 탐색 [2분]

> 데이터를 불러왔으면 가장 먼저 해야 할 일은 **탐색**입니다.
>
> *(코드 시연)*
>
> ```python
> # 처음 5행 보기
> df.head()
>
> # 마지막 5행
> df.tail()
>
> # 크기 확인
> df.shape  # (행수, 열수)
>
> # 열 이름
> df.columns
>
> # 데이터 정보
> df.info()
>
> # 기본 통계
> df.describe()
> ```
>
> `df.info()`는 각 열의 데이터 타입과 결측치 개수를 보여줍니다. 데이터 분석 시작할 때 꼭 확인하세요.

#### 열/행 선택 [2분]

> 특정 열이나 행을 선택하는 방법입니다.
>
> *(코드 시연)*
>
> ```python
> # 열 선택
> df["생산량"]        # 단일 열 (Series)
> df[["생산량", "불량수"]]  # 여러 열 (DataFrame)
>
> # 행 선택 - loc (라벨 기반)
> df.loc[0]           # 0번 행
> df.loc[0:2]         # 0, 1, 2번 행 (포함!)
>
> # 행 선택 - iloc (위치 기반)
> df.iloc[0]          # 첫 번째 행
> df.iloc[0:2]        # 0, 1번 행 (미포함)
> ```
>
> loc와 iloc의 차이, 특히 슬라이싱에서 끝 인덱스 포함 여부가 다르다는 점 기억해두세요.

---

### 섹션 3: 데이터 분석 기초 (4분)

#### 조건 필터링 [1.5분]

> 원하는 조건의 데이터만 추출하는 방법입니다.
>
> *(코드 시연)*
>
> ```python
> # 생산량 1200 초과인 행
> high_prod = df[df["생산량"] > 1200]
>
> # 복합 조건 (and: &, or: |)
> filtered = df[(df["생산량"] > 1100) & (df["라인"] == 1)]
> ```
>
> 주의할 점! Python의 `and`가 아니라 `&`를 사용합니다. 그리고 각 조건을 괄호로 감싸야 합니다.

#### 그룹별 집계 [1.5분]

> 제조 현장에서 자주 하는 분석 중 하나가 라인별, 제품별 통계입니다.
>
> *(코드 시연)*
>
> ```python
> # 라인별 평균 생산량
> df.groupby("라인")["생산량"].mean()
>
> # 라인별 여러 통계
> df.groupby("라인").agg({
>     "생산량": ["mean", "sum"],
>     "불량수": ["mean", "sum"]
> })
> ```
>
> `groupby()`로 그룹을 나누고, 원하는 열에 통계 함수를 적용합니다.

#### 결측치 처리 [1분]

> 실제 데이터에는 빈 값, 즉 결측치가 있는 경우가 많습니다.
>
> *(코드 시연)*
>
> ```python
> # 결측치 확인
> df.isnull().sum()
>
> # 결측치 있는 행 제거
> df_clean = df.dropna()
>
> # 결측치 채우기
> df["불량수"] = df["불량수"].fillna(0)
> # 또는 평균으로 채우기
> df["불량수"] = df["불량수"].fillna(df["불량수"].mean())
> ```
>
> 결측치를 어떻게 처리할지는 상황에 따라 다릅니다. 8차시 데이터 전처리에서 자세히 다룰 예정입니다.

---

## 정리 (3분)

### 핵심 내용 요약 [1.5분]

> 오늘 배운 내용을 정리하겠습니다.
>
> **첫째, NumPy**를 배웠습니다.
> 배열을 만들고, 벡터화 연산으로 빠르게 계산하고, mean, std, max, min 같은 통계 함수를 사용했죠.
>
> **둘째, Pandas DataFrame**을 배웠습니다.
> 딕셔너리나 CSV 파일에서 DataFrame을 만들고, head(), info(), describe()로 데이터를 탐색했습니다.
>
> **셋째, 기본 분석** 방법을 배웠습니다.
> 조건 필터링, groupby 집계, 결측치 처리까지.
>
> 이 두 라이브러리는 앞으로 매 차시마다 사용할 거예요.

### 다음 차시 예고 [1분]

> 다음 4차시에서는 **데이터 시각화**를 배웁니다.
>
> Matplotlib 라이브러리로 히스토그램, 상자그림, 산점도를 그려볼 거예요. 숫자로만 보던 데이터를 그래프로 보면 훨씬 이해가 쉬워집니다.
>
> 오늘 배운 NumPy와 Pandas 코드를 직접 실행해보시고, 자신만의 데이터로 실습해보세요.

### 마무리 인사 [0.5분]

> 오늘 데이터 분석의 양대 산맥인 NumPy와 Pandas를 배웠습니다.
>
> 처음에는 낯설 수 있지만, 이 두 도구만 잘 쓸 줄 알면 대부분의 데이터 분석이 가능합니다.
>
> 질문 있으시면 말씀해주세요. 수고하셨습니다!

---

## 강의 노트

### 준비물
- Jupyter Notebook 실행 환경
- 실습용 CSV 파일 (production_sample.csv)
- 실습 코드 파일 (code.py)

### 주의사항
- NumPy/Pandas 버전에 따라 일부 기능 차이 있을 수 있음
- 한글 CSV 파일은 인코딩 문제 주의 (utf-8 또는 cp949)
- 대용량 데이터 실습은 메모리 부족 가능성 있음

### 예상 질문
1. "NumPy와 Pandas 중 뭘 먼저 배워야 하나요?"
   → 둘 다 필수. NumPy는 계산, Pandas는 데이터 구조화. Pandas가 NumPy를 기반으로 만들어짐

2. "엑셀 파일도 읽을 수 있나요?"
   → `pd.read_excel("file.xlsx")` 사용. openpyxl 패키지 필요

3. "DataFrame을 엑셀처럼 직접 수정할 수 있나요?"
   → 코드로 수정. GUI 원하면 JupyterLab의 DataFrame 뷰어 또는 VS Code 확장 사용

4. "groupby 결과가 이상하게 나와요"
   → 멀티인덱스 문제일 수 있음. `.reset_index()` 적용해보기

### 시간 조절 팁
- NumPy에 시간이 부족하면: 2차원 배열 부분 간략히
- Pandas에 시간이 부족하면: 결측치 처리는 8차시로 미루기
- 시간이 남으면: 실제 CSV 파일 불러와서 함께 분석해보기
