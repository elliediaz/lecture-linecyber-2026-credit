# [24차시] 모델 해석과 특성 중요도 분석 - 강사 스크립트

## 강의 정보
- **차시**: 24차시 (25분)
- **유형**: 실습 중심
- **대상**: AI 기초체력훈련 수강생 (비전공자/입문자)

---

## 도입 (3분)

### 인사 및 지난 시간 복습 [1.5분]

> 안녕하세요, 24차시를 시작하겠습니다.
>
> 지난 시간에 FastAPI로 모델을 API로 서비스하는 방법을 배웠습니다.
>
> 오늘은 **모델 해석**을 배웁니다. 모델이 왜 그렇게 예측했는지 설명하는 방법이에요!

### 학습목표 안내 [1.5분]

> 오늘 수업을 마치면 다음을 할 수 있습니다.
>
> 첫째, 모델 해석의 필요성을 이해합니다.
> 둘째, 특성 중요도(Feature Importance)를 분석합니다.
> 셋째, Permutation Importance를 활용합니다.
>
> 실무에서는 "왜 불량이라고 판단했나요?"라는 질문에 답할 수 있어야 해요!

---

## 전개 (19분)

### 섹션 1: 모델 해석의 필요성 (3분)

#### 블랙박스 문제 [1.5분]

> 머신러닝 모델, 특히 복잡한 모델은 **블랙박스**처럼 작동해요.
>
> 입력을 넣으면 결과가 나오는데, 그 과정을 알 수 없죠.
>
> "왜 이 제품이 불량인가요?"
> "모델이 그렇다고 했으니까요..." 이렇게 답하면 안 되겠죠?

#### 해석이 필요한 이유 [1.5분]

> 모델 해석이 필요한 이유는 세 가지입니다.
>
> 첫째, **신뢰**. 현장 담당자가 모델을 믿으려면 이유를 알아야 해요.
>
> 둘째, **디버깅**. 모델이 이상한 패턴을 학습하진 않았는지 확인해야 해요.
>
> 셋째, **규제**. 금융이나 의료 분야에서는 설명 의무가 있어요.
>
> 성능만 좋은 게 아니라, 설명할 수 있어야 실무에서 사용됩니다!

---

### 섹션 2: 특성 중요도 (Feature Importance) (7분)

#### 개념 이해 [2분]

> *(코드 시연)*
>
> **특성 중요도**는 각 변수가 예측에 얼마나 기여하는지 보여줘요.
>
> ```python
> from sklearn.ensemble import RandomForestClassifier
>
> model = RandomForestClassifier()
> model.fit(X_train, y_train)
>
> print(model.feature_importances_)
> # [0.35, 0.30, 0.25, 0.10]
> ```
>
> 랜덤포레스트, 의사결정트리 같은 트리 기반 모델은 학습하면서 자동으로 계산해줘요.
>
> 숫자는 비율이고, 합치면 1이 됩니다.

#### 시각화 [2분]

> *(코드 시연)*
>
> ```python
> import matplotlib.pyplot as plt
>
> plt.barh(feature_names, model.feature_importances_)
> plt.xlabel('중요도')
> plt.title('특성 중요도')
> plt.show()
> ```
>
> 막대 그래프로 보면 어떤 변수가 중요한지 한눈에 알 수 있어요.
>
> 보통 중요도 순으로 정렬해서 보여줍니다.

#### 제조 예시 해석 [3분]

> 품질 예측 모델에서 특성 중요도를 분석했더니:
>
> - 온도: 35%
> - 습도: 30%
> - 속도: 25%
> - 압력: 10%
>
> 이 결과를 어떻게 해석할까요?
>
> **온도**가 품질에 가장 큰 영향을 미친다는 뜻이에요.
>
> 불량률을 줄이려면 온도 관리를 최우선으로 해야 하는 거죠!
>
> 반면 압력은 상대적으로 영향이 적으니, 다른 요인에 집중하는 게 효율적이에요.

---

### 섹션 3: Permutation Importance (6분)

#### 개념 설명 [2min]

> *(코드 시연)*
>
> Feature Importance는 학습 중에 계산되는데, 편향이 있을 수 있어요.
>
> **Permutation Importance**는 더 신뢰할 수 있는 방법이에요.
>
> 원리는 간단해요:
>
> 1. 특정 특성의 값을 무작위로 섞어요
> 2. 예측 성능이 얼마나 떨어지는지 봐요
> 3. 많이 떨어지면? 그 특성이 중요한 거예요!

#### 코드 실습 [2min]

> ```python
> from sklearn.inspection import permutation_importance
>
> result = permutation_importance(
>     model, X_test, y_test,
>     n_repeats=10,
>     random_state=42
> )
>
> print(result.importances_mean)
> ```
>
> n_repeats=10이면 10번 반복해서 평균을 계산해요.
>
> 여러 번 하면 결과가 더 안정적이에요.

#### 두 방법 비교 [2min]

> 두 방법을 비교해볼게요.
>
> **Feature Importance**: 학습 중 계산, 빠름, 하지만 편향 가능
>
> **Permutation Importance**: 학습 후 계산, 느림, 하지만 더 신뢰성
>
> 실무에서는 먼저 Feature Importance로 빠르게 확인하고,
> 중요한 분석이나 보고서에는 Permutation Importance를 사용해요.

---

### 섹션 4: 실무 활용과 주의사항 (3분)

#### 해석 시 주의점 [1.5min]

> 중요도 해석할 때 주의할 점이 있어요.
>
> 첫째, **상관된 특성**. 온도와 습도가 높은 상관관계가 있으면 중요도가 분산돼요.
>
> 둘째, **인과관계 ≠ 상관관계**. 중요도가 높다고 원인인 건 아니에요.
>
> 비즈니스 도메인 지식이 있어야 제대로 해석할 수 있어요!

#### 보고서 작성 [1.5min]

> 실무에서는 이렇게 보고해요:
>
> "모델 분석 결과, 온도가 품질에 35%로 가장 큰 영향을 미칩니다.
> 85도 초과 시 불량률이 급증하므로, 온도 모니터링 강화를 권장합니다."
>
> 숫자만 나열하지 말고, 비즈니스 의사결정에 도움이 되게 해석해야 해요.

---

## 정리 (3분)

### 핵심 내용 요약 [1.5분]

> 오늘 배운 핵심 내용:
>
> 1. **모델 해석**: 왜 그렇게 예측했는지 설명
> 2. **Feature Importance**: model.feature_importances_
> 3. **Permutation Importance**: sklearn.inspection 사용
> 4. **시각화**: 막대 그래프로 중요도 표현
> 5. **실무 활용**: 비즈니스 인사이트 도출
>
> 모델 성능 + 해석 가능성 = 실무 적용!

### 다음 차시 예고 [1min]

> 다음 25차시는 마지막 수업으로 **모델 저장과 실무 배포**를 배웁니다.
>
> joblib으로 모델을 저장하고 불러오는 방법,
> 실무에서 배포할 때 체크리스트를 다룹니다!

### 마무리 인사 [0.5분]

> 모델 해석 방법을 배웠습니다.
>
> 다음 시간에 뵙겠습니다. 수고하셨습니다!

---

## 강의 노트

### 예상 질문

1. "SHAP은 안 배우나요?"
   → SHAP은 고급 과정에서 다룸. 이번 차시는 기본적인 방법 학습

2. "딥러닝 모델도 해석 가능?"
   → 가능하지만 더 어려움. Grad-CAM, Attention 등 사용

3. "중요도가 비슷하면?"
   → 상관관계 분석 필요. 도메인 지식으로 우선순위 결정

### 시간 조절 팁
- 시간 부족: 고급 기법(SHAP, LIME) 소개 생략
- 시간 여유: 박스플롯으로 Permutation Importance 변동성 시각화

### 실습 팁
- feature_importances_는 학습 후 바로 접근 가능
- Permutation Importance는 시간이 걸리므로 n_repeats를 낮게 시작
