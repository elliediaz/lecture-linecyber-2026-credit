# [9차시] 데이터 전처리 실무 (2) - 강사 스크립트

## 강의 정보
- **차시**: 9차시 (25분)
- **유형**: 이론 + 실습
- **대상**: AI 기초체력훈련 수강생 (비전공자/입문자)

---

## 도입 (3분)

### 인사 및 지난 시간 복습 [1.5분]

> 안녕하세요, 9차시를 시작하겠습니다.
>
> 지난 시간에 결측치와 이상치 처리를 배웠죠. 오늘은 또 다른 중요한 전처리, **스케일링**과 **인코딩**을 배웁니다.

### 학습목표 안내 [1.5분]

> 오늘 수업을 마치면 다음을 할 수 있습니다.
>
> 첫째, 스케일링의 필요성을 이해하고 적용합니다.
> 둘째, 범주형 데이터를 인코딩합니다.
> 셋째, sklearn의 전처리 도구를 활용합니다.

---

## 전개 (19분)

### 섹션 1: 스케일링 (8분)

#### 스케일링 필요성 [2분]

> 온도는 80~100, 생산량은 1000~1500 범위입니다. 스케일이 다르죠.
>
> 이 상태로 모델에 넣으면 생산량이 과도한 영향을 미칩니다. 특히 거리 기반 알고리즘(KNN 등)에서 문제가 됩니다.

#### 표준화와 정규화 [4분]

> **표준화(StandardScaler)**는 평균 0, 표준편차 1로 변환합니다. 대부분의 ML 모델에 적합해요.
>
> **정규화(MinMaxScaler)**는 0~1 범위로 변환합니다. 신경망에서 주로 사용합니다.
>
> *(코드 시연)*
>
> ```python
> from sklearn.preprocessing import StandardScaler, MinMaxScaler
>
> scaler = StandardScaler()
> X_scaled = scaler.fit_transform(X)
> ```

#### 실습 [2분]

> 제조 데이터에 스케일링을 적용하고 전후를 비교해봅시다.

---

### 섹션 2: 인코딩 (8분)

#### 범주형 데이터 문제 [2분]

> 라인 'A', 'B', 'C' 같은 문자는 ML 모델에 넣을 수 없습니다. 숫자로 바꿔야 해요.

#### 레이블 인코딩 [2분]

> 순서가 있는 범주(등급 상/중/하)는 **LabelEncoder**를 사용합니다.
>
> ```python
> le = LabelEncoder()
> df['등급_encoded'] = le.fit_transform(df['등급'])
> ```

#### 원-핫 인코딩 [2min]

> 순서가 없는 범주(라인 A/B/C)는 **OneHotEncoder**를 사용합니다.
>
> ```python
> df_encoded = pd.get_dummies(df, columns=['라인'])
> ```
>
> 각 범주가 별도의 열이 됩니다.

#### Pipeline 소개 [2분]

> sklearn의 **Pipeline**으로 전처리를 자동화할 수 있습니다.
>
> ```python
> pipe = Pipeline([
>     ('scaler', StandardScaler()),
>     ('model', LinearRegression())
> ])
> ```

---

### 섹션 3: 실습 (3분)

> 스케일링과 인코딩을 조합한 전처리 파이프라인을 만들어봅시다.

---

## 정리 (3분)

### 핵심 내용 요약 [1.5분]

> **스케일링**: StandardScaler(표준화), MinMaxScaler(정규화)
>
> **인코딩**: LabelEncoder(순서 있음), OneHotEncoder(순서 없음)
>
> **Pipeline**: 전처리 자동화

### 다음 차시 예고 [1분]

> 다음 10차시에서는 **탐색적 데이터분석(EDA)**을 종합적으로 실습합니다.

### 마무리 인사 [0.5분]

> 전처리 2부작이 끝났습니다. 수고하셨습니다!

---

## 강의 노트

### 예상 질문
1. "fit과 transform 차이가 뭔가요?"
   → fit: 통계량 계산(평균, 표준편차 등)
   → transform: 실제 변환 적용
   → 학습 데이터에만 fit, 테스트 데이터는 transform만

2. "원-핫 인코딩하면 열이 너무 많아지는데요?"
   → 범주가 많으면 타겟 인코딩, 빈도 인코딩 고려

### 시간 조절 팁
- 시간 부족: Pipeline 부분 간략히
- 시간 여유: RobustScaler, OrdinalEncoder 추가
