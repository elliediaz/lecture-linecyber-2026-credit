# [15차시] 모델 평가와 교차검증 - 강사 스크립트

## 강의 정보
- **차시**: 15차시 (25분)
- **유형**: 이론 + 실습
- **대상**: AI 기초체력훈련 수강생 (비전공자/입문자)

---

## 도입 (3분)

### 인사 및 지난 시간 복습 [1.5분]

> 안녕하세요, 15차시를 시작하겠습니다.
>
> 지금까지 분류 모델(의사결정트리, 랜덤포레스트)과 회귀 모델(선형회귀, 다항회귀)을 배웠습니다. 모델을 만들고 score()로 성능을 확인했죠.
>
> 그런데 이 평가 방법이 **충분히 신뢰할 수 있을까요?** 오늘은 더 정확한 평가 방법을 배웁니다.

### 학습목표 안내 [1.5분]

> 오늘 수업을 마치면 다음을 할 수 있습니다.
>
> 첫째, 교차검증의 개념과 필요성을 이해합니다.
> 둘째, 과대적합과 과소적합을 진단합니다.
> 셋째, 혼동행렬, 정밀도, 재현율을 해석합니다.

---

## 전개 (19분)

### 섹션 1: 교차검증 (6분)

#### 기존 방법의 문제 [2min]

> 지금까지는 train_test_split으로 한 번 나눠서 평가했죠.
>
> 문제가 있어요. 운 좋게 쉬운 테스트 데이터가 뽑힐 수 있고, 운 나쁘게 어려운 데이터가 뽑힐 수도 있어요.
>
> 85%라는 점수가 나왔는데, 진짜 85%인지 아니면 운이 좋았던 건지 알기 어렵습니다.

#### 교차검증 개념 [2min]

> **교차검증(Cross Validation)**은 데이터를 여러 번 나눠서 평가하고 평균을 계산하는 방법입니다.
>
> **K-Fold 교차검증**이 가장 많이 사용돼요. 데이터를 K개로 나누고, 각각을 한 번씩 테스트 데이터로 사용합니다.
>
> 5-Fold라면: 1회차에서 첫 번째가 테스트, 2회차에서 두 번째가 테스트... 이렇게 5번 평가하고 평균을 냅니다.
>
> 결과: "평균 84% (±1.4%)" 이렇게 나오면 더 신뢰할 수 있죠.

#### sklearn 구현 [2min]

> *(코드 시연)*
>
> ```python
> from sklearn.model_selection import cross_val_score
>
> model = RandomForestClassifier(n_estimators=100)
> scores = cross_val_score(model, X, y, cv=5)
>
> print(f"각 Fold 점수: {scores}")
> print(f"평균: {scores.mean():.3f}")
> print(f"표준편차: {scores.std():.3f}")
> ```
>
> cross_val_score 하나로 간단하게 교차검증을 할 수 있어요. cv=5면 5-Fold입니다.

---

### 섹션 2: 과대적합과 과소적합 (5분)

#### 개념 설명 [2min]

> 모델이 복잡하면 학습 데이터를 잘 맞추지만 새 데이터에서는 성능이 떨어질 수 있어요. 이것을 **과대적합(Overfitting)**이라고 합니다.
>
> 반대로 모델이 너무 단순하면 학습 데이터조차 잘 못 맞춰요. 이것은 **과소적합(Underfitting)**입니다.

#### 진단 방법 [2min]

> 학습 정확도와 테스트 정확도를 비교하면 알 수 있어요.
>
> - **과소적합**: 둘 다 낮음 (학습 70%, 테스트 68%)
> - **과대적합**: 학습만 높음 (학습 98%, 테스트 75%)
> - **적절한 모델**: 비슷하게 높음 (학습 86%, 테스트 84%)
>
> 학습과 테스트 점수의 **차이가 크면** 과대적합을 의심하세요.

#### 해결 방법 [1min]

> **과소적합 해결**: 더 복잡한 모델, 특성 추가, max_depth 증가
>
> **과대적합 해결**: 더 단순한 모델, 데이터 추가, max_depth 감소
>
> 다음 차시에서 배울 하이퍼파라미터 튜닝이 이 문제를 해결하는 데 도움됩니다.

---

### 섹션 3: 분류 모델 상세 평가 (8분)

#### 혼동행렬 [3min]

> 정확도만으로는 부족할 때가 있어요. 예를 들어 불량률이 5%인 데이터에서 "모든 것을 정상"이라고 예측해도 정확도 95%가 나옵니다.
>
> **혼동행렬(Confusion Matrix)**은 더 자세한 정보를 줍니다.
>
> *(슬라이드 설명)*
>
> - TN: 정상을 정상으로 예측 (맞음)
> - FP: 정상을 불량으로 예측 (틀림)
> - FN: 불량을 정상으로 예측 (틀림)
> - TP: 불량을 불량으로 예측 (맞음)

#### 정밀도와 재현율 [3min]

> **정밀도(Precision)**: 불량이라고 예측한 것 중 진짜 불량 비율
> - "불량 경고를 했을 때, 얼마나 맞을까?"
>
> **재현율(Recall)**: 실제 불량 중 잡아낸 비율
> - "진짜 불량을 얼마나 놓치지 않았을까?"
>
> 상황에 따라 중요한 지표가 달라요.
> - 암 진단: 재현율이 중요 (환자를 놓치면 안 됨)
> - 스팸 필터: 정밀도가 중요 (중요한 메일을 스팸으로 분류하면 안 됨)
> - 제조 불량: 보통 재현율이 중요 (불량품이 고객에게 가면 안 됨)

#### F1 Score와 분류 리포트 [2min]

> **F1 Score**는 정밀도와 재현율의 조화평균이에요. 둘 다 중요할 때 사용합니다.
>
> *(코드 시연)*
>
> ```python
> from sklearn.metrics import classification_report
> print(classification_report(y_test, y_pred))
> ```
>
> classification_report로 정밀도, 재현율, F1을 한 번에 볼 수 있어요.

---

## 정리 (3분)

### 핵심 내용 요약 [1.5분]

> 오늘 배운 핵심 내용을 정리하면:
>
> 1. **교차검증**: 여러 번 나눠서 평가, 평균으로 신뢰성 확보
> 2. **과대적합**: 학습 높고 테스트 낮음 → 모델 단순화
> 3. **과소적합**: 둘 다 낮음 → 모델 복잡화
> 4. **혼동행렬**: 분류 결과 상세 분석
> 5. **정밀도/재현율**: 상황에 따라 중요도 다름
> 6. **F1 Score**: 둘의 균형
>
> 모델 성능은 **한 번이 아니라 여러 번** 평가해야 합니다!

### 다음 차시 예고 [1min]

> 다음 16차시에서는 **하이퍼파라미터 튜닝**을 배웁니다.
>
> max_depth, n_estimators 같은 값을 어떻게 설정하면 좋을까요? GridSearchCV로 최적의 조합을 자동으로 찾아봅니다.

### 마무리 인사 [0.5분]

> 모델을 제대로 평가하는 방법을 배웠습니다. 수고하셨습니다!

---

## 강의 노트

### 예상 질문
1. "cv는 몇으로 하면 되나요?"
   → 보통 5 또는 10. 데이터가 적으면 5, 많으면 10

2. "정밀도와 재현율 중 뭐가 더 중요한가요?"
   → 도메인에 따라 다름. 비용을 고려해서 결정

3. "교차검증은 항상 해야 하나요?"
   → 모델 선택/비교할 때 필수. 최종 모델 학습은 전체 데이터로

### 시간 조절 팁
- 시간 부족: F1 Score 부분 간략히
- 시간 여유: ROC-AUC 소개
