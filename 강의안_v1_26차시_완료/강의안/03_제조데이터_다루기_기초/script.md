# [3차시] 제조 데이터 다루기 기초 - 강사 스크립트

## 강의 정보
- **차시**: 3차시 (25-30분)
- **유형**: 이론 + 실습
- **구성**: 이론 10분 + 실습 15-20분
- **대상**: 비전공자, AI 입문자, 제조업 종사자

---

## 이론편 (10분)

### 도입 (2분)

#### 인사 및 지난 시간 복습 [1분]

> 안녕하세요, 3차시를 시작하겠습니다.
>
> 지난 시간에 Python 기본 문법을 배웠죠? 변수, 리스트, 딕셔너리, 조건문, 반복문.
>
> 오늘부터는 이 기본기를 바탕으로 실제 제조 데이터를 다루는 방법을 배웁니다.

#### 학습목표 안내 [1분]

> 오늘 수업을 마치면 다음 세 가지를 할 수 있습니다.
>
> 첫째, NumPy 배열의 개념과 기본 연산을 이해합니다.
> 둘째, Pandas DataFrame으로 표 형태 데이터를 다룰 수 있습니다.
> 셋째, CSV 파일을 불러오고 제조 데이터를 탐색할 수 있습니다.
>
> 이 두 라이브러리는 앞으로 모든 데이터 분석과 AI 개발의 기초가 됩니다.

---

### 핵심 내용 (8분)

#### 왜 NumPy와 Pandas인가? [2분]

> 먼저 왜 이 도구들이 필요한지 알아봅시다.
>
> Python 리스트로도 계산할 수 있지만, NumPy를 쓰면 코드가 간단해지고 속도가 최대 100배까지 빨라집니다.
>
> ```python
> # 리스트로 평균 계산 - 복잡함
> total = 0
> for x in data:
>     total += x
> average = total / len(data)
>
> # NumPy로 평균 계산 - 한 줄!
> average = np.array(data).mean()
> ```
>
> 왜 빠르냐면, NumPy는 C 언어로 최적화되어 있기 때문입니다.

#### NumPy 배열과 연산 [2분]

> NumPy의 핵심은 **배열(array)**입니다.
>
> ```python
> import numpy as np
> temperatures = np.array([82, 85, 88, 95, 84])
> ```
>
> `np.array()`로 배열을 만듭니다. NumPy의 강력한 점은 **벡터화 연산**이에요.
>
> ```python
> # 모든 요소에 한 번에 연산 적용
> temps_adjusted = temperatures - 32
> high_temps = temperatures[temperatures > 90]  # 조건 필터링
> ```
>
> 반복문 없이 한 줄로 모든 요소에 연산이 적용됩니다.

#### NumPy 통계 함수 [1분]

> NumPy에는 통계 함수가 내장되어 있습니다.
>
> ```python
> production = np.array([1200, 1150, 1300, 1180, 1250])
> print(np.mean(production))  # 평균
> print(np.std(production))   # 표준편차
> print(np.max(production))   # 최대값
> ```
>
> 한 줄 코드로 통계 계산이 가능합니다.

#### Pandas DataFrame [2분]

> 이제 **Pandas**를 배워봅시다.
>
> Pandas는 표 형태 데이터를 다루는 도구입니다. 엑셀 시트처럼 행과 열이 있고, 각 열에 이름이 붙어 있죠.
>
> ```python
> import pandas as pd
>
> data = {
>     "제품코드": ["SM-001", "SM-002", "SM-003"],
>     "생산량": [1200, 1150, 1300],
>     "불량수": [24, 35, 26]
> }
> df = pd.DataFrame(data)
> ```
>
> 딕셔너리의 키가 열 이름이 되고, 값 리스트가 각 열의 데이터가 됩니다.

#### CSV 파일과 데이터 탐색 [1분]

> 실무에서는 CSV 파일을 가장 많이 사용합니다.
>
> ```python
> df = pd.read_csv("production_data.csv")
> df.head()       # 처음 5행
> df.info()       # 데이터 타입과 결측치
> df.describe()   # 기본 통계
> ```
>
> `df.info()`는 각 열의 데이터 타입과 결측치 개수를 보여줍니다. 데이터 분석 시작할 때 꼭 확인하세요.

---

## 실습편 (15-20분)

### 실습 소개 [2분]

> 이제 실습 시간입니다. 오늘은 제조 데이터를 NumPy와 Pandas로 분석해보겠습니다.
>
> **실습 환경**을 확인해주세요.
>
> ```python
> import numpy as np
> import pandas as pd
> ```
>
> 두 라이브러리가 정상적으로 불러와지나요? 준비되셨으면 시작하겠습니다.

### 실습 1: NumPy 배열 다루기 [3분]

> 첫 번째 실습입니다. 24시간 온도 센서 데이터를 분석해봅시다.
>
> ```python
> import numpy as np
>
> temperatures = np.array([
>     82, 84, 85, 87, 88, 90, 92, 95,
>     93, 91, 89, 86, 85, 84, 83, 82,
>     81, 80, 79, 80, 81, 82, 83, 84
> ])
>
> print(f"평균 온도: {temperatures.mean():.1f}도")
> print(f"최고 온도: {temperatures.max()}도")
> print(f"최저 온도: {temperatures.min()}도")
>
> # 90도 초과 횟수
> over_90 = temperatures[temperatures > 90]
> print(f"90도 초과: {len(over_90)}회")
> ```
>
> `temperatures > 90`은 불리언 배열을 만들고, 이걸 인덱스로 사용하면 조건에 맞는 값만 추출됩니다.

### 실습 2: DataFrame 생성 [3분]

> 두 번째 실습입니다. 생산 데이터를 DataFrame으로 만들어봅시다.
>
> ```python
> import pandas as pd
>
> production_data = {
>     "날짜": ["2024-01-01", "2024-01-02", "2024-01-03",
>              "2024-01-04", "2024-01-05"],
>     "라인": [1, 2, 1, 2, 1],
>     "생산량": [1200, 1150, 1300, 1180, 1250],
>     "불량수": [24, 35, 26, 42, 25]
> }
>
> df = pd.DataFrame(production_data)
> print(df)
> ```
>
> 5일간의 생산 데이터가 표 형태로 만들어졌습니다.

### 실습 3: 불량률 계산 [3분]

> 세 번째 실습입니다. 새 열을 추가해서 불량률을 계산해봅시다.
>
> ```python
> df["불량률"] = df["불량수"] / df["생산량"]
> df["불량률_%"] = (df["불량률"] * 100).round(2)
>
> print(df[["날짜", "생산량", "불량수", "불량률_%"]])
> ```
>
> DataFrame에 새 열을 추가하는 건 딕셔너리에 새 키를 추가하는 것과 비슷합니다. 열 이름을 지정하고 값을 할당하면 됩니다.

### 실습 4: 조건 필터링 [3분]

> 네 번째 실습입니다. 원하는 조건의 데이터만 추출해봅시다.
>
> ```python
> # 불량률 3% 초과 데이터
> high_defect = df[df["불량률"] > 0.03]
> print("=== 불량률 3% 초과 ===")
> print(high_defect)
>
> # 복합 조건: 1번 라인 AND 생산량 1200 이상
> filtered = df[(df["라인"] == 1) & (df["생산량"] >= 1200)]
> print("\n=== 1번 라인, 생산량 1200+ ===")
> print(filtered)
> ```
>
> 주의할 점! Python의 `and`가 아니라 `&`를 사용합니다. 그리고 각 조건을 괄호로 감싸야 합니다.

### 실습 5: 그룹별 집계 [3분]

> 다섯 번째 실습입니다. 라인별 통계를 계산해봅시다.
>
> ```python
> line_avg = df.groupby("라인")[["생산량", "불량률"]].mean()
> print("=== 라인별 평균 ===")
> print(line_avg)
>
> line_sum = df.groupby("라인")["생산량"].sum()
> print("\n=== 라인별 총 생산량 ===")
> print(line_sum)
> ```
>
> `groupby()`로 그룹을 나누고, 원하는 열에 통계 함수를 적용합니다. 1번 라인과 2번 라인의 평균 불량률이 다른 게 보이시나요?

### 실습 6: 종합 예제 [2분]

> 마지막 종합 예제입니다. 일일 품질 리포트를 생성해봅시다.
>
> ```python
> print("=" * 40)
> print("       일일 품질 리포트")
> print("=" * 40)
> print(f"총 생산량: {df['생산량'].sum():,}개")
> print(f"총 불량수: {df['불량수'].sum():,}개")
> print(f"평균 불량률: {df['불량률'].mean()*100:.2f}%")
>
> best_line = df.groupby("라인")["불량률"].mean().idxmin()
> worst_line = df.groupby("라인")["불량률"].mean().idxmax()
> print(f"\n최우수 라인: {best_line}번")
> print(f"개선 필요 라인: {worst_line}번")
> print("=" * 40)
> ```
>
> 지금까지 배운 내용을 모두 활용한 품질 리포트입니다.

---

### 정리 (3분)

#### 자주 하는 실수 [1분]

> 초보자가 자주 하는 실수를 정리해드립니다.
>
> 첫째, **단일 열 vs 다중 열 선택**. `df["열"]`은 Series, `df[["열"]]`은 DataFrame을 반환합니다.
> 둘째, **조건 연결에서 and 대신 & 사용**. `df[(조건1) and (조건2)]`가 아니라 `df[(조건1) & (조건2)]`입니다.
> 셋째, **조건마다 괄호로 감싸기 필수**. 안 그러면 연산자 우선순위 문제로 에러가 납니다.

#### 핵심 요약 [1분]

> 오늘 배운 내용을 정리하겠습니다.
>
> **NumPy**: 빠른 수치 계산, 벡터화 연산, 통계 함수 (mean, std, max, min)
>
> **Pandas**: 표 형태 데이터, CSV 읽기/쓰기, 그룹별 집계 (groupby)
>
> 이 두 라이브러리는 앞으로 매 차시마다 사용할 거예요.

#### 다음 차시 예고 [0.5분]

> 다음 4차시에서는 **데이터 시각화**를 배웁니다.
>
> Matplotlib으로 히스토그램, 상자그림, 산점도를 그려볼 거예요. 숫자로만 보던 데이터를 그래프로 보면 훨씬 이해가 쉬워집니다.

#### 마무리 [0.5분]

> 오늘 데이터 분석의 핵심 도구인 NumPy와 Pandas를 배웠습니다.
>
> 처음에는 낯설 수 있지만, 이 두 도구만 잘 쓸 줄 알면 대부분의 데이터 분석이 가능합니다.
>
> 수고하셨습니다. 다음 시간에 뵙겠습니다!

---

## 강의 노트

### 준비물
- PPT 슬라이드 (slides.md)
- 실습 코드 파일 (code.py)
- 실습용 CSV 파일 (선택)

### 주의사항
- NumPy/Pandas 버전에 따라 일부 기능 차이 있을 수 있음
- 한글 CSV 파일은 인코딩 문제 주의 (utf-8 또는 cp949)

### 예상 질문
1. "NumPy와 Pandas 중 뭘 먼저 배워야 하나요?"
   → 둘 다 필수. Pandas가 NumPy를 기반으로 만들어짐

2. "엑셀 파일도 읽을 수 있나요?"
   → `pd.read_excel("file.xlsx")` 사용. openpyxl 패키지 필요

3. "groupby 결과가 이상하게 나와요"
   → 멀티인덱스 문제일 수 있음. `.reset_index()` 적용해보기

4. "DataFrame을 엑셀처럼 직접 수정할 수 있나요?"
   → 코드로 수정. GUI 원하면 JupyterLab 뷰어 사용
