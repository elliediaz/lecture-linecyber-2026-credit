# [ 강의계획서 ]

| 항목 | 내용 |
|------|------|
| **과목명** | AI 기초체력훈련 (Pre AI-Campus) |
| **운영 교·강사명** | (담당 강사명) |
| **연도/학기** | 2026 |

---

## 강의개요

본 과정은 AI 기술 개발 분야에 진입하려는 비전공자와 입문자를 대상으로, 제조 분야 공공/기업 데이터를 활용하여 AI 어플리케이션 개발자로 전환하기 위한 기초역량을 배양한다. "문제정의 → 데이터 수집·분석 → 모델링 → 평가"의 전 과정을 단계별 실습 훈련으로 구성하여, AI 작동 원리를 이해하고 실제 데이터를 활용한 예측 모델을 직접 구축할 수 있도록 한다. 파이썬 프로그래밍 환경에서 NumPy, Pandas, Scikit-learn, TensorFlow/Keras 등 핵심 라이브러리를 활용하며, AI Hub, 공공데이터포털 등 다양한 제조 분야 공개 데이터셋을 통해 실제 분석 및 모델 학습을 수행한다.

---

## 사전필요지식

- 기본적인 컴퓨터 활용 능력 (파일 관리, 인터넷 검색 등)
- 프로그래밍 경험이 없어도 수강 가능 (파이썬 기초부터 시작)
- 고등학교 수준의 수학 기초 (함수, 그래프 해석 등)

---

## 훈련핵심역량

- 파이썬 기반 데이터 분석 및 시각화 역량
- 통계적 데이터 검증 및 전처리 기법 적용 역량
- 머신러닝·딥러닝 모델 설계 및 학습 역량
- 제조 분야 공개 데이터셋을 활용한 실무형 AI 모델 구축 역량
- AI 모델의 서비스화 및 API 연동 기초 역량

---

## 사후취득지식

- 파이썬 프로그래밍 및 데이터 분석 도구(NumPy, Pandas, Matplotlib) 활용 능력
- 기술통계, 가설검정(t-test) 등 통계적 데이터 분석 능력
- 데이터 전처리(결측치, 이상치, 스케일링, 인코딩) 기법 적용 능력
- Scikit-learn 기반 머신러닝 모델(의사결정트리, 랜덤포레스트 등) 구현 능력
- MLP 등 딥러닝 모델의 구조 이해 및 구현 능력
- Streamlit, FastAPI를 활용한 AI 모델 서비스화 기초 능력

---

## 주교재

- **주교재**:
  - 박해선, 『혼자 공부하는 머신러닝+딥러닝』, 한빛미디어, 2024
  - 오렐리앙 제롱, 『핸즈온 머신러닝 (3판)』, 한빛미디어, 2023

- **부교재/참고자료**:
  - AI Hub (https://aihub.or.kr) 제조 분야 데이터셋
  - 공공데이터포털 (https://data.go.kr) 산업·제조 통계
  - KAMP 스마트공장 데이터셋 (https://kamp.or.kr)
  - TensorFlow/Keras 공식 문서 및 튜토리얼

---

## 제조 분야 활용 데이터셋

| 데이터명 | 출처 | 활용 실습 |
|----------|------|----------|
| AI Hub 제조 공정 품질 데이터 | https://aihub.or.kr | 품질 예측, 이상탐지 |
| 공공데이터포털 산업통계 | https://data.go.kr | 생산량 분석, 시계열 예측 |
| KAMP 스마트공장 데이터셋 | https://kamp.or.kr | 설비 이상감지, 예지보전 |
| 통계청 제조업 동향 | https://kostat.go.kr | 경제지표 분석 |
| UCI Steel Plates Faults | https://archive.ics.uci.edu | 불량 분류 실습 |

---

## 차시별 강의내용

### Part I. AI 윤리와 환경 구축 (1~3차시)

---

#### 차시 1

| 항목 | 내용 |
|------|------|
| **차시명** | AI 활용 윤리 및 보호체계 |
| **학습목표** | - AI 윤리의 기본 원칙과 중요성을 설명한다 |
| | - 데이터 보안 사고의 유형과 예방 방법을 이해한다 |
| | - AI 결과물의 저작권 및 지식재산권 이슈를 파악한다 |
| **학습내용** | - AI 윤리 원칙: 공정성, 투명성, 책임성, 프라이버시 |
| | - 제조 현장 AI 활용 시 발생 가능한 윤리적 문제 사례 |
| | - 기업 데이터 보안: 개인정보보호법, 정보보안 기본 수칙 |
| | - AI 생성물의 저작권 귀속 문제 및 분쟁 사례 |
| **이론/실습** | 이론 |
| **과제/프로젝트** | - |

---

#### 차시 2

| 항목 | 내용 |
|------|------|
| **차시명** | Python 환경 구축과 기초 |
| **학습목표** | - Anaconda와 Jupyter Notebook 환경을 설치하고 실행한다 |
| | - 파이썬 기본 자료형(int, float, str, list, dict)을 활용한다 |
| | - 조건문과 반복문으로 간단한 로직을 구현한다 |
| **학습내용** | - Anaconda 설치 및 가상환경 생성 |
| | - Jupyter Notebook 실행 및 기본 사용법 |
| | - 변수, 자료형, 조건문(if-else), 반복문(for, while) |
| **이론/실습** | 이론 + 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 파이썬 기초
# 변수와 자료형
name = "제조공정"
temperature = 85.5
is_normal = True

# 조건문
if temperature > 90:
    print("경고: 온도 초과")
else:
    print("정상 범위")

# 반복문
for i in range(5):
    print(f"센서 {i+1} 체크 완료")
```

---

#### 차시 3

| 항목 | 내용 |
|------|------|
| **차시명** | 데이터 다루기 기초 (NumPy, Pandas) |
| **학습목표** | - NumPy 배열의 생성과 기본 연산을 수행한다 |
| | - Pandas DataFrame을 생성하고 데이터를 조회한다 |
| | - 제조 데이터 CSV 파일을 불러와 기본 정보를 확인한다 |
| **학습내용** | - NumPy: 배열 생성, 형상 변환, 기본 연산 |
| | - Pandas: Series와 DataFrame, read_csv(), head(), info(), describe() |
| | - 제조 센서 데이터 불러오기 및 탐색 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: NumPy와 Pandas 기초
import numpy as np
import pandas as pd

# NumPy 배열
sensor_values = np.array([23.5, 24.1, 22.8, 25.0, 23.9])
print(f"평균 온도: {sensor_values.mean():.2f}")

# Pandas DataFrame
df = pd.read_csv('manufacturing_data.csv')
print(df.head())
print(df.info())
print(df.describe())
```

---

### Part II. 기초 수리와 데이터 분석 (4~10차시)

---

#### 차시 4

| 항목 | 내용 |
|------|------|
| **차시명** | 기술통계의 시각적 이해 |
| **학습목표** | - 평균, 중앙값, 표준편차의 개념을 코드로 구현하고 시각화한다 |
| | - 각 통계량이 적합한 상황을 판단한다 |
| | - 제조 품질 데이터의 분포를 시각적으로 분석한다 |
| **학습내용** | - 중심경향 측도: 평균(mean), 중앙값(median) |
| | - 산포도: 분산(variance), 표준편차(std), IQR |
| | - 박스플롯과 히스토그램을 통한 데이터 분포 시각화 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 기술통계와 시각화
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 제조 품질 데이터 (예시)
quality_scores = np.random.normal(85, 10, 100)  # 평균 85, 표준편차 10

print(f"평균: {np.mean(quality_scores):.2f}")
print(f"중앙값: {np.median(quality_scores):.2f}")
print(f"표준편차: {np.std(quality_scores):.2f}")

# 시각화
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(quality_scores, bins=20, edgecolor='black')
axes[0].set_title('품질 점수 분포')
axes[1].boxplot(quality_scores)
axes[1].set_title('품질 점수 박스플롯')
plt.tight_layout()
plt.show()
```

---

#### 차시 5

| 항목 | 내용 |
|------|------|
| **차시명** | 확률분포와 AI 예측의 연결 |
| **학습목표** | - 정규분포의 특성과 68-95-99.7 규칙을 설명한다 |
| | - Z-점수(표준화)의 의미를 이해하고 계산한다 |
| | - AI 예측 결과의 신뢰 구간 개념을 파악한다 |
| **학습내용** | - 정규분포 N(μ, σ²): 종 모양 곡선, 평균 중심 대칭 |
| | - 표준정규분포 Z = (X - μ) / σ |
| | - 시뮬레이션을 통한 확률분포 체험 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 정규분포와 표준화
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# 제조 공정 온도 데이터 (평균 85도, 표준편차 5도)
mu, sigma = 85, 5
temperatures = np.random.normal(mu, sigma, 1000)

# 특정 온도의 Z-점수
sample_temp = 95
z_score = (sample_temp - mu) / sigma
print(f"{sample_temp}도의 Z-점수: {z_score:.2f}")

# 이 온도 이상일 확률
prob = 1 - stats.norm.cdf(z_score)
print(f"{sample_temp}도 이상일 확률: {prob:.4f} ({prob*100:.2f}%)")

# 시각화
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)
plt.plot(x, stats.norm.pdf(x, mu, sigma))
plt.axvline(sample_temp, color='r', linestyle='--', label=f'{sample_temp}도')
plt.fill_between(x[x >= sample_temp], stats.norm.pdf(x[x >= sample_temp], mu, sigma), alpha=0.3)
plt.title('공정 온도 정규분포')
plt.legend()
plt.show()
```

---

#### 차시 6

| 항목 | 내용 |
|------|------|
| **차시명** | 가설검정의 직관적 이해 |
| **학습목표** | - 귀무가설과 대립가설의 개념을 구분한다 |
| | - p-value의 의미와 유의수준(α)의 관계를 이해한다 |
| | - 제조 공정 사례로 t-검정을 수행하고 해석한다 |
| **학습내용** | - 가설검정의 논리: 귀무가설 기각 여부 판단 |
| | - t-검정: 두 집단의 평균 비교 |
| | - 제조 현장 적용: 공정 A와 B의 품질 차이 검증 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: t-검정으로 공정 비교
from scipy import stats
import numpy as np

# 공정 A와 B의 품질 점수
process_A = np.array([85, 88, 90, 87, 86, 89, 91, 88])
process_B = np.array([78, 82, 80, 79, 81, 83, 77, 80])

# 독립표본 t-검정
t_stat, p_value = stats.ttest_ind(process_A, process_B)
print(f"t-통계량: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("결론: 두 공정의 품질 점수는 통계적으로 유의미하게 다릅니다.")
else:
    print("결론: 두 공정의 품질 점수 차이가 유의미하지 않습니다.")
```

---

#### 차시 7

| 항목 | 내용 |
|------|------|
| **차시명** | 상관분석과 회귀의 기초 |
| **학습목표** | - 피어슨 상관계수의 의미와 해석 방법을 이해한다 |
| | - 산점도를 통해 변수 간 관계를 시각화한다 |
| | - 단순선형회귀의 원리를 이해하고 적용한다 |
| **학습내용** | - 상관계수 r: -1 ~ +1, 선형 관계의 강도와 방향 |
| | - 제조 공정 변수 간 상관관계 분석 |
| | - 회귀직선 y = wx + b, sklearn LinearRegression |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 상관분석과 선형회귀
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 제조 데이터: 온도와 불량률
temperature = np.array([70, 75, 80, 85, 90, 95, 100]).reshape(-1, 1)
defect_rate = np.array([2.1, 2.5, 3.0, 3.8, 4.5, 5.2, 6.1])

# 상관계수
corr = np.corrcoef(temperature.flatten(), defect_rate)[0, 1]
print(f"상관계수: {corr:.4f}")

# 선형회귀
model = LinearRegression()
model.fit(temperature, defect_rate)
print(f"기울기: {model.coef_[0]:.4f}, 절편: {model.intercept_:.4f}")

# 시각화
plt.scatter(temperature, defect_rate, label='실제 데이터')
plt.plot(temperature, model.predict(temperature), 'r-', label='회귀선')
plt.xlabel('온도 (°C)')
plt.ylabel('불량률 (%)')
plt.legend()
plt.title('온도와 불량률의 관계')
plt.show()
```

---

#### 차시 8

| 항목 | 내용 |
|------|------|
| **차시명** | 데이터 전처리 실무 (1) - 결측치와 이상치 |
| **학습목표** | - 결측치 처리 방법(삭제, 대체)을 상황에 맞게 적용한다 |
| | - IQR 방법으로 이상치를 탐지하고 처리한다 |
| | - 제조 센서 데이터 정제 실습을 수행한다 |
| **학습내용** | - isnull(), dropna(), fillna()를 활용한 결측치 처리 |
| | - 이상치 탐지: IQR(Q1-1.5*IQR ~ Q3+1.5*IQR) |
| | - 제조 센서 데이터의 실제 결측치/이상치 처리 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 결측치 및 이상치 처리
import pandas as pd
import numpy as np

# 제조 센서 데이터 (결측치, 이상치 포함)
df = pd.DataFrame({
    'temperature': [85, 86, np.nan, 88, 150, 87, 86, np.nan],
    'pressure': [100, 102, 101, np.nan, 103, 99, 101, 100],
    'quality': ['양호', '양호', '불량', '양호', '불량', '양호', '양호', '양호']
})

print("원본 데이터:")
print(df)

# 결측치 확인 및 처리
print(f"\n결측치 개수:\n{df.isnull().sum()}")
df_filled = df.copy()
df_filled['temperature'].fillna(df_filled['temperature'].median(), inplace=True)
df_filled['pressure'].fillna(df_filled['pressure'].mean(), inplace=True)

# IQR 기반 이상치 탐지
Q1 = df_filled['temperature'].quantile(0.25)
Q3 = df_filled['temperature'].quantile(0.75)
IQR = Q3 - Q1
outliers = df_filled[(df_filled['temperature'] < Q1 - 1.5*IQR) |
                     (df_filled['temperature'] > Q3 + 1.5*IQR)]
print(f"\n온도 이상치:\n{outliers}")
```

---

#### 차시 9

| 항목 | 내용 |
|------|------|
| **차시명** | 데이터 전처리 실무 (2) - 스케일링과 인코딩 |
| **학습목표** | - 피처 스케일링(정규화, 표준화)의 필요성을 이해한다 |
| | - MinMaxScaler와 StandardScaler를 적절히 선택한다 |
| | - 범주형 변수의 인코딩(Label, One-Hot)을 수행한다 |
| **학습내용** | - 정규화(Min-Max): 0~1 범위로 변환 |
| | - 표준화(Z-score): 평균 0, 표준편차 1로 변환 |
| | - LabelEncoder, pd.get_dummies() 활용 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 스케일링과 인코딩
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder
import pandas as pd
import numpy as np

# 제조 데이터
df = pd.DataFrame({
    'temperature': [85, 90, 75, 100, 80],
    'pressure': [1.0, 1.2, 0.8, 1.5, 0.9],
    'machine_type': ['A', 'B', 'A', 'C', 'B']
})

# 스케일링
scaler = StandardScaler()
df[['temp_scaled', 'pressure_scaled']] = scaler.fit_transform(df[['temperature', 'pressure']])
print("표준화 결과:")
print(df[['temperature', 'temp_scaled', 'pressure', 'pressure_scaled']])

# 원-핫 인코딩
machine_encoded = pd.get_dummies(df['machine_type'], prefix='machine')
print("\n원-핫 인코딩 결과:")
print(machine_encoded)
```

---

#### 차시 10

| 항목 | 내용 |
|------|------|
| **차시명** | 탐색적 데이터 분석(EDA) 종합 |
| **학습목표** | - 제조 품질 데이터에 대한 종합적인 EDA를 수행한다 |
| | - 데이터 시각화를 통해 패턴과 인사이트를 도출한다 |
| | - 분석 결과를 정리하고 해석한다 |
| **학습내용** | - 데이터 개요 파악 및 기술통계 분석 |
| | - 변수별 분포 시각화 (히스토그램, 박스플롯) |
| | - 변수 간 관계 분석 (상관행렬, 산점도 매트릭스) |
| **이론/실습** | 실습 (과제) |
| **과제/프로젝트** | **[실습과제 1]** 제조 품질 데이터 EDA 보고서 작성 |

```python
# 실습 예시: EDA 종합
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 제조 품질 데이터 로드 (예시)
np.random.seed(42)
df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, 200),
    'pressure': np.random.normal(1.0, 0.1, 200),
    'humidity': np.random.normal(60, 10, 200),
    'quality_score': np.random.normal(90, 8, 200)
})

# 기술통계
print("기술통계:")
print(df.describe())

# 상관행렬
print("\n상관행렬:")
print(df.corr())

# 시각화
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# 히스토그램
df['quality_score'].hist(ax=axes[0, 0], bins=20, edgecolor='black')
axes[0, 0].set_title('품질 점수 분포')

# 박스플롯
df.boxplot(column='quality_score', ax=axes[0, 1])
axes[0, 1].set_title('품질 점수 박스플롯')

# 산점도
axes[1, 0].scatter(df['temperature'], df['quality_score'], alpha=0.5)
axes[1, 0].set_xlabel('온도')
axes[1, 0].set_ylabel('품질 점수')
axes[1, 0].set_title('온도 vs 품질 점수')

# 상관행렬 히트맵
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', ax=axes[1, 1])
axes[1, 1].set_title('상관행렬 히트맵')

plt.tight_layout()
plt.show()
```

---

### Part III. 문제 중심 모델링 실습 (11~20차시)

---

#### 차시 11

| 항목 | 내용 |
|------|------|
| **차시명** | 머신러닝 개요와 문제 유형 |
| **학습목표** | - 지도학습, 비지도학습의 개념을 구분한다 |
| | - 분류(Classification)와 회귀(Regression)의 차이를 이해한다 |
| | - 제조 분야에서의 머신러닝 적용 사례를 파악한다 |
| **학습내용** | - 머신러닝의 정의와 학습 유형 |
| | - 분류: 불량/양품 판정, 제품 등급 분류 |
| | - 회귀: 생산량 예측, 품질 점수 예측 |
| | - 제조 AI 적용 사례: 예지보전, 품질 검사, 공정 최적화 |
| **이론/실습** | 이론 + 실습 |
| **과제/프로젝트** | - |

---

#### 차시 12

| 항목 | 내용 |
|------|------|
| **차시명** | 분류 모델 (1): 의사결정트리 |
| **학습목표** | - 의사결정트리의 분할 기준(지니 계수)을 이해한다 |
| | - 트리 구조를 시각화하고 해석한다 |
| | - 제조 불량 분류 모델을 구축한다 |
| **학습내용** | - 의사결정트리의 원리: 정보 이득 기반 분할 |
| | - sklearn DecisionTreeClassifier 활용 |
| | - 트리 시각화 및 해석 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 의사결정트리 분류
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# 데이터 로드 (예시: Iris → 제조 데이터로 대체 가능)
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# 의사결정트리 모델
model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)

print(f"훈련 정확도: {model.score(X_train, y_train):.4f}")
print(f"테스트 정확도: {model.score(X_test, y_test):.4f}")

# 트리 시각화
plt.figure(figsize=(15, 8))
plot_tree(model, feature_names=iris.feature_names,
          class_names=iris.target_names, filled=True)
plt.title('의사결정트리 시각화')
plt.show()
```

---

#### 차시 13

| 항목 | 내용 |
|------|------|
| **차시명** | 분류 모델 (2): 랜덤포레스트 |
| **학습목표** | - 앙상블 학습의 개념을 이해한다 |
| | - 랜덤포레스트가 단일 트리보다 성능이 좋은 이유를 설명한다 |
| | - 특성 중요도(feature importance)를 분석한다 |
| **학습내용** | - 앙상블: 여러 모델의 예측을 결합 |
| | - 랜덤포레스트: 다수의 의사결정트리 + 배깅 |
| | - sklearn RandomForestClassifier 활용 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 랜덤포레스트 분류
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# 제조 품질 분류 데이터 (예시)
np.random.seed(42)
X = np.random.randn(200, 4)  # 4개 특성
y = (X[:, 0] + X[:, 1] > 0).astype(int)  # 불량/양품

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 랜덤포레스트 모델
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

print(f"테스트 정확도: {rf_model.score(X_test, y_test):.4f}")

# 특성 중요도 시각화
feature_names = ['온도', '압력', '습도', '진동']
importances = rf_model.feature_importances_

plt.barh(feature_names, importances)
plt.xlabel('중요도')
plt.title('특성 중요도')
plt.show()
```

---

#### 차시 14

| 항목 | 내용 |
|------|------|
| **차시명** | 회귀 모델: 선형회귀와 다항회귀 |
| **학습목표** | - 선형회귀 모델을 활용하여 수치를 예측한다 |
| | - 다항회귀로 비선형 관계를 모델링한다 |
| | - 잔차 분석을 통해 모델 적합도를 평가한다 |
| **학습내용** | - 다중선형회귀: 여러 특성으로 예측 |
| | - 다항회귀: 비선형 패턴 학습 |
| | - 잔차(residual) 분석 및 시각화 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 생산량 예측 회귀 모델
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# 제조 데이터: 가동시간 → 생산량
hours = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(-1, 1)
production = np.array([50, 95, 160, 210, 270, 310, 370, 400])

# 선형회귀
lr_model = LinearRegression()
lr_model.fit(hours, production)
lr_pred = lr_model.predict(hours)

# 다항회귀 (2차)
poly = PolynomialFeatures(degree=2)
hours_poly = poly.fit_transform(hours)
poly_model = LinearRegression()
poly_model.fit(hours_poly, production)
poly_pred = poly_model.predict(hours_poly)

# 시각화
plt.scatter(hours, production, label='실제 데이터')
plt.plot(hours, lr_pred, 'r-', label='선형회귀')
plt.plot(hours, poly_pred, 'g--', label='다항회귀')
plt.xlabel('가동시간')
plt.ylabel('생산량')
plt.legend()
plt.title('생산량 예측')
plt.show()

print(f"선형회귀 R²: {r2_score(production, lr_pred):.4f}")
print(f"다항회귀 R²: {r2_score(production, poly_pred):.4f}")
```

---

#### 차시 15

| 항목 | 내용 |
|------|------|
| **차시명** | 모델 평가와 교차검증 |
| **학습목표** | - 분류/회귀 모델의 평가 지표를 이해하고 계산한다 |
| | - K-Fold 교차검증의 필요성과 방법을 익힌다 |
| | - 과적합과 과소적합을 진단한다 |
| **학습내용** | - 분류 평가: 정확도, 정밀도, 재현율, F1-score |
| | - 회귀 평가: MSE, RMSE, MAE, R² |
| | - cross_val_score()를 활용한 K-Fold 교차검증 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 모델 평가와 교차검증
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.datasets import load_breast_cancer

# 데이터 로드
data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

# 모델 학습
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 평가
print("분류 보고서:")
print(classification_report(y_test, y_pred, target_names=data.target_names))

# 교차검증
cv_scores = cross_val_score(model, data.data, data.target, cv=5)
print(f"\n5-Fold 교차검증 평균 정확도: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})")
```

---

#### 차시 16

| 항목 | 내용 |
|------|------|
| **차시명** | 하이퍼파라미터 튜닝 |
| **학습목표** | - 하이퍼파라미터의 개념과 영향을 이해한다 |
| | - GridSearchCV를 활용하여 최적 파라미터를 탐색한다 |
| | - 과적합 방지 전략을 적용한다 |
| **학습내용** | - 하이퍼파라미터 vs 학습 파라미터 |
| | - GridSearchCV, RandomizedSearchCV |
| | - 정규화, 조기 종료 등 과적합 방지 기법 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: GridSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_breast_cancer

# 데이터 로드
data = load_breast_cancer()

# 파라미터 그리드
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 10, None],
    'min_samples_split': [2, 5, 10]
}

# GridSearchCV
rf = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(data.data, data.target)

print(f"최적 파라미터: {grid_search.best_params_}")
print(f"최고 정확도: {grid_search.best_score_:.4f}")
```

---

#### 차시 17

| 항목 | 내용 |
|------|------|
| **차시명** | 시계열 데이터 기초 |
| **학습목표** | - 시계열 데이터의 구성요소(추세, 계절성, 잔차)를 파악한다 |
| | - 시계열 데이터의 전처리와 시각화를 수행한다 |
| | - 이동평균을 통해 추세를 분석한다 |
| **학습내용** | - 시계열 데이터 특성: 시간 순서 의존성 |
| | - pd.to_datetime(), resample() 활용 |
| | - 이동평균(rolling), 차분(diff) |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 시계열 데이터 분석
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 제조 생산량 시계열 데이터 (예시)
dates = pd.date_range('2024-01-01', periods=100, freq='D')
np.random.seed(42)
production = 1000 + np.arange(100) * 5 + np.random.randn(100) * 50  # 추세 + 노이즈

ts = pd.Series(production, index=dates)

# 시각화
fig, axes = plt.subplots(3, 1, figsize=(12, 8))

# 원본 데이터
axes[0].plot(ts)
axes[0].set_title('일별 생산량')

# 7일 이동평균
ts_ma = ts.rolling(window=7).mean()
axes[1].plot(ts, alpha=0.5, label='원본')
axes[1].plot(ts_ma, 'r-', label='7일 이동평균')
axes[1].legend()
axes[1].set_title('이동평균')

# 차분 (추세 제거)
ts_diff = ts.diff()
axes[2].plot(ts_diff)
axes[2].set_title('1차 차분')

plt.tight_layout()
plt.show()
```

---

#### 차시 18

| 항목 | 내용 |
|------|------|
| **차시명** | 시계열 예측 모델 |
| **학습목표** | - 시계열 예측의 기본 접근법을 이해한다 |
| | - 과거 데이터를 활용한 예측 모델을 구축한다 |
| | - 설비 가동률 예측 실습을 수행한다 |
| **학습내용** | - 시계열 예측의 기본 개념 |
| | - 슬라이딩 윈도우 기반 특성 생성 |
| | - sklearn 모델을 활용한 시계열 예측 |
| **이론/실습** | 실습 (과제) |
| **과제/프로젝트** | **[실습과제 2]** 제조 생산량 시계열 예측 모델 구축 |

```python
# 실습 예시: 시계열 예측
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# 시계열 데이터 생성
np.random.seed(42)
n = 200
data = 100 + np.arange(n) * 0.5 + np.random.randn(n) * 10

# 슬라이딩 윈도우 특성 생성 (lag features)
def create_features(data, lookback=5):
    X, y = [], []
    for i in range(lookback, len(data)):
        X.append(data[i-lookback:i])
        y.append(data[i])
    return np.array(X), np.array(y)

X, y = create_features(data, lookback=5)

# 학습/테스트 분할 (시계열: 순서 유지)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# 모델 학습 및 예측
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RMSE: {rmse:.4f}")
```

---

#### 차시 19

| 항목 | 내용 |
|------|------|
| **차시명** | 딥러닝 입문: 신경망 기초 |
| **학습목표** | - 퍼셉트론과 다층 신경망의 구조를 이해한다 |
| | - 활성화 함수(ReLU, Sigmoid)의 역할을 설명한다 |
| | - Keras를 활용하여 간단한 신경망을 구성한다 |
| **학습내용** | - 퍼셉트론: 가중합 → 활성화 → 출력 |
| | - 다층 퍼셉트론(MLP): 은닉층의 역할 |
| | - Keras Sequential 모델 구성 |
| **이론/실습** | 이론 + 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: Keras 신경망 기초
import tensorflow as tf
from tensorflow import keras
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 데이터 준비
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# MLP 모델 구성
model = keras.Sequential([
    keras.layers.Dense(16, activation='relu', input_shape=(4,)),
    keras.layers.Dense(8, activation='relu'),
    keras.layers.Dense(3, activation='softmax')
])

# 컴파일
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 모델 요약
model.summary()

# 학습
history = model.fit(X_train, y_train, epochs=50, batch_size=16,
                    validation_split=0.2, verbose=0)

# 평가
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\n테스트 정확도: {test_acc:.4f}")
```

---

#### 차시 20

| 항목 | 내용 |
|------|------|
| **차시명** | 딥러닝 실습: MLP로 품질 예측 |
| **학습목표** | - 제조 품질 데이터에 MLP 모델을 적용한다 |
| | - 학습 곡선을 분석하여 모델 성능을 진단한다 |
| | - 과적합 방지 기법(Dropout)을 적용한다 |
| **학습내용** | - 제조 품질 분류를 위한 MLP 모델 설계 |
| | - 학습 곡선(loss, accuracy) 시각화 |
| | - Dropout을 활용한 정규화 |
| **이론/실습** | 실습 (과제) |
| **과제/프로젝트** | **[실습과제 3]** 제조 품질 분류 MLP 모델 구축 및 평가 보고서 |

```python
# 실습 예시: 제조 품질 분류 MLP
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# 제조 품질 데이터 (예시)
np.random.seed(42)
X = np.random.randn(500, 10)  # 10개 센서 특성
y = (X[:, 0] + X[:, 1] + X[:, 2] > 0).astype(int)  # 불량/양품

# 학습/테스트 분할
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# MLP 모델 (Dropout 포함)
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(10,)),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 학습
history = model.fit(X_train, y_train, epochs=50, batch_size=32,
                    validation_split=0.2, verbose=0)

# 학습 곡선 시각화
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].plot(history.history['loss'], label='Train')
axes[0].plot(history.history['val_loss'], label='Validation')
axes[0].set_title('손실 곡선')
axes[0].legend()

axes[1].plot(history.history['accuracy'], label='Train')
axes[1].plot(history.history['val_accuracy'], label='Validation')
axes[1].set_title('정확도 곡선')
axes[1].legend()
plt.show()

print(f"테스트 정확도: {model.evaluate(X_test, y_test, verbose=0)[1]:.4f}")
```

---

### Part IV. 서비스화와 종합 실습 (21~25차시)

---

#### 차시 21

| 항목 | 내용 |
|------|------|
| **차시명** | AI API의 이해와 활용 |
| **학습목표** | - REST API의 기본 개념(GET, POST)을 이해한다 |
| | - 외부 AI API를 호출하고 응답을 처리한다 |
| | - API 활용 시 인증과 보안 고려사항을 파악한다 |
| **학습내용** | - REST API 개념: 요청(Request), 응답(Response) |
| | - requests 라이브러리를 활용한 API 호출 |
| | - API 키 관리 및 보안 |
| **이론/실습** | 이론 + 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: REST API 호출
import requests

# 공공 API 호출 예시 (날씨 API)
# 실제 사용 시 API 키 필요
url = "https://api.example.com/data"
params = {
    "serviceKey": "YOUR_API_KEY",
    "numOfRows": 10,
    "dataType": "JSON"
}

# GET 요청
# response = requests.get(url, params=params)
# data = response.json()
# print(data)

# POST 요청 예시
post_url = "https://api.example.com/predict"
payload = {
    "temperature": 85,
    "pressure": 1.2,
    "humidity": 60
}

# response = requests.post(post_url, json=payload)
# result = response.json()
# print(result)

print("API 호출 예시 - 실제 실행 시 유효한 API 키 필요")
```

---

#### 차시 22

| 항목 | 내용 |
|------|------|
| **차시명** | Streamlit으로 웹앱 만들기 |
| **학습목표** | - Streamlit의 기본 구조와 실행 방법을 이해한다 |
| | - 학습된 모델을 Streamlit 앱에 연동한다 |
| | - 사용자 입력을 받아 예측 결과를 표시한다 |
| **학습내용** | - Streamlit 설치 및 기본 컴포넌트 |
| | - st.slider(), st.button(), st.file_uploader() |
| | - 저장된 모델 로드 및 예측 결과 시각화 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: Streamlit 앱 (app.py)
import streamlit as st
import joblib
import numpy as np

st.title('제조 품질 예측 앱')
st.write('센서 데이터를 입력하면 품질을 예측합니다.')

# 사용자 입력
col1, col2 = st.columns(2)
with col1:
    temperature = st.slider('온도 (°C)', 60, 100, 85)
    pressure = st.slider('압력 (bar)', 0.5, 2.0, 1.0)
with col2:
    humidity = st.slider('습도 (%)', 30, 80, 60)
    vibration = st.slider('진동 (mm/s)', 0.0, 5.0, 1.0)

# 예측 버튼
if st.button('품질 예측'):
    # 모델 로드 (실제 사용 시)
    # model = joblib.load('quality_model.joblib')
    # features = np.array([[temperature, pressure, humidity, vibration]])
    # prediction = model.predict(features)

    # 예시 결과
    st.success('예측 결과: 양품 (신뢰도 95.2%)')
    st.balloons()

# 실행: streamlit run app.py
```

---

#### 차시 23

| 항목 | 내용 |
|------|------|
| **차시명** | FastAPI로 모델 서빙하기 |
| **학습목표** | - FastAPI로 간단한 API 서버를 구축한다 |
| | - 학습된 모델을 API로 서빙하는 방법을 익힌다 |
| | - Pydantic을 활용한 데이터 검증을 수행한다 |
| **학습내용** | - FastAPI 설치 및 기본 구조 |
| | - Pydantic 모델을 활용한 요청/응답 정의 |
| | - /predict 엔드포인트 구현 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: FastAPI 모델 서빙 (main.py)
from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI(title="제조 품질 예측 API")

class SensorInput(BaseModel):
    temperature: float
    pressure: float
    humidity: float
    vibration: float

class PredictionOutput(BaseModel):
    prediction: str
    confidence: float

# 모델 로드 (서버 시작 시 1회)
# model = joblib.load('quality_model.joblib')

@app.get("/")
def root():
    return {"message": "제조 품질 예측 API입니다."}

@app.post("/predict", response_model=PredictionOutput)
def predict(data: SensorInput):
    features = np.array([[
        data.temperature, data.pressure,
        data.humidity, data.vibration
    ]])
    # prediction = model.predict(features)
    # proba = model.predict_proba(features).max()

    # 예시 응답
    return PredictionOutput(prediction="양품", confidence=0.952)

# 실행: uvicorn main:app --reload
```

---

#### 차시 24

| 항목 | 내용 |
|------|------|
| **차시명** | 모델 해석과 특성 중요도 분석 |
| **학습목표** | - sklearn의 feature_importances_를 활용하여 모델 예측에 영향을 미치는 특성을 파악한다 |
| | - 특성 중요도를 시각화하고 제조 현장에서의 의미를 해석한다 |
| | - 모델 예측 결과를 비전문가에게 설명하는 방법을 익힌다 |
| **학습내용** | - 왜 모델 해석이 필요한가? (제조 현장 의사결정, 품질 개선 포인트 도출) |
| | - 트리 기반 모델의 feature_importances_ 활용 |
| | - 특성 중요도 막대 그래프 시각화 |
| | - 상관관계 vs 인과관계 주의점 |
| **이론/실습** | 실습 |
| **과제/프로젝트** | - |

```python
# 실습 예시: 특성 중요도 분석
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# 제조 품질 데이터 (예시)
np.random.seed(42)
n_samples = 500
df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n_samples),
    'pressure': np.random.normal(1.0, 0.1, n_samples),
    'humidity': np.random.normal(60, 10, n_samples),
    'vibration': np.random.normal(1.0, 0.3, n_samples),
    'cycle_time': np.random.normal(30, 5, n_samples)
})

# 품질 레이블 생성 (온도와 압력이 주요 영향 요인)
df['quality'] = ((df['temperature'] > 88) | (df['pressure'] > 1.15)).astype(int)

# 모델 학습
X = df.drop('quality', axis=1)
y = df['quality']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print(f"모델 정확도: {model.score(X_test, y_test):.4f}")

# 특성 중요도 추출 및 시각화
feature_importance = pd.DataFrame({
    '특성': X.columns,
    '중요도': model.feature_importances_
}).sort_values('중요도', ascending=True)

plt.figure(figsize=(10, 6))
plt.barh(feature_importance['특성'], feature_importance['중요도'], color='steelblue')
plt.xlabel('중요도')
plt.title('제조 품질에 영향을 미치는 주요 특성')
plt.tight_layout()
plt.show()

# 해석
print("\n품질에 가장 큰 영향을 미치는 상위 3개 특성:")
for _, row in feature_importance.tail(3).iterrows():
    print(f"  - {row['특성']}: {row['중요도']:.3f}")

print("\n해석: 온도와 압력이 품질에 가장 큰 영향을 미칩니다.")
print("      → 공정 개선 시 이 두 변수를 우선적으로 관리해야 합니다.")
```

---

#### 차시 25

| 항목 | 내용 |
|------|------|
| **차시명** | 모델 저장과 실무 배포 준비 |
| **학습목표** | - pickle/joblib을 사용하여 학습된 모델을 저장하고 불러온다 |
| | - 실무 배포 시 고려해야 할 핵심 사항을 이해한다 |
| | - 지속적인 모델 운영의 필요성과 다음 학습 방향을 파악한다 |
| **학습내용** | - 모델 저장의 필요성 (매번 재학습 vs 저장된 모델 사용) |
| | - pickle vs joblib 비교 (sklearn 모델에는 joblib 권장) |
| | - 저장된 모델을 FastAPI/Streamlit에서 불러오기 |
| | - 실무 배포 체크리스트 (입력 검증, 버전 관리, 로깅) |
| **이론/실습** | 실습 |
| **과제/프로젝트** | **[최종 과제]** 제조 품질 예측 웹 서비스 구축 (EDA → 모델링 → 서비스화) |

```python
# 실습 예시: 모델 저장과 로드
import joblib
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# 모델 학습 (예시)
np.random.seed(42)
X_train = np.random.randn(100, 4)
y_train = (X_train[:, 0] + X_train[:, 1] > 0).astype(int)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 모델 저장 (버전 정보 포함)
model_version = datetime.now().strftime("%Y%m%d_%H%M")
model_filename = f"quality_model_v{model_version}.joblib"
joblib.dump(model, model_filename)
print(f"모델 저장 완료: {model_filename}")

# 모델 메타정보 저장
model_info = {
    'version': model_version,
    'accuracy': model.score(X_train, y_train),
    'features': ['temperature', 'pressure', 'humidity', 'vibration'],
    'created_at': datetime.now().isoformat(),
    'model_type': 'RandomForestClassifier',
    'n_estimators': 100
}
joblib.dump(model_info, f"model_info_v{model_version}.joblib")
print(f"메타정보 저장 완료")

# 모델 불러오기
loaded_model = joblib.load(model_filename)
loaded_info = joblib.load(f"model_info_v{model_version}.joblib")

print(f"\n불러온 모델 정보:")
print(f"  - 버전: {loaded_info['version']}")
print(f"  - 정확도: {loaded_info['accuracy']:.4f}")
print(f"  - 특성: {loaded_info['features']}")

# 새 데이터로 예측
new_data = np.array([[85, 1.0, 60, 1.2]])
prediction = loaded_model.predict(new_data)
print(f"\n예측 결과: {'불량' if prediction[0] == 1 else '양품'}")
```

**실무 배포 체크리스트:**

| 항목 | 설명 |
|------|------|
| 입력 데이터 검증 | 타입, 범위, 결측치 확인 |
| 모델 버전 관리 | 파일명에 날짜/버전 포함 |
| 예측 로깅 | 입력, 출력, 타임스탬프 기록 |
| 에러 처리 | 예외 상황 대비 (try-except) |
| 성능 모니터링 | 정확도 변화 추적 |

---

## 실습과제 및 프로젝트 정리

### 실습과제 목록

| 차시 | 과제명 | 내용 |
|------|--------|------|
| 10 | 실습과제 1 | 제조 품질 데이터 EDA 보고서 작성 |
| 18 | 실습과제 2 | 제조 생산량 시계열 예측 모델 구축 |
| 20 | 실습과제 3 | 제조 품질 분류 MLP 모델 구축 및 평가 보고서 |
| 25 | 최종 과제 | 제조 품질 예측 웹 서비스 구축 (EDA → 모델링 → 서비스화) |

### 최종 과제

**주제**: 제조 품질 예측 웹 서비스 구축

**평가 기준**:

| 항목 | 비중 | 내용 |
|------|------|------|
| 문제 정의 | 10% | 데이터 기반 문제 설정의 명확성 |
| 데이터 분석 | 20% | 전처리 및 EDA의 적절성 |
| 모델링 | 30% | 모델 선택, 학습, 튜닝의 타당성 |
| 모델 평가 | 20% | 평가 지표 해석 및 개선 방향 도출 |
| 서비스 구현 | 10% | Streamlit/FastAPI 활용 |
| 보고서 | 10% | 분석 결과 정리 및 비즈니스 해석 |

---

## 편성기준 충족 현황

| 편성기준 | 해당 차시 | 내용 |
|----------|----------|------|
| **[1] 기초 수리 (AI Math)** | 4~7차시 | 기술통계, 확률분포, 가설검정, 상관/회귀 - 개념 중심 |
| **[2] 기술적 요소 (Python, SQL)** | 2~3, 8~10차시 | Python 기초, 데이터 분석, 전처리 - 문제 해결 수단 |
| **[3] 문제 중심 훈련** | 전 과정 | 제조 분야 실제 데이터 활용, 품질 예측 문제 |
| **[4] 단계별 실습 학습** | 10~25차시 | 문제정의→데이터분석→모델링→평가→서비스화 |
| **AI 활용 윤리 및 보호체계** | 1차시 | AI 윤리, 데이터 보안, 저작권 (필수) |

---

*본 강의계획서는 AI 기초체력훈련(Pre AI-Campus) 심사 기준에 맞추어 작성되었습니다.*
