---
marp: true
theme: default
paginate: true
header: '제조 AI 과정 | 1차시'
footer: '제조데이터를 활용한 AI 이해와 예측 모델 구축'
style: |
  section {
    font-family: 'Malgun Gothic', 'Apple SD Gothic Neo', sans-serif;
    background-color: #f8fafc;
  }
  h1 { color: #1e40af; font-size: 2.2em; }
  h2 { color: #2563eb; font-size: 1.6em; }
  h3 { color: #3b82f6; }
  .highlight { background-color: #fef3c7; padding: 4px 12px; border-radius: 6px; }
  .important { background-color: #fee2e2; padding: 4px 12px; border-radius: 6px; }
  .success { background-color: #dcfce7; padding: 4px 12px; border-radius: 6px; }
  table { font-size: 0.85em; }
  code { background-color: #e2e8f0; padding: 2px 6px; border-radius: 4px; }
  blockquote { border-left: 4px solid #3b82f6; padding-left: 16px; color: #64748b; }
---

# AI 활용 윤리와 데이터 보호

## 1차시 | Part I. AI 윤리와 환경 구축

**제조 현장에서 AI를 올바르게 활용하기 위한 첫걸음**

---

# 학습목표

이 차시를 마치면 다음을 할 수 있습니다:

1. **AI 윤리 4대 원칙**을 설명하고 제조 현장에 적용할 수 있다
2. **데이터 보안 사고 유형**과 구체적인 예방 방법을 이해한다
3. **AI 생성물의 저작권 문제**와 법적 쟁점을 파악한다
4. **윤리 점검 체크리스트**를 활용하여 AI 프로젝트를 검토할 수 있다

---

# 오늘의 진행 순서

## 이론 중심 강의 (25-30분)

| 순서 | 내용 | 시간 |
|------|------|------|
| 1 | AI 시대와 제조업의 변화 | 5분 |
| 2 | AI 윤리 4대 원칙 심화 | 10분 |
| 3 | 데이터 보안 사고 사례 분석 | 8분 |
| 4 | AI 저작권과 법적 이슈 | 5분 |
| 5 | 정리 및 Q&A | 2분 |

---

# PART 1. AI 시대와 제조업의 변화

## 왜 지금 AI 윤리를 배워야 하는가?

---

# AI의 역사 - 간략한 타임라인

```
1956년: AI 용어 탄생 (다트머스 회의)
    ↓
1980년대: 전문가 시스템의 시대
    ↓
1997년: Deep Blue, 체스 세계 챔피언 격파
    ↓
2016년: AlphaGo, 이세돌 9단 격파
    ↓
2022년: ChatGPT 등장, 생성형 AI 대중화
    ↓
2024년: 제조업 AI 본격 도입
```

---

# 제조업 AI 도입 현황 (2024년)

## 국내 제조업 AI 도입 통계

| 구분 | 비율 |
|------|------|
| AI 도입 완료 | 23% |
| 도입 진행 중 | 35% |
| 도입 검토 중 | 28% |
| 계획 없음 | 14% |

> 출처: 한국산업기술진흥원 (2024)

**58%의 기업이 AI 도입 중이거나 완료!**

---

# 제조 현장의 AI 활용 분야

## 실제 적용 사례

| 분야 | AI 활용 사례 | 기대 효과 |
|------|-------------|----------|
| **품질 관리** | 불량품 자동 검출, 품질 예측 | 불량률 30% 감소 |
| **설비 관리** | 고장 예측, 예지 정비 | 다운타임 50% 감소 |
| **공정 최적화** | 최적 파라미터 자동 설정 | 생산성 20% 향상 |
| **수요 예측** | AI 기반 생산 계획 | 재고 비용 25% 절감 |
| **에너지 관리** | 소비 패턴 분석, 최적화 | 에너지 15% 절감 |

---

# 왜 AI 윤리가 중요한가?

## AI의 양면성

```
       AI의 혜택                    AI의 위험
    ┌─────────────┐            ┌─────────────┐
    │ 생산성 향상   │            │ 편향된 판단   │
    │ 품질 개선    │     VS     │ 개인정보 침해 │
    │ 비용 절감    │            │ 책임 소재 불명 │
    │ 안전 강화    │            │ 일자리 위협   │
    └─────────────┘            └─────────────┘
```

> **"강력한 도구에는 그에 맞는 책임이 따른다"**

---

# PART 2. AI 윤리 4대 원칙 심화

## 공정성, 투명성, 책임성, 안전성

---

# AI 윤리 4대 원칙 개요

```
    ┌─────────────────────────────────────┐
    │          AI 윤리 4대 원칙            │
    ├─────────┬─────────┬─────────┬───────┤
    │ 공정성   │ 투명성   │ 책임성   │ 안전성 │
    │Fairness │Transparency│Accountability│Safety│
    └─────────┴─────────┴─────────┴───────┘
```

국내: 과학기술정보통신부 「인공지능 윤리기준」 (2020)
국제: EU AI Act, OECD AI 원칙

---

# 원칙 1: 공정성 (Fairness)

## 정의
> AI 시스템은 **모든 사용자를 공평하게** 대우하고,
> **특정 그룹에 불리한 결과**를 내지 않아야 함

## 핵심 질문
- 학습 데이터에 편향이 있지 않은가?
- 특정 조건에서만 잘 작동하지 않는가?
- 결과가 특정 그룹에 불이익을 주지 않는가?

---

# 공정성 위반 사례 1: 채용 AI

## Amazon 채용 AI 사례 (2018년)

| 항목 | 내용 |
|------|------|
| **문제** | 여성 지원자에게 불리한 점수 부여 |
| **원인** | 과거 10년간 남성 위주 채용 데이터로 학습 |
| **결과** | 시스템 전면 폐기 |
| **교훈** | 역사적 편향이 AI에 그대로 반영됨 |

> "과거의 편견이 미래의 불공정으로 이어진다"

---

# 공정성 위반 사례 2: 제조 품질 AI

## 제조 현장 가상 시나리오

```
상황: 품질 검사 AI가 A라인 제품만 더 엄격하게 판정

원인 분석:
┌─────────────────────────────────────┐
│ A라인 학습 데이터: 10,000건 (불량 다수) │
│ B라인 학습 데이터: 2,000건 (불량 적음)  │
└─────────────────────────────────────┘

결과:
• A라인 불량률 15% → 실제보다 과다 판정
• B라인 불량률 3% → 실제보다 과소 판정
• A라인 작업자 부당한 불이익
```

---

# 공정성 확보 방안

## 실무 체크리스트

| 단계 | 점검 항목 |
|------|----------|
| **데이터 수집** | 모든 라인/시간대에서 균등 수집 |
| **데이터 분석** | 편향 여부 통계적 검증 |
| **모델 학습** | 공정성 지표 모니터링 |
| **배포 후** | 정기적 편향 감사 (Bias Audit) |

### 공정성 지표 예시
- Demographic Parity: 집단별 예측 비율 동일
- Equal Opportunity: 집단별 정답률 동일

---

# 원칙 2: 투명성 (Transparency)

## 정의
> AI의 **의사결정 과정이 설명 가능**해야 하며,
> **왜 그런 결과가 나왔는지** 이해할 수 있어야 함

## 핵심 질문
- AI가 왜 이런 결정을 내렸는지 설명할 수 있는가?
- 사용자가 결과를 이해하고 신뢰할 수 있는가?
- 오류 발생 시 원인 파악이 가능한가?

---

# 투명성의 두 가지 측면

```
┌─────────────────────────────────────────────┐
│               투명성                         │
├─────────────────────┬───────────────────────┤
│   설명 가능성        │    해석 가능성         │
│  (Explainability)   │  (Interpretability)    │
├─────────────────────┼───────────────────────┤
│ 개별 예측의 근거 설명 │ 모델 전체 동작 이해    │
│ "왜 이 제품이 불량?"  │ "어떤 변수가 중요?"    │
│ LIME, SHAP 등       │ 특성 중요도, 규칙 추출  │
└─────────────────────┴───────────────────────┘
```

---

# 투명성 부족 사례: 블랙박스 AI

## 나쁜 예 vs 좋은 예

**나쁜 예 (블랙박스)**
```
AI: "이 제품은 불량입니다."
작업자: "왜요? 어디가 문제인가요?"
AI: "..."
```

**좋은 예 (설명 가능 AI)**
```
AI: "이 제품은 불량입니다."
    - 이유: 표면 스크래치 0.7mm 검출 (기준: 0.5mm 이하)
    - 위치: 우측 상단 모서리
    - 신뢰도: 94%
작업자: "아, 저 부분을 재검사해봐야겠네요."
```

---

# 투명성 확보를 위한 XAI 기법

## Explainable AI (설명 가능 AI)

| 기법 | 설명 | 활용 |
|------|------|------|
| **LIME** | 개별 예측에 대한 국소 설명 | 왜 이 제품이 불량인가? |
| **SHAP** | 특성별 기여도 계산 | 어떤 센서값이 영향? |
| **Attention** | 모델이 집중한 영역 시각화 | 이미지의 어디를 봤나? |
| **규칙 추출** | 의사결정 규칙 추출 | IF 온도 > 90 THEN... |

> 24차시에서 상세히 다룰 예정

---

# 원칙 3: 책임성 (Accountability)

## 정의
> AI 시스템의 결과에 대한 **책임 주체가 명확**해야 하며,
> 문제 발생 시 **대응 체계**가 갖춰져야 함

## 핵심 질문
- AI 오류 시 누가 책임지는가?
- 피해 발생 시 보상 체계가 있는가?
- 수동 점검/개입 프로세스가 있는가?

---

# 책임 소재의 복잡성

## AI가 잘못 판단해서 불량품이 출하되었다면?

| 후보 | 책임 여부 | 조건 |
|------|----------|------|
| **AI 개발사** | O | 모델 오류, 학습 결함 |
| **도입 기업** | O | 운영 관리 책임, 검증 미흡 |
| **담당 부서** | O | 모니터링 소홀, 경고 무시 |
| **담당자** | △ | 고의/과실 여부에 따라 |
| **AI 자체** | X | 법적 주체 아님 |

> 현행법상 AI는 책임 주체가 될 수 없음

---

# 책임성 사례: 자율주행 사고

## 우버 자율주행 사망 사고 (2018년)

| 항목 | 내용 |
|------|------|
| **사고 개요** | 보행자 사망, 세계 첫 자율주행 사망 사고 |
| **원인** | AI가 보행자를 인식했으나 시스템이 급정거 비활성화 |
| **책임 판결** | 안전 운전원에게 과실 치사 인정 |
| **교훈** | 인간 감독의 중요성, 비상 대응 체계 필수 |

---

# 제조 현장의 책임성 확보

## 책임성 프레임워크

```
┌─────────────────────────────────────────────┐
│           AI 책임성 체계                      │
├─────────────┬─────────────┬─────────────────┤
│ 설계 단계    │ 운영 단계    │ 사고 대응 단계   │
├─────────────┼─────────────┼─────────────────┤
│ 윤리 검토 위원회│ 모니터링 담당자│ 사고 조사팀    │
│ 안전 기준 설정│ 정기 감사   │ 보상 체계       │
│ 문서화      │ 로그 기록   │ 개선 조치       │
└─────────────┴─────────────┴─────────────────┘
```

---

# 원칙 4: 안전성 / 프라이버시

## 정의
> **개인정보 및 기업 비밀**을 보호하고,
> 데이터 수집/저장/활용 시 **적법한 동의**를 받아야 함

## 핵심 질문
- 개인정보 수집에 동의를 받았는가?
- 기업 비밀이 외부로 유출될 위험은 없는가?
- 데이터 접근 권한이 적절히 관리되는가?

---

# 안전성 위반 사례: 작업자 감시 AI

## 가상 시나리오

```
상황: 작업자 동작 분석 AI 도입
┌─────────────────────────────────────────────┐
│ 수집 데이터:                                  │
│ • 작업 동작 패턴                              │
│ • 휴식 시간 및 빈도                           │
│ • 화장실 이용 횟수                            │
│ • 동료와의 대화 시간                          │
└─────────────────────────────────────────────┘

문제:
• 동의 없이 인사 평가에 활용
• 개인 행동 패턴 무단 수집
→ 심각한 프라이버시 침해!
```

---

# PART 3. 데이터 보안 사고 사례

## 실제 발생한 사고에서 배우기

---

# 데이터 보안 사고 개요

## 제조업 데이터 유출 유형

| 유형 | 비율 | 주요 원인 |
|------|------|----------|
| **내부자 유출** | 45% | 퇴직자, 불만 직원 |
| **외부 해킹** | 30% | 랜섬웨어, 피싱 |
| **실수에 의한 유출** | 20% | 이메일 오발송, 설정 오류 |
| **협력사 경유** | 5% | 공급망 취약점 |

> 내부자에 의한 유출이 가장 많음!

---

# 사례 1: S전자 ChatGPT 유출 사건

## 2023년 삼성전자 사내 데이터 유출

| 항목 | 내용 |
|------|------|
| **사건 개요** | 직원들이 ChatGPT에 반도체 소스코드 입력 |
| **유출 데이터** | 반도체 설비 측정 데이터, 소스코드 |
| **문제점** | OpenAI 서버로 데이터 전송, 학습 데이터로 활용 가능성 |
| **대응** | 사내 ChatGPT 사용 전면 금지 (이후 자체 AI 개발) |
| **교훈** | 외부 AI 서비스에 기밀 정보 입력 금지 |

---

# 사례 2: L에너지 배터리 기술 유출

## 2022년 LG에너지솔루션 기술 유출 시도

| 항목 | 내용 |
|------|------|
| **사건 개요** | 퇴직 예정 직원이 핵심 기술 자료 유출 시도 |
| **유출 시도** | 배터리 제조 공정 데이터, 설계 도면 |
| **적발 경위** | DLP(Data Loss Prevention) 시스템 탐지 |
| **처리 결과** | 형사 고발, 실형 선고 |
| **교훈** | 퇴직자 보안 관리 강화, DLP 시스템 필수 |

---

# 사례 3: H자동차 협력사 경유 유출

## 2021년 현대자동차 설계 도면 유출

| 항목 | 내용 |
|------|------|
| **사건 개요** | 1차 협력사 직원이 설계 도면 유출 |
| **유출 경로** | 협력사 → 경쟁사 (중국) |
| **유출 데이터** | 신차 설계 도면, 부품 사양서 |
| **피해 규모** | 수천억 원 추정 |
| **교훈** | 공급망 전체 보안 관리 필요 |

---

# 사례 4: 랜섬웨어 공격

## 2021년 미국 Colonial Pipeline 사태

| 항목 | 내용 |
|------|------|
| **사건 개요** | 미국 최대 송유관 회사 랜섬웨어 감염 |
| **피해** | 6일간 운영 중단, 동부 연료 공급 대란 |
| **몸값** | 440만 달러 (약 50억 원) 지불 |
| **원인** | 단일 비밀번호 유출 (VPN 계정) |
| **제조업 교훈** | OT(운영기술) 보안의 중요성 |

---

# 사례 5: 외부 AI 서비스 위험

## ChatGPT/Claude 등 생성형 AI 위험

```
┌─────────────────────────────────────────────┐
│           외부 AI 서비스 데이터 흐름           │
├─────────────────────────────────────────────┤
│                                             │
│  사용자 → [프롬프트 입력] → 외부 AI 서버      │
│                ↓                            │
│         서버에 데이터 저장                    │
│                ↓                            │
│         모델 학습에 활용 가능                 │
│                ↓                            │
│         다른 사용자에게 노출 위험             │
│                                             │
└─────────────────────────────────────────────┘
```

---

# 데이터 보안 3대 영역

## 체계적 보안 관리

| 영역 | 보호 대상 | 핵심 조치 |
|------|----------|----------|
| **개인정보** | 작업자 정보, 연락처 | 비식별화, 동의 획득 |
| **기업 비밀** | 공정 데이터, 파라미터 | 암호화, 접근 제한 |
| **접근 권한** | 시스템 전체 | 최소 권한 원칙 |

---

# 개인정보 보호 방안

## 비식별화 기법

| 기법 | 설명 | 예시 |
|------|------|------|
| **가명처리** | 식별자를 가명으로 대체 | 홍길동 → ID_001 |
| **총계처리** | 개별값을 집계값으로 | 개인 실적 → 팀 평균 |
| **데이터 삭제** | 불필요 정보 제거 | 주민번호 삭제 |
| **범주화** | 구체적 값을 범주로 | 32세 → 30대 |
| **데이터 마스킹** | 일부 문자 가림 | 010-****-5678 |

---

# 기업 비밀 보호 방안

## 보안 등급 분류

| 등급 | 대상 | 보호 조치 |
|------|------|----------|
| **최고 (Confidential)** | 핵심 기술, 고객 정보 | 분리 저장, 2중 인증 |
| **높음 (Secret)** | 설비 파라미터, 공정 조건 | 암호화, 접근 로그 |
| **중간 (Internal)** | 센서 데이터, 품질 결과 | 접근 권한 관리 |
| **낮음 (Public)** | 일반 문서, 매뉴얼 | 기본 보안 |

---

# 접근 권한 관리

## 최소 권한 원칙 (Principle of Least Privilege)

```
┌─────────────────────────────────────────────┐
│            최소 권한 원칙                     │
├─────────────────────────────────────────────┤
│                                             │
│  "업무 수행에 필요한 최소한의 권한만 부여"      │
│                                             │
│  ✓ 필요한 데이터만 접근                      │
│  ✓ 필요한 기간만 권한 부여                   │
│  ✓ 정기적 권한 검토 및 회수                  │
│                                             │
└─────────────────────────────────────────────┘
```

---

# PART 4. AI 저작권과 법적 이슈

## AI 생성물의 권리는 누구에게?

---

# AI 저작권의 핵심 쟁점

## 법적으로 불명확한 영역

| 쟁점 | 현황 |
|------|------|
| **AI 생성물 저작권** | 인간 창작물로 볼 수 있는가? |
| **학습 데이터 저작권** | 저작물을 학습에 사용해도 되는가? |
| **AI 출력물 유사성** | 기존 저작물과 유사하면? |

> 현재 대부분 국가에서 AI 자체는 저작권 주체가 될 수 없음

---

# AI 저작권 분쟁 사례

## 1. Getty Images vs Stability AI (2023)

| 항목 | 내용 |
|------|------|
| **원고** | Getty Images (세계 최대 이미지 에이전시) |
| **피고** | Stability AI (Stable Diffusion 개발사) |
| **쟁점** | 1,200만 장 저작권 이미지 무단 학습 |
| **현황** | 소송 진행 중 |

---

# AI 저작권 분쟁 사례

## 2. New York Times vs OpenAI (2023)

| 항목 | 내용 |
|------|------|
| **원고** | New York Times |
| **피고** | OpenAI, Microsoft |
| **쟁점** | 수백만 개 기사 무단 학습 |
| **청구액** | 수십억 달러 |

---

# 오픈소스 라이선스 종류

## 코드 생성 AI 사용 시 주의

| 라이선스 | 특징 | 주의사항 |
|----------|------|---------|
| **MIT** | 자유롭게 사용 가능 | 저작권 표시 필요 |
| **Apache 2.0** | 상업적 사용 가능 | 특허권 명시 |
| **GPL** | 소스 공개 의무 | 파생작품도 GPL |
| **LGPL** | 라이브러리 사용 가능 | 수정 시 공개 |

> AI가 생성한 코드에 어떤 라이선스가 적용되는지 확인 필수!

---

# 제조업 AI 법적 고려사항

## 체크리스트

- [ ] AI 학습에 사용된 데이터의 저작권 확인
- [ ] AI 생성 코드의 라이선스 검토
- [ ] 개인정보보호법 준수 여부 확인
- [ ] 산업기술보호법 적용 여부 검토
- [ ] AI 오류 시 책임 소재 명확화

---

# PART 5. 실무 가이드라인

## AI 프로젝트 시작 전 점검

---

# AI 프로젝트 윤리 점검 체크리스트

## 공정성 점검

- [ ] 학습 데이터에 특정 라인/시간대 편향이 없는가?
- [ ] 모든 생산 조건에서 공평하게 예측하는가?
- [ ] 특정 그룹에 불이익을 주지 않는가?

## 투명성 점검

- [ ] 예측 결과의 근거를 설명할 수 있는가?
- [ ] 작업자가 결과를 이해할 수 있는가?
- [ ] 오류 시 원인 파악이 가능한가?

---

# AI 프로젝트 윤리 점검 체크리스트 (계속)

## 책임성 점검

- [ ] AI 오류 시 책임자가 지정되어 있는가?
- [ ] 수동 점검 프로세스가 있는가?
- [ ] 비상 대응 계획이 수립되어 있는가?

## 안전성 점검

- [ ] 개인정보 수집에 동의를 받았는가?
- [ ] 기업 비밀 보호 조치가 되어 있는가?
- [ ] 접근 권한이 최소 원칙에 따라 설정되어 있는가?

---

# 외부 AI 서비스 사용 가이드

## 안전한 사용 (O)

- 일반적인 Python 문법 질문
- 공개된 알고리즘 설명 요청
- 오픈소스 라이브러리 사용법
- 일반적인 코딩 패턴 질문

## 위험한 사용 (X)

- 실제 센서 데이터 입력
- 품질 기준 파라미터 공유
- 설비 운영 코드 검토 요청
- 고객사 관련 정보 언급

---

# 핵심 요약

## 1차시 정리

### AI 윤리 4대 원칙
- **공정성**: 편향 없는 공평한 판단
- **투명성**: 설명 가능한 AI
- **책임성**: 명확한 책임 주체
- **안전성**: 개인정보/기업비밀 보호

### 데이터 보안 3대 영역
- 개인정보 보호 / 기업 비밀 보호 / 접근 권한 관리

### 실무 적용
- 체크리스트로 프로젝트 시작 전 점검

---

# 토론 주제

## 생각해볼 문제

1. **공정성 딜레마**: 품질 AI가 A라인 불량률을 높게 예측한다면,
   이것은 AI의 편향인가, 실제 문제의 발견인가?

2. **투명성 한계**: 모든 AI 판단을 설명해야 한다면,
   성능이 낮아지는 것은 감수해야 하는가?

3. **책임성 경계**: AI 오류로 인한 손실이 발생했을 때,
   어디까지가 회사 책임이고 개인 책임인가?

---

# 퀴즈

## 오늘 배운 내용 확인

1. AI 윤리 4대 원칙에 해당하지 **않는** 것은?
   a) 공정성  b) 투명성  c) 효율성  d) 책임성

2. 2023년 S전자 데이터 유출 사고의 원인은?
   a) 해킹  b) 내부자 유출  c) 외부 AI 서비스 사용  d) 랜섬웨어

3. 최소 권한 원칙의 의미는?
   a) 권한을 최소한으로 줄여라
   b) 업무에 필요한 최소 권한만 부여하라
   c) 관리자 권한을 최소화하라
   d) 외부 접근을 최소화하라

---

# 다음 차시 예고

## 2차시: Python 시작하기

### 학습 내용
- Anaconda 설치 및 환경 구성
- Jupyter Notebook 사용법
- Python 기본 문법 (변수, 조건문, 반복문)
- 첫 번째 Python 프로그램 작성

### 준비물
- 개인 PC (Windows 10 이상 권장)
- 인터넷 연결 환경
- 관리자 권한 (소프트웨어 설치용)

---

# 참고 자료

## 추가 학습 리소스

| 자료 | 출처 |
|------|------|
| 인공지능 윤리기준 | 과학기술정보통신부 (2020) |
| 개인정보보호법 해설서 | 개인정보보호위원회 |
| EU AI Act | 유럽연합 |
| OECD AI 원칙 | OECD |

---

# 감사합니다

## 1차시: AI 활용 윤리와 데이터 보호

**제조데이터를 활용한 AI 이해와 예측 모델 구축**

> "기술만큼이나 윤리 의식이 중요합니다"

수고하셨습니다!
