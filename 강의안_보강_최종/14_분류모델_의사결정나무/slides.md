---
marp: true
theme: default
paginate: true
header: 'ì œì¡° AI ê³¼ì • | 13ì°¨ì‹œ'
footer: 'ê³µê³µë°ì´í„°ë¥¼ í™œìš©í•œ AI ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•'
style: |
  section {
    font-family: 'Malgun Gothic', 'Apple SD Gothic Neo', sans-serif;
    background-color: #f8fafc;
  }
  h1 { color: #1e40af; font-size: 2.2em; }
  h2 { color: #2563eb; font-size: 1.6em; }
  h3 { color: #3b82f6; }
  code { background-color: #e2e8f0; padding: 2px 6px; border-radius: 4px; }
  pre { background-color: #1e293b; color: #e2e8f0; }
  table { font-size: 0.9em; }
  .highlight { background-color: #fef3c7; padding: 10px; border-radius: 8px; }
  .important { background-color: #fee2e2; padding: 10px; border-radius: 8px; }
  .tip { background-color: #d1fae5; padding: 10px; border-radius: 8px; }
---

# ë¶„ë¥˜ ëª¨ë¸ (1) - ì˜ì‚¬ê²°ì •ë‚˜ë¬´

## 13ì°¨ì‹œ | Part III. ë¬¸ì œ ì¤‘ì‹¬ ëª¨ë¸ë§ ì‹¤ìŠµ

**ì²« ë²ˆì§¸ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤!**

---

# ì§€ë‚œ ì‹œê°„ ë³µìŠµ

## 11ì°¨ì‹œì—ì„œ ë°°ìš´ ê²ƒ

- **ë¨¸ì‹ ëŸ¬ë‹**: ë°ì´í„°ì—ì„œ íŒ¨í„´ í•™ìŠµ
- **ì§€ë„í•™ìŠµ**: ì •ë‹µ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ
- **ë¶„ë¥˜**: ë²”ì£¼ ì˜ˆì¸¡ / **íšŒê·€**: ìˆ«ì ì˜ˆì¸¡
- **sklearn íŒ¨í„´**: fit â†’ predict â†’ score

<div class="tip">

ì˜¤ëŠ˜ì€ ì²« ë²ˆì§¸ ë¶„ë¥˜ ëª¨ë¸, **ì˜ì‚¬ê²°ì •ë‚˜ë¬´**ë¥¼ ë°°ì›ë‹ˆë‹¤!

</div>

---

# í•™ìŠµ ëª©í‘œ

ì´ ì°¨ì‹œë¥¼ ë§ˆì¹˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

| ë²ˆí˜¸ | í•™ìŠµ ëª©í‘œ |
|:----:|----------|
| 1 | **ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ì›ë¦¬**ë¥¼ ì´í•´í•œë‹¤ |
| 2 | **DecisionTreeClassifier**ë¥¼ ì‚¬ìš©í•œë‹¤ |
| 3 | **íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ê³  í•´ì„**í•œë‹¤ |

---

# ì˜¤ëŠ˜ì˜ í•™ìŠµ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Part 1    â”‚    â”‚   Part 2    â”‚    â”‚   Part 3    â”‚
â”‚  ì˜ì‚¬ê²°ì •   â”‚ â†’  â”‚   sklearn   â”‚ â†’  â”‚  ì‹œê°í™”ì™€   â”‚
â”‚  ë‚˜ë¬´ ì›ë¦¬  â”‚    â”‚    ì‹¤ìŠµ     â”‚    â”‚    í•´ì„     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ì§ˆë¬¸ ê¸°ë°˜        ëª¨ë¸ í•™ìŠµ/ì˜ˆì¸¡      íŠ¸ë¦¬ êµ¬ì¡°
   ë¶„ê¸° êµ¬ì¡°        ì£¼ìš” íŒŒë¼ë¯¸í„°       íŠ¹ì„± ì¤‘ìš”ë„
```

---

<!-- _class: lead -->

# Part 1

## ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ì›ë¦¬

---

# ì˜ì‚¬ê²°ì •ë‚˜ë¬´ë€?

## Decision Tree

> ì§ˆë¬¸ì„ í†µí•´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
> "ìŠ¤ë¬´ê³ ê°œ"ì™€ ê°™ì€ ì›ë¦¬!

### í•µì‹¬ ì•„ì´ë””ì–´
- ì˜ˆ/ì•„ë‹ˆì˜¤ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë˜ì§
- ì§ˆë¬¸ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë‚˜ëˆ”
- ìµœì¢…ì ìœ¼ë¡œ í´ë˜ìŠ¤(ë²”ì£¼) ê²°ì •

---

# ì¼ìƒ ì† ì˜ì‚¬ê²°ì •ë‚˜ë¬´

## ê³¼ì¼ ë¶„ë¥˜ ì˜ˆì‹œ

```
                "ë¹¨ê°„ìƒ‰ì¸ê°€ìš”?"
                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           ì˜ˆ                  ì•„ë‹ˆì˜¤
            â”‚                    â”‚
    "ë™ê·¸ë€ê°€ìš”?"           "ë…¸ë€ìƒ‰ì¸ê°€ìš”?"
          â”‚                      â”‚
      â”Œâ”€â”€â”€â”´â”€â”€â”€â”              â”Œâ”€â”€â”€â”´â”€â”€â”€â”
     ì˜ˆ       ì•„ë‹ˆì˜¤         ì˜ˆ       ì•„ë‹ˆì˜¤
      â”‚         â”‚            â”‚         â”‚
   ì‚¬ê³¼      ë”¸ê¸°        ë°”ë‚˜ë‚˜      í¬ë„
```

---

# ì œì¡° í˜„ì¥ ì˜ˆì‹œ

## ë¶ˆëŸ‰í’ˆ ë¶„ë¥˜

```
                "ì˜¨ë„ > 85ë„?"
                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           ì˜ˆ                  ì•„ë‹ˆì˜¤
            â”‚                    â”‚
    "ìŠµë„ > 60%?"              ì •ìƒ
          â”‚
      â”Œâ”€â”€â”€â”´â”€â”€â”€â”
     ì˜ˆ       ì•„ë‹ˆì˜¤
      â”‚         â”‚
   ë¶ˆëŸ‰       ì •ìƒ
```

---

# ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ìš©ì–´

## íŠ¸ë¦¬ êµ¬ì¡°

```
        [ë£¨íŠ¸ ë…¸ë“œ]        â† ì²« ë²ˆì§¸ ì§ˆë¬¸ (ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±)
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
[ë‚´ë¶€ ë…¸ë“œ]    [ë‚´ë¶€ ë…¸ë“œ]  â† ì¶”ê°€ ì§ˆë¬¸
    â”‚              â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
[ë¦¬í”„]  [ë¦¬í”„] [ë¦¬í”„] [ë¦¬í”„]  â† ìµœì¢… ê²°ì • (í´ë˜ìŠ¤)
```

- **ë£¨íŠ¸ ë…¸ë“œ**: ì²« ë²ˆì§¸ ë¶„ê¸°ì 
- **ë‚´ë¶€ ë…¸ë“œ**: ì¤‘ê°„ ë¶„ê¸°ì 
- **ë¦¬í”„ ë…¸ë“œ**: ìµœì¢… ê²°ì •

---

# ì–´ë–¤ ì§ˆë¬¸ì´ ì¢‹ì€ ì§ˆë¬¸ì¸ê°€?

## ë¶ˆìˆœë„ (Impurity)

> ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ "ì„ì—¬ìˆëŠ”ì§€" ì¸¡ì •

### ì¢‹ì€ ë¶„í• 
- ë¶„í•  í›„ ê° ê·¸ë£¹ì´ **í•œ í´ë˜ìŠ¤ë¡œ í†µì¼**
- ë¶ˆìˆœë„ê°€ **ë‚®ì•„ì§**

### ë‚˜ìœ ë¶„í• 
- ë¶„í•  í›„ì—ë„ í´ë˜ìŠ¤ê°€ **ì„ì—¬ìˆìŒ**
- ë¶ˆìˆœë„ê°€ **ì—¬ì „íˆ ë†’ìŒ**

---

# ë¶ˆìˆœë„ ì˜ˆì‹œ

## ì–´ë–¤ ë¶„í• ì´ ë” ì¢‹ì„ê¹Œìš”?

```
[ë¶„í•  ì „]
ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸ”´ğŸ”´ğŸ”´ğŸ”´ (50% ì •ìƒ, 50% ë¶ˆëŸ‰)

[ë¶„í•  A - ì¢‹ì€ ë¶„í• ]
ì™¼ìª½: ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢    ì˜¤ë¥¸ìª½: ğŸ”´ğŸ”´ğŸ”´ğŸ”´
      (100% ì •ìƒ)         (100% ë¶ˆëŸ‰)

[ë¶„í•  B - ë‚˜ìœ ë¶„í• ]
ì™¼ìª½: ğŸŸ¢ğŸŸ¢ğŸ”´ğŸ”´    ì˜¤ë¥¸ìª½: ğŸŸ¢ğŸŸ¢ğŸ”´ğŸ”´
      (50% ì •ìƒ)          (50% ì •ìƒ)
```

**ë¶„í•  A**ê°€ ë¶ˆìˆœë„ë¥¼ ë” ë§ì´ ë‚®ì·„ìŠµë‹ˆë‹¤!

---

# ì§€ë‹ˆ ë¶ˆìˆœë„ (Gini Impurity)

## ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ë¶ˆìˆœë„ ì¸¡ì •

$$Gini = 1 - \sum_{i=1}^{C} p_i^2$$

### ì§ê´€ì  ì´í•´
- Gini = 0: ì™„ì „íˆ ìˆœìˆ˜ (í•œ í´ë˜ìŠ¤ë§Œ ìˆìŒ)
- Gini = 0.5: ê°€ì¥ ë¶ˆìˆœ (ì´ì§„ ë¶„ë¥˜ì—ì„œ 50:50)

---

# ì§€ë‹ˆ ë¶ˆìˆœë„ ê³„ì‚° ì˜ˆì‹œ

## ë‘ ê²½ìš° ë¹„êµ

### Case A: [ì •ìƒ 10ê°œ, ë¶ˆëŸ‰ 0ê°œ]
```
Gini = 1 - (10/10)Â² - (0/10)Â² = 0
â†’ ì™„ì „íˆ ìˆœìˆ˜!
```

### Case B: [ì •ìƒ 5ê°œ, ë¶ˆëŸ‰ 5ê°œ]
```
Gini = 1 - (5/10)Â² - (5/10)Â² = 0.5
â†’ ê°€ì¥ ë¶ˆìˆœ!
```

### Case C: [ì •ìƒ 8ê°œ, ë¶ˆëŸ‰ 2ê°œ]
```
Gini = 1 - (8/10)Â² - (2/10)Â² = 0.32
```

---

# ì •ë³´ ì´ë“ (Information Gain)

## ë¶„í• ë¡œ ì–¼ë§ˆë‚˜ ìˆœìˆ˜í•´ì¡Œë‚˜?

```
ì •ë³´ ì´ë“ = ë¶€ëª¨ ë¶ˆìˆœë„ - ìì‹ ë¶ˆìˆœë„ì˜ ê°€ì¤‘ í‰ê· 
```

### íŠ¸ë¦¬ í•™ìŠµ ê³¼ì •
1. ëª¨ë“  íŠ¹ì„±, ëª¨ë“  ë¶„í• ì  ê²€í† 
2. **ì •ë³´ ì´ë“ì´ ê°€ì¥ í°** ë¶„í•  ì„ íƒ
3. ë°˜ë³µí•˜ì—¬ íŠ¸ë¦¬ ì„±ì¥

---

# íŠ¸ë¦¬ í•™ìŠµ ê³¼ì •

## ë‹¨ê³„ë³„ ì„¤ëª…

```
[1ë‹¨ê³„] ì „ì²´ ë°ì´í„°
        ëª¨ë“  íŠ¹ì„± ê²€í†  â†’ "ì˜¨ë„ > 85" ì„ íƒ (ì •ë³´ ì´ë“ ìµœëŒ€)

[2ë‹¨ê³„] ì™¼ìª½ ë…¸ë“œ (ì˜¨ë„ > 85)
        ë‚¨ì€ íŠ¹ì„± ê²€í†  â†’ "ìŠµë„ > 60" ì„ íƒ

[3ë‹¨ê³„] ì˜¤ë¥¸ìª½ ë…¸ë“œ (ì˜¨ë„ â‰¤ 85)
        ì´ë¯¸ ì¶©ë¶„íˆ ìˆœìˆ˜ â†’ ë¶„í•  ì¤‘ë‹¨

... ë°˜ë³µ ...
```

---

# ê³¼ëŒ€ì í•© ë¬¸ì œ

## íŠ¸ë¦¬ê°€ ë„ˆë¬´ ê¹Šì–´ì§€ë©´?

<div class="important">

### ê³¼ëŒ€ì í•© (Overfitting)
- í•™ìŠµ ë°ì´í„°ì— **ë„ˆë¬´ ë§ì¶¤**
- ìƒˆ ë°ì´í„°ì— **ì¼ë°˜í™” ì‹¤íŒ¨**
- ë…¸ì´ì¦ˆê¹Œì§€ í•™ìŠµ

</div>

### í•´ê²°ì±…
- íŠ¸ë¦¬ ê¹Šì´ ì œí•œ (`max_depth`)
- ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ì„¤ì • (`min_samples_split`)
- ê°€ì§€ì¹˜ê¸° (Pruning)

---

# ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì¥ë‹¨ì 

## ì •ë¦¬

| ì¥ì  | ë‹¨ì  |
|------|------|
| ì§ê´€ì , í•´ì„ ìš©ì´ | ê³¼ëŒ€ì í•© ì‰¬ì›€ |
| ì „ì²˜ë¦¬ ë¶ˆí•„ìš” | ë¶ˆì•ˆì • (ë°ì´í„° ë³€í™”ì— ë¯¼ê°) |
| íŠ¹ì„± ì¤‘ìš”ë„ ì œê³µ | ë‹¨ì¼ íŠ¸ë¦¬ ì„±ëŠ¥ í•œê³„ |
| ë²”ì£¼í˜•/ìˆ˜ì¹˜í˜• ëª¨ë‘ ì²˜ë¦¬ | ì¶•ì— í‰í–‰í•œ ë¶„í• ë§Œ ê°€ëŠ¥ |

---

<!-- _class: lead -->

# Part 2

## sklearnìœ¼ë¡œ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‹¤ìŠµ

---

# DecisionTreeClassifier

## sklearn í´ë˜ìŠ¤

```python
from sklearn.tree import DecisionTreeClassifier

# ëª¨ë¸ ìƒì„±
model = DecisionTreeClassifier(
    criterion='gini',      # ë¶ˆìˆœë„ ì¸¡ì • (gini ë˜ëŠ” entropy)
    max_depth=None,        # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´
    min_samples_split=2,   # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    random_state=42        # ì¬í˜„ì„±
)
```

---

# ì£¼ìš” íŒŒë¼ë¯¸í„°

## ê³¼ëŒ€ì í•© ë°©ì§€ìš©

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¸°ë³¸ê°’ |
|----------|------|--------|
| `max_depth` | íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ | None (ì œí•œ ì—†ìŒ) |
| `min_samples_split` | ë¶„í• ì— í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œ | 2 |
| `min_samples_leaf` | ë¦¬í”„ì— í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œ | 1 |
| `max_features` | ë¶„í•  ì‹œ ê³ ë ¤í•  ìµœëŒ€ íŠ¹ì„± ìˆ˜ | None (ì „ì²´) |

---

# max_depthì˜ ì˜í–¥

## ê¹Šì´ì— ë”°ë¥¸ ê²°ì • ê²½ê³„

```
max_depth=1          max_depth=3          max_depth=10
(ê³¼ì†Œì í•©)           (ì ì ˆ)               (ê³¼ëŒ€ì í•©)

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”¬â”€â”€â”€â”          â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”
  â”‚   A   â”‚          â”‚ A â”‚   â”‚          â”‚Aâ”‚Bâ”‚Aâ”‚Bâ”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”¤ B â”‚          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¤
  â”‚   B   â”‚          â”‚ B â”‚   â”‚          â”‚Bâ”‚Aâ”‚Bâ”‚Aâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”´â”€â”€â”€â”˜          â””â”€â”´â”€â”´â”€â”´â”€â”˜

ë‹¨ìˆœ               ì ì ˆí•œ ë³µì¡ë„        ë„ˆë¬´ ë³µì¡
```

---

# ì‹¤ìŠµ ë°ì´í„° ìƒì„±

## ì œì¡° ë¶ˆëŸ‰ ë¶„ë¥˜ ë°ì´í„°

```python
import numpy as np
import pandas as pd

np.random.seed(42)
n = 500

df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n),
    'humidity': np.random.normal(50, 10, n),
    'speed': np.random.normal(100, 15, n),
    'pressure': np.random.normal(1.0, 0.1, n),
})

# ë¶ˆëŸ‰ ì—¬ë¶€ (ì˜¨ë„, ìŠµë„ì— ì˜í–¥)
defect_prob = 0.1 + 0.03*(df['temperature']-80) + 0.01*(df['humidity']-45)
df['defect'] = (np.random.random(n) < defect_prob).astype(int)
```

---

# ë°ì´í„° ì¤€ë¹„

## íŠ¹ì„±/íƒ€ê²Ÿ ë¶„ë¦¬ ë° í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 

```python
from sklearn.model_selection import train_test_split

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
X = df[['temperature', 'humidity', 'speed', 'pressure']]
y = df['defect']

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
)

print(f"í•™ìŠµ: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
```

---

# ëª¨ë¸ í•™ìŠµ

## fit ë©”ì„œë“œ

```python
from sklearn.tree import DecisionTreeClassifier

# ëª¨ë¸ ìƒì„± (ê¹Šì´ ì œí•œ)
model = DecisionTreeClassifier(
    max_depth=5,
    random_state=42
)

# í•™ìŠµ
model.fit(X_train, y_train)

print("í•™ìŠµ ì™„ë£Œ!")
print(f"íŠ¸ë¦¬ ê¹Šì´: {model.get_depth()}")
print(f"ë¦¬í”„ ë…¸ë“œ ìˆ˜: {model.get_n_leaves()}")
```

---

# ì˜ˆì¸¡

## predict ë©”ì„œë“œ

```python
# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í™•ë¥  ì˜ˆì¸¡ (ê° í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ )
y_proba = model.predict_proba(X_test)

print("ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 10ê°œ):")
print(f"ì‹¤ì œ: {list(y_test[:10])}")
print(f"ì˜ˆì¸¡: {list(y_pred[:10])}")

print("\ní™•ë¥  ì˜ˆì¸¡ (ì²˜ìŒ 5ê°œ):")
for i in range(5):
    print(f"  ìƒ˜í”Œ {i+1}: ì •ìƒ {y_proba[i][0]:.1%}, ë¶ˆëŸ‰ {y_proba[i][1]:.1%}")
```

---

# í‰ê°€

## ì •í™•ë„ì™€ í˜¼ë™ í–‰ë ¬

```python
from sklearn.metrics import accuracy_score, confusion_matrix

# ì •í™•ë„
accuracy = model.score(X_test, y_test)
print(f"ì •í™•ë„: {accuracy:.1%}")

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(y_test, y_pred)
print("\ní˜¼ë™ í–‰ë ¬:")
print(f"           ì˜ˆì¸¡: ì •ìƒ  ë¶ˆëŸ‰")
print(f"ì‹¤ì œ ì •ìƒ: {cm[0,0]:6}  {cm[0,1]:4}")
print(f"ì‹¤ì œ ë¶ˆëŸ‰: {cm[1,0]:6}  {cm[1,1]:4}")
```

---

# max_depth ì‹¤í—˜

## ê¹Šì´ë³„ ì„±ëŠ¥ ë¹„êµ

```python
# ë‹¤ì–‘í•œ ê¹Šì´ í…ŒìŠ¤íŠ¸
depths = [1, 2, 3, 5, 10, None]

for depth in depths:
    model = DecisionTreeClassifier(max_depth=depth, random_state=42)
    model.fit(X_train, y_train)

    train_acc = model.score(X_train, y_train)
    test_acc = model.score(X_test, y_test)

    depth_str = str(depth) if depth else "None"
    print(f"ê¹Šì´ {depth_str:>4}: í•™ìŠµ {train_acc:.1%}, í…ŒìŠ¤íŠ¸ {test_acc:.1%}")
```

---

# max_depth ì‹¤í—˜ ê²°ê³¼

## ê³¼ëŒ€ì í•© ê´€ì°°

```
ê¹Šì´    1: í•™ìŠµ 85.5%, í…ŒìŠ¤íŠ¸ 84.0%  â† ê³¼ì†Œì í•©
ê¹Šì´    2: í•™ìŠµ 87.3%, í…ŒìŠ¤íŠ¸ 86.0%
ê¹Šì´    3: í•™ìŠµ 89.0%, í…ŒìŠ¤íŠ¸ 87.0%  â† ì ì ˆ
ê¹Šì´    5: í•™ìŠµ 92.5%, í…ŒìŠ¤íŠ¸ 86.0%
ê¹Šì´   10: í•™ìŠµ 98.0%, í…ŒìŠ¤íŠ¸ 82.0%  â† ê³¼ëŒ€ì í•© ì‹œì‘
ê¹Šì´ None: í•™ìŠµ 100%, í…ŒìŠ¤íŠ¸ 78.0%  â† ì‹¬í•œ ê³¼ëŒ€ì í•©
```

<div class="tip">

í•™ìŠµ ì •í™•ë„ì™€ í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì°¨ì´ê°€ í¬ë©´ **ê³¼ëŒ€ì í•©**!

</div>

---

<!-- _class: lead -->

# Part 3

## íŠ¸ë¦¬ ì‹œê°í™”ì™€ í•´ì„

---

# íŠ¸ë¦¬ ì‹œê°í™”

## plot_tree í•¨ìˆ˜

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(
    model,
    feature_names=['ì˜¨ë„', 'ìŠµë„', 'ì†ë„', 'ì••ë ¥'],
    class_names=['ì •ìƒ', 'ë¶ˆëŸ‰'],
    filled=True,        # ìƒ‰ìƒ ì±„ìš°ê¸°
    rounded=True,       # ëª¨ì„œë¦¬ ë‘¥ê¸€ê²Œ
    fontsize=10
)
plt.title("ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‹œê°í™”")
plt.savefig('decision_tree.png', dpi=150)
plt.show()
```

---

# íŠ¸ë¦¬ ë…¸ë“œ í•´ì„

## ë…¸ë“œ ì •ë³´ ì½ê¸°

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ì˜¨ë„ <= 87.5   â”‚  â† ë¶„í•  ì¡°ê±´
        â”‚  gini = 0.42    â”‚  â† ë¶ˆìˆœë„
        â”‚  samples = 400  â”‚  â† ìƒ˜í”Œ ìˆ˜
        â”‚  value = [320, 80]â”‚  â† í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜
        â”‚  class = ì •ìƒ    â”‚  â† ë‹¤ìˆ˜ í´ë˜ìŠ¤
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# í…ìŠ¤íŠ¸ë¡œ íŠ¸ë¦¬ ë³´ê¸°

## export_text í•¨ìˆ˜

```python
from sklearn.tree import export_text

tree_rules = export_text(
    model,
    feature_names=['temperature', 'humidity', 'speed', 'pressure']
)
print(tree_rules)
```

ì¶œë ¥ ì˜ˆì‹œ:
```
|--- temperature <= 87.50
|   |--- humidity <= 55.00
|   |   |--- class: ì •ìƒ
|   |--- humidity > 55.00
|   |   |--- temperature <= 84.50
|   |   |   |--- class: ì •ìƒ
|   |   |--- temperature > 84.50
|   |   |   |--- class: ë¶ˆëŸ‰
|--- temperature > 87.50
|   |--- class: ë¶ˆëŸ‰
```

---

# íŠ¹ì„± ì¤‘ìš”ë„

## feature_importances_

```python
# íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
importances = model.feature_importances_
feature_names = ['temperature', 'humidity', 'speed', 'pressure']

# ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
sorted_idx = np.argsort(importances)[::-1]

print("íŠ¹ì„± ì¤‘ìš”ë„:")
for idx in sorted_idx:
    print(f"  {feature_names[idx]}: {importances[idx]:.3f}")
```

---

# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”

## ë§‰ëŒ€ ê·¸ë˜í”„

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.barh(range(len(importances)), importances[sorted_idx])
plt.yticks(range(len(importances)),
           [feature_names[i] for i in sorted_idx])
plt.xlabel('íŠ¹ì„± ì¤‘ìš”ë„')
plt.title('ì˜ì‚¬ê²°ì •ë‚˜ë¬´ - íŠ¹ì„± ì¤‘ìš”ë„')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=150)
plt.show()
```

---

# íŠ¹ì„± ì¤‘ìš”ë„ í•´ì„

## ì‹¤ë¬´ í™œìš©

```
íŠ¹ì„± ì¤‘ìš”ë„:
  temperature: 0.650  â† ê°€ì¥ ì¤‘ìš”!
  humidity:    0.280
  pressure:    0.050
  speed:       0.020
```

### ì¸ì‚¬ì´íŠ¸
- **ì˜¨ë„**ê°€ ë¶ˆëŸ‰ íŒì •ì— ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†Œ
- **ìŠµë„**ë„ ìœ ì˜ë¯¸í•œ ì˜í–¥
- ì†ë„ì™€ ì••ë ¥ì€ ì˜í–¥ì´ ì‘ìŒ

â†’ ì˜¨ë„ ê´€ë¦¬ì— **ì§‘ì¤‘ íˆ¬ì** ê¶Œì¥

---

# ê²°ì • ê²½ê³„ ì‹œê°í™”

## 2ê°œ íŠ¹ì„±ìœ¼ë¡œ ì‹œê°í™”

```python
from sklearn.tree import DecisionTreeClassifier

# 2ê°œ íŠ¹ì„±ë§Œ ì„ íƒ
X_2d = X_train[['temperature', 'humidity']]
model_2d = DecisionTreeClassifier(max_depth=4, random_state=42)
model_2d.fit(X_2d, y_train)

# ê²°ì • ê²½ê³„ ê·¸ë¦¬ê¸°
xx, yy = np.meshgrid(
    np.linspace(X_2d['temperature'].min()-2, X_2d['temperature'].max()+2, 200),
    np.linspace(X_2d['humidity'].min()-5, X_2d['humidity'].max()+5, 200)
)
Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
```

---

# ê²°ì • ê²½ê³„ ì‹œê°í™” ê²°ê³¼

## ì¶•ì— í‰í–‰í•œ ë¶„í• 

```
     ìŠµë„
      â†‘
   80 â”¼â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ë¶ˆëŸ‰ â”‚             â”‚
   60 â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¤
      â”‚     â”‚ ë¶ˆëŸ‰ â”‚      â”‚
   40 â”¼  ì •ìƒâ”‚      â”‚ ì •ìƒ â”‚
      â”‚     â”‚      â”‚      â”‚
   20 â”¼â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ì˜¨ë„
          75    85    95
```

ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” **ì¶•ì— í‰í–‰í•œ ì„ **ìœ¼ë¡œë§Œ ë¶„í• í•©ë‹ˆë‹¤.

---

<!-- _class: lead -->

# ì‹¤ìŠµí¸

## ì œì¡° ë¶ˆëŸ‰ ë¶„ë¥˜ í”„ë¡œì íŠ¸

---

# ì‹¤ìŠµ ëª©í‘œ

## ì™„ì „í•œ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸

1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
2. íŠ¹ì„±/íƒ€ê²Ÿ ë¶„ë¦¬
3. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
4. ì˜ì‚¬ê²°ì •ë‚˜ë¬´ í•™ìŠµ
5. í‰ê°€ ë° í•´ì„
6. ìµœì  ê¹Šì´ ì°¾ê¸°

---

# ì‹¤ìŠµ 1: ë°ì´í„° íƒìƒ‰

## ê¸°ë³¸ í†µê³„ í™•ì¸

```python
import pandas as pd
import numpy as np

# ë°ì´í„° ìƒì„± (ë˜ëŠ” ë¡œë“œ)
np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n),
    'humidity': np.random.normal(50, 10, n),
    'speed': np.random.normal(100, 15, n),
    'pressure': np.random.normal(1.0, 0.1, n),
})
defect_prob = 0.1 + 0.03*(df['temperature']-80) + 0.01*(df['humidity']-45)
df['defect'] = (np.random.random(n) < defect_prob).astype(int)

print(df.describe())
print(f"\në¶ˆëŸ‰ë¥ : {df['defect'].mean():.1%}")
```

---

# ì‹¤ìŠµ 2: ë°ì´í„° ë¶„í• 

## 80:20 ë¶„í• 

```python
from sklearn.model_selection import train_test_split

X = df[['temperature', 'humidity', 'speed', 'pressure']]
y = df['defect']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"í•™ìŠµ ì„¸íŠ¸: {len(X_train)}ê°œ")
print(f"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(X_test)}ê°œ")
print(f"í•™ìŠµ ë¶ˆëŸ‰ë¥ : {y_train.mean():.1%}")
print(f"í…ŒìŠ¤íŠ¸ ë¶ˆëŸ‰ë¥ : {y_test.mean():.1%}")
```

---

# ì‹¤ìŠµ 3: ëª¨ë¸ í•™ìŠµ

## ê¸°ë³¸ ëª¨ë¸

```python
from sklearn.tree import DecisionTreeClassifier

# ê¸°ë³¸ ëª¨ë¸ (ê¹Šì´ ì œí•œ)
model = DecisionTreeClassifier(
    max_depth=5,
    min_samples_leaf=10,
    random_state=42
)

model.fit(X_train, y_train)

print(f"íŠ¸ë¦¬ ê¹Šì´: {model.get_depth()}")
print(f"ë¦¬í”„ ë…¸ë“œ ìˆ˜: {model.get_n_leaves()}")
```

---

# ì‹¤ìŠµ 4: í‰ê°€

## ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ

```python
from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)

# ì •í™•ë„
print(f"ì •í™•ë„: {model.score(X_test, y_test):.1%}")

# ë¶„ë¥˜ ë³´ê³ ì„œ
print("\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(
    y_test, y_pred,
    target_names=['ì •ìƒ', 'ë¶ˆëŸ‰']
))

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(y_test, y_pred)
print("í˜¼ë™ í–‰ë ¬:")
print(cm)
```

---

# ì‹¤ìŠµ 5: ìµœì  ê¹Šì´ ì°¾ê¸°

## í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì •í™•ë„ ë¹„êµ

```python
train_scores = []
test_scores = []
depths = range(1, 16)

for depth in depths:
    model = DecisionTreeClassifier(max_depth=depth, random_state=42)
    model.fit(X_train, y_train)
    train_scores.append(model.score(X_train, y_train))
    test_scores.append(model.score(X_test, y_test))

# ìµœì  ê¹Šì´
best_depth = depths[np.argmax(test_scores)]
best_score = max(test_scores)
print(f"ìµœì  ê¹Šì´: {best_depth}, í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_score:.1%}")
```

---

# ì‹¤ìŠµ 6: ìµœì  ê¹Šì´ ì‹œê°í™”

## í•™ìŠµ ê³¡ì„ 

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(depths, train_scores, 'o-', label='í•™ìŠµ ì •í™•ë„')
plt.plot(depths, test_scores, 'o-', label='í…ŒìŠ¤íŠ¸ ì •í™•ë„')
plt.axvline(x=best_depth, color='red', linestyle='--',
            label=f'ìµœì  ê¹Šì´={best_depth}')
plt.xlabel('íŠ¸ë¦¬ ê¹Šì´')
plt.ylabel('ì •í™•ë„')
plt.title('ê¹Šì´ë³„ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì •í™•ë„')
plt.legend()
plt.grid(True)
plt.savefig('depth_comparison.png', dpi=150)
plt.show()
```

---

# ì‹¤ìŠµ 7: ìµœì¢… ëª¨ë¸ í•™ìŠµ

## ìµœì  íŒŒë¼ë¯¸í„° ì ìš©

```python
# ìµœì  ê¹Šì´ë¡œ ìµœì¢… ëª¨ë¸
final_model = DecisionTreeClassifier(
    max_depth=best_depth,
    min_samples_leaf=5,
    random_state=42
)
final_model.fit(X_train, y_train)

print(f"ìµœì¢… ëª¨ë¸ ì •í™•ë„: {final_model.score(X_test, y_test):.1%}")

# íŠ¹ì„± ì¤‘ìš”ë„
print("\níŠ¹ì„± ì¤‘ìš”ë„:")
for name, imp in zip(X.columns, final_model.feature_importances_):
    print(f"  {name}: {imp:.3f}")
```

---

# ì‹¤ìŠµ 8: ìƒˆ ë°ì´í„° ì˜ˆì¸¡

## ì‹¤ì œ í™œìš©

```python
# ìƒˆ ì œí’ˆ ë°ì´í„°
new_data = pd.DataFrame({
    'temperature': [87, 92, 78],
    'humidity': [55, 68, 42],
    'speed': [100, 95, 105],
    'pressure': [1.0, 0.95, 1.05]
})

# ì˜ˆì¸¡
predictions = final_model.predict(new_data)
probabilities = final_model.predict_proba(new_data)

for i, (pred, proba) in enumerate(zip(predictions, probabilities)):
    status = "ë¶ˆëŸ‰" if pred == 1 else "ì •ìƒ"
    print(f"ì œí’ˆ {i+1}: {status} (ë¶ˆëŸ‰ í™•ë¥ : {proba[1]:.1%})")
```

---

# í•µì‹¬ ì •ë¦¬

## 13ì°¨ì‹œ ìš”ì•½

| ê°œë… | ì„¤ëª… |
|------|------|
| **ì˜ì‚¬ê²°ì •ë‚˜ë¬´** | ì§ˆë¬¸ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ë¶„ë¥˜ |
| **ì§€ë‹ˆ ë¶ˆìˆœë„** | ë°ì´í„° ì„ì„ ì •ë„ ì¸¡ì • |
| **ì •ë³´ ì´ë“** | ë¶„í• ë¡œ ì¸í•œ ë¶ˆìˆœë„ ê°ì†ŒëŸ‰ |
| **max_depth** | ê³¼ëŒ€ì í•© ë°©ì§€ìš© ê¹Šì´ ì œí•œ |
| **íŠ¹ì„± ì¤‘ìš”ë„** | ë¶„ë¥˜ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ |

---

# ì‹¤ë¬´ ê°€ì´ë“œ

## ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‚¬ìš© ì‹œ

<div class="highlight">

### ê¶Œì¥ ì„¤ì •
- `max_depth`: 3~10 ì‚¬ì´ì—ì„œ êµì°¨ê²€ì¦ìœ¼ë¡œ ì„ íƒ
- `min_samples_leaf`: ì „ì²´ ë°ì´í„°ì˜ 1~5%
- `class_weight='balanced'`: ë¶ˆê· í˜• ë°ì´í„°ì— ìœ ìš©

### ì£¼ì˜ì‚¬í•­
- ë‹¨ì¼ íŠ¸ë¦¬ëŠ” ë¶ˆì•ˆì • â†’ **ëœë¤í¬ë ˆìŠ¤íŠ¸** ê¶Œì¥
- ê¹Šì´ê°€ ë„ˆë¬´ ê¹Šìœ¼ë©´ ê³¼ëŒ€ì í•©
- ì¶•ì— í‰í–‰í•œ ë¶„í• ë§Œ ê°€ëŠ¥

</div>

---

# ë‹¤ìŒ ì°¨ì‹œ ì˜ˆê³ 

## 13ì°¨ì‹œ: ë¶„ë¥˜ ëª¨ë¸ (2) - ëœë¤í¬ë ˆìŠ¤íŠ¸

### í•™ìŠµ ë‚´ìš©
- ì•™ìƒë¸” í•™ìŠµì˜ ê°œë…
- ëœë¤í¬ë ˆìŠ¤íŠ¸ ì›ë¦¬ (Bagging)
- ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ì•½ì  ë³´ì™„

<div class="tip">

ì—¬ëŸ¬ ë‚˜ë¬´ë¥¼ ëª¨ì•„ **ìˆ²**ì„ ë§Œë“­ë‹ˆë‹¤!

</div>

---

# ê°ì‚¬í•©ë‹ˆë‹¤

## 13ì°¨ì‹œ: ë¶„ë¥˜ ëª¨ë¸ - ì˜ì‚¬ê²°ì •ë‚˜ë¬´

**ì²« ë²ˆì§¸ ë¶„ë¥˜ ëª¨ë¸ì„ ì™„ì„±í–ˆìŠµë‹ˆë‹¤!**

Q&A
