# [13ì°¨ì‹œ] ë¶„ë¥˜ ëª¨ë¸ (1) - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ - ê°•ì‚¬ ìŠ¤í¬ë¦½íŠ¸

## ğŸ“‹ ìˆ˜ì—… ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì°¨ì‹œ | 13ì°¨ì‹œ |
| ì£¼ì œ | ë¶„ë¥˜ ëª¨ë¸ - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ |
| ì‹œê°„ | 30ë¶„ (ì´ë¡  15ë¶„ + ì‹¤ìŠµ 13ë¶„ + ì •ë¦¬ 2ë¶„) |
| í•™ìŠµ ëª©í‘œ | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì›ë¦¬ ì´í•´, ëª¨ë¸ í•™ìŠµ ë° ì‹œê°í™”/í•´ì„ |

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

1. ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤
2. DecisionTreeClassifierë¥¼ ì‚¬ìš©í•œë‹¤
3. íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ê³  í•´ì„í•œë‹¤

---

## ğŸ• ì‹œê°„ ë°°ë¶„

| êµ¬ê°„ | ì‹œê°„ | ë‚´ìš© |
|------|------|------|
| ë„ì… | 2ë¶„ | ë³µìŠµ ë° í•™ìŠµëª©í‘œ |
| Part 1 | 5ë¶„ | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì›ë¦¬ |
| Part 2 | 5ë¶„ | sklearn ì‹¤ìŠµ |
| Part 3 | 5ë¶„ | ì‹œê°í™”ì™€ í•´ì„ |
| ì‹¤ìŠµ | 11ë¶„ | ë¶ˆëŸ‰ ë¶„ë¥˜ í”„ë¡œì íŠ¸ |
| ì •ë¦¬ | 2ë¶„ | ìš”ì•½ ë° ë‹¤ìŒ ì°¨ì‹œ ì˜ˆê³  |

---

## ğŸ“ ìƒì„¸ ìŠ¤í¬ë¦½íŠ¸

### ë„ì…ë¶€ (2ë¶„)

#### ìŠ¬ë¼ì´ë“œ 1-2: ë³µìŠµ

> "ì§€ë‚œ ì‹œê°„ì— ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆë¥¼ ë°°ì› ìŠµë‹ˆë‹¤. ì§€ë„í•™ìŠµì€ ì •ë‹µì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³ , ë¶„ë¥˜ëŠ” ë²”ì£¼ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê±°ì˜€ì£ ."

> "ì˜¤ëŠ˜ì€ ì²« ë²ˆì§¸ ë¶„ë¥˜ ëª¨ë¸ì¸ 'ì˜ì‚¬ê²°ì •ë‚˜ë¬´'ë¥¼ ë°°ì›ë‹ˆë‹¤. ê°€ì¥ ì§ê´€ì ì´ê³  í•´ì„í•˜ê¸° ì‰¬ìš´ ëª¨ë¸ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 3-4: í•™ìŠµ ëª©í‘œ

> "ì˜¤ëŠ˜ì˜ í•™ìŠµ ëª©í‘œëŠ” ì„¸ ê°€ì§€ì…ë‹ˆë‹¤."

> "ì²«ì§¸, ì˜ì‚¬ê²°ì •ë‚˜ë¬´ê°€ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤. ë‘˜ì§¸, sklearnì˜ DecisionTreeClassifierë¥¼ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤. ì…‹ì§¸, íŠ¸ë¦¬ë¥¼ ì‹œê°í™”í•˜ê³  í•´ì„í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."

---

### Part 1: ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì›ë¦¬ (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 5-7: ì˜ì‚¬ê²°ì •ë‚˜ë¬´ë€

> "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” ì´ë¦„ ê·¸ëŒ€ë¡œ 'ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë‚˜ë¬´ êµ¬ì¡°'ì…ë‹ˆë‹¤. ìŠ¤ë¬´ê³ ê°œ ê²Œì„ì„ ìƒê°í•´ë³´ì„¸ìš”."

> "ì˜ˆë¥¼ ë“¤ì–´ ê³¼ì¼ì„ ë¶„ë¥˜í•œë‹¤ê³  í•©ì‹œë‹¤. 'ë¹¨ê°„ìƒ‰ì¸ê°€ìš”?' ì˜ˆ, 'ë™ê·¸ë€ê°€ìš”?' ì˜ˆ, ê·¸ëŸ¬ë©´ ì‚¬ê³¼ë„¤ìš”! ì´ëŸ° ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ë˜ì ¸ì„œ ë¶„ë¥˜í•˜ëŠ” ê±°ì£ ."

> "ì œì¡° í˜„ì¥ì—ì„œëŠ” 'ì˜¨ë„ê°€ 85ë„ ì´ˆê³¼ì¸ê°€ìš”?', 'ìŠµë„ê°€ 60% ì´ˆê³¼ì¸ê°€ìš”?' ì´ëŸ° ì§ˆë¬¸ìœ¼ë¡œ ë¶ˆëŸ‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 8-9: íŠ¸ë¦¬ ìš©ì–´

> "íŠ¸ë¦¬ êµ¬ì¡°ì—ì„œ ì“°ëŠ” ìš©ì–´ë¥¼ ì•Œì•„ë´…ì‹œë‹¤."

> "ë§¨ ìœ„ê°€ 'ë£¨íŠ¸ ë…¸ë“œ', ì²« ë²ˆì§¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ìœ¼ë¡œ ë¨¼ì € ë‚˜ëˆ•ë‹ˆë‹¤."

> "ì¤‘ê°„ì— ìˆëŠ” ê±´ 'ë‚´ë¶€ ë…¸ë“œ', ì¶”ê°€ ì§ˆë¬¸ì´ì£ ."

> "ë§¨ ì•„ë˜ê°€ 'ë¦¬í”„ ë…¸ë“œ', ìµœì¢… ê²°ì •ì…ë‹ˆë‹¤. 'ì •ìƒ' ë˜ëŠ” 'ë¶ˆëŸ‰'ì´ë¼ê³  íŒì •í•˜ëŠ” ê±°ì£ ."

---

#### ìŠ¬ë¼ì´ë“œ 10-12: ë¶ˆìˆœë„ì™€ ë¶„í• 

> "ê·¸ëŸ¼ ì–´ë–¤ ì§ˆë¬¸ì´ ì¢‹ì€ ì§ˆë¬¸ì¼ê¹Œìš”? ì—¬ê¸°ì„œ 'ë¶ˆìˆœë„'ë¼ëŠ” ê°œë…ì´ ë‚˜ì˜µë‹ˆë‹¤."

> "ë¶ˆìˆœë„ëŠ” ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì„ì—¬ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."

> "ì¢‹ì€ ë¶„í• ì€ ë¶ˆìˆœë„ë¥¼ í¬ê²Œ ë‚®ì¶”ëŠ” ë¶„í• ì…ë‹ˆë‹¤. ë¶„í•  í›„ì— ê° ê·¸ë£¹ì´ í•œ í´ë˜ìŠ¤ë¡œ ê¹”ë”í•˜ê²Œ ë‚˜ë‰˜ë©´ ì¢‹ì€ ê±°ì£ ."

> "ì˜ˆë¥¼ ë“¤ì–´, 8ê°œ ë°ì´í„°ê°€ ì •ìƒ 4ê°œ, ë¶ˆëŸ‰ 4ê°œ ì„ì—¬ìˆë‹¤ê³  í•©ì‹œë‹¤. ë¶„í•  í›„ì— ì™¼ìª½ì€ ì •ìƒ 4ê°œ, ì˜¤ë¥¸ìª½ì€ ë¶ˆëŸ‰ 4ê°œë¡œ ë‚˜ë‰˜ë©´ ì™„ë²½í•œ ë¶„í• ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 13-15: ì§€ë‹ˆ ë¶ˆìˆœë„

> "sklearnì—ì„œ ê¸°ë³¸ìœ¼ë¡œ ì“°ëŠ” ë¶ˆìˆœë„ê°€ 'ì§€ë‹ˆ ë¶ˆìˆœë„'ì…ë‹ˆë‹¤."

> "ì§€ë‹ˆ ê°’ì´ 0ì´ë©´ ì™„ì „íˆ ìˆœìˆ˜í•œ ê²ë‹ˆë‹¤. í•œ í´ë˜ìŠ¤ë§Œ ìˆë‹¤ëŠ” ëœ»ì´ì£ . ì´ì§„ ë¶„ë¥˜ì—ì„œ ì§€ë‹ˆ ê°’ì´ 0.5ë©´ 50:50ìœ¼ë¡œ ê°€ì¥ ë¶ˆìˆœí•œ ìƒíƒœì…ë‹ˆë‹¤."

> "íŠ¸ë¦¬ í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ëª¨ë“  íŠ¹ì„±, ëª¨ë“  ë¶„í• ì ì„ ê²€í† í•´ì„œ ì •ë³´ ì´ë“ì´ ê°€ì¥ í° ë¶„í• ì„ ì„ íƒí•©ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 16-17: ê³¼ëŒ€ì í•©

> "ì£¼ì˜í•  ì ì´ ìˆìŠµë‹ˆë‹¤. íŠ¸ë¦¬ê°€ ë„ˆë¬´ ê¹Šì–´ì§€ë©´ ê³¼ëŒ€ì í•©ì´ ë°œìƒí•©ë‹ˆë‹¤."

> "í•™ìŠµ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆê¹Œì§€ ë‹¤ ì™¸ì›Œë²„ë ¤ì„œ, ìƒˆ ë°ì´í„°ì—ì„œ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì£ ."

> "ê·¸ë˜ì„œ max_depthë¡œ ê¹Šì´ë¥¼ ì œí•œí•˜ê±°ë‚˜, min_samples_splitìœ¼ë¡œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."

---

### Part 2: sklearn ì‹¤ìŠµ (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 18-20: DecisionTreeClassifier

> "ì´ì œ sklearnìœ¼ë¡œ ì‹¤ì œë¡œ ë§Œë“¤ì–´ë´…ì‹œë‹¤."

```python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(
    max_depth=5,        # ê¹Šì´ ì œí•œ
    random_state=42     # ì¬í˜„ì„±
)
```

> "criterionì€ ë¶ˆìˆœë„ ì¸¡ì • ë°©ì‹ì¸ë°, ê¸°ë³¸ê°’ 'gini'ë¥¼ ë³´í†µ ì”ë‹ˆë‹¤."

> "max_depthê°€ ê°€ì¥ ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ê³¼ëŒ€ì í•© ë°©ì§€ìš©ì´ì£ ."

---

#### ìŠ¬ë¼ì´ë“œ 21-23: í•™ìŠµê³¼ ì˜ˆì¸¡

> "ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ íŒ¨í„´ ê¸°ì–µë‚˜ì‹œì£ ? fit, predict, scoreì…ë‹ˆë‹¤."

```python
# í•™ìŠµ
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
accuracy = model.score(X_test, y_test)
```

> "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” predict_probaë¡œ í™•ë¥ ë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶ˆëŸ‰ í™•ë¥ ì´ 70%ë‹¤, ì´ëŸ° ì‹ìœ¼ë¡œìš”."

---

#### ìŠ¬ë¼ì´ë“œ 24-26: max_depth ì‹¤í—˜

> "ê¹Šì´ë¥¼ ë‹¤ë¥´ê²Œ í•´ì„œ ì‹¤í—˜í•´ë³´ë©´ ì¬ë¯¸ìˆëŠ” ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤."

> "ê¹Šì´ 1ì€ ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ ê³¼ì†Œì í•©, ê¹Šì´ 10ì€ í•™ìŠµ ë°ì´í„°ì— 100% ë§ì¶”ì§€ë§Œ í…ŒìŠ¤íŠ¸ì—ì„œ ë–¨ì–´ì§€ëŠ” ê³¼ëŒ€ì í•©."

> "ë³´í†µ ê¹Šì´ 3~5 ì •ë„ê°€ ê· í˜• ì¡íŒ ê²°ê³¼ë¥¼ ì¤ë‹ˆë‹¤. ë°ì´í„°ë§ˆë‹¤ ë‹¤ë¥´ë‹ˆê¹Œ ì‹¤í—˜í•´ë´ì•¼ í•©ë‹ˆë‹¤."

---

### Part 3: ì‹œê°í™”ì™€ í•´ì„ (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 27-29: íŠ¸ë¦¬ ì‹œê°í™”

> "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ í° ì¥ì ì´ ì‹œê°í™”ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ë‹ˆë‹¤."

```python
from sklearn.tree import plot_tree

plt.figure(figsize=(20, 10))
plot_tree(model, feature_names=['ì˜¨ë„', 'ìŠµë„', 'ì†ë„', 'ì••ë ¥'],
          class_names=['ì •ìƒ', 'ë¶ˆëŸ‰'], filled=True)
plt.show()
```

> "ê° ë…¸ë“œì— ë¶„í•  ì¡°ê±´, ë¶ˆìˆœë„, ìƒ˜í”Œ ìˆ˜, í´ë˜ìŠ¤ ë¶„í¬ê°€ ë‹¤ ë‚˜ì˜µë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 30-32: íŠ¹ì„± ì¤‘ìš”ë„

> "ë˜ ë‹¤ë¥¸ ì¥ì ì´ 'íŠ¹ì„± ì¤‘ìš”ë„'ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤ëŠ” ê²ë‹ˆë‹¤."

```python
importances = model.feature_importances_
```

> "ì˜¨ë„ê°€ 0.65, ìŠµë„ê°€ 0.28ì´ë©´, ì˜¨ë„ê°€ ë¶ˆëŸ‰ íŒì •ì— ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†Œë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤."

> "ì‹¤ë¬´ì—ì„œ ì´ ì •ë³´ê°€ ì•„ì£¼ ìœ ìš©í•©ë‹ˆë‹¤. ì–´ë””ì— ê´€ë¦¬ ë…¸ë ¥ì„ ì§‘ì¤‘í•´ì•¼ í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ë‹ˆê¹Œìš”."

---

#### ìŠ¬ë¼ì´ë“œ 33-34: í•´ì„ê³¼ ì¸ì‚¬ì´íŠ¸

> "íŠ¸ë¦¬ë¥¼ ì½ì–´ë³´ë©´ ì´ëŸ° ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

> "'ì˜¨ë„ 87.5ë„ê°€ ì²« ë²ˆì§¸ ë¶„ê¸°ì ì´ë„¤? ê·¸ëŸ¼ ì˜¨ë„ë¥¼ 87ë„ ì´í•˜ë¡œ ìœ ì§€í•˜ë©´ ë¶ˆëŸ‰ì´ ì¤„ê² ë‹¤.'"

> "'ì˜¨ë„ê°€ ë‚®ì•„ë„ ìŠµë„ê°€ 60%ë¥¼ ë„˜ìœ¼ë©´ ë¶ˆëŸ‰ì´ ë‚˜ì˜¤ë„¤? ìŠµë„ ê´€ë¦¬ë„ í•„ìš”í•˜ê² ë‹¤.'"

> "ì´ê²Œ ë°”ë¡œ ML ëª¨ë¸ì´ ì£¼ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤."

---

### ì‹¤ìŠµí¸ (11ë¶„)

#### ìŠ¬ë¼ì´ë“œ 35-36: ì‹¤ìŠµ ê°œìš”

> "ì´ì œ ì™„ì „í•œ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤."

> "ë°ì´í„° ìƒì„±ë¶€í„° ìµœì  ê¹Šì´ ì°¾ê¸°ê¹Œì§€ ì „ ê³¼ì •ì„ í•´ë´…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 37-40: ë°ì´í„° ì¤€ë¹„

> "ë¨¼ì € ë°ì´í„°ë¥¼ ë§Œë“¤ê³  íƒìƒ‰í•©ë‹ˆë‹¤."

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n),
    'humidity': np.random.normal(50, 10, n),
    'speed': np.random.normal(100, 15, n),
    'pressure': np.random.normal(1.0, 0.1, n),
})
defect_prob = 0.1 + 0.03*(df['temperature']-80) + 0.01*(df['humidity']-45)
df['defect'] = (np.random.random(n) < defect_prob).astype(int)

X = df[['temperature', 'humidity', 'speed', 'pressure']]
y = df['defect']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---

#### ìŠ¬ë¼ì´ë“œ 41-44: ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

> "ê¸°ë³¸ ëª¨ë¸ì„ ë§Œë“¤ê³  í‰ê°€í•©ë‹ˆë‹¤."

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report

model = DecisionTreeClassifier(max_depth=5, random_state=42)
model.fit(X_train, y_train)

print(f"ì •í™•ë„: {model.score(X_test, y_test):.1%}")
print(classification_report(y_test, model.predict(X_test)))
```

> "classification_reportë¡œ ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ê¹Œì§€ í•œ ë²ˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 45-47: ìµœì  ê¹Šì´ ì°¾ê¸°

> "ë‹¤ì–‘í•œ ê¹Šì´ë¡œ ì‹¤í—˜í•´ì„œ ìµœì  ê¹Šì´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."

```python
train_scores = []
test_scores = []

for depth in range(1, 16):
    model = DecisionTreeClassifier(max_depth=depth, random_state=42)
    model.fit(X_train, y_train)
    train_scores.append(model.score(X_train, y_train))
    test_scores.append(model.score(X_test, y_test))

# í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ê¹Šì´
best_depth = np.argmax(test_scores) + 1
print(f"ìµœì  ê¹Šì´: {best_depth}")
```

> "í•™ìŠµ ì •í™•ë„ëŠ” ê³„ì† ì˜¬ë¼ê°€ì§€ë§Œ, í…ŒìŠ¤íŠ¸ ì •í™•ë„ëŠ” ì–´ëŠ ì‹œì ì—ì„œ ë–¨ì–´ì§€ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ê·¸ ì§€ì ì´ ê³¼ëŒ€ì í•©ì˜ ì‹œì‘ì ì´ì—ìš”."

---

#### ìŠ¬ë¼ì´ë“œ 48-50: ìµœì¢… ëª¨ë¸ê³¼ ì˜ˆì¸¡

> "ìµœì  ê¹Šì´ë¡œ ìµœì¢… ëª¨ë¸ì„ ë§Œë“¤ê³ , ìƒˆ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤."

```python
final_model = DecisionTreeClassifier(max_depth=best_depth, random_state=42)
final_model.fit(X_train, y_train)

# ìƒˆ ì œí’ˆ ì˜ˆì¸¡
new_data = pd.DataFrame({
    'temperature': [87, 92, 78],
    'humidity': [55, 68, 42],
    'speed': [100, 95, 105],
    'pressure': [1.0, 0.95, 1.05]
})

predictions = final_model.predict(new_data)
probabilities = final_model.predict_proba(new_data)
```

> "ì´ì œ í˜„ì¥ì—ì„œ ìƒˆ ì œí’ˆì´ ë“¤ì–´ì˜¤ë©´ ë°”ë¡œ ë¶ˆëŸ‰ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

---

### ì •ë¦¬ (2ë¶„)

#### ìŠ¬ë¼ì´ë“œ 51-52: í•µì‹¬ ì •ë¦¬

> "ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤."

> "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” ì§ˆë¬¸ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤. ìŠ¤ë¬´ê³ ê°œì²˜ëŸ¼ìš”."

> "ì§€ë‹ˆ ë¶ˆìˆœë„ë¡œ ë¶„í• ì˜ ì¢‹ê³  ë‚˜ì¨ì„ ì¸¡ì •í•˜ê³ , ì •ë³´ ì´ë“ì´ ê°€ì¥ í° ë¶„í• ì„ ì„ íƒí•©ë‹ˆë‹¤."

> "max_depthë¡œ ê³¼ëŒ€ì í•©ì„ ë°©ì§€í•˜ê³ , íŠ¹ì„± ì¤‘ìš”ë„ë¡œ ì–´ë–¤ ë³€ìˆ˜ê°€ ì¤‘ìš”í•œì§€ íŒŒì•…í•©ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 53-54: ë‹¤ìŒ ì°¨ì‹œ ì˜ˆê³ 

> "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ë‹¨ì ì€ ë¶ˆì•ˆì •í•˜ë‹¤ëŠ” ê²ë‹ˆë‹¤. ë°ì´í„°ê°€ ì¡°ê¸ˆë§Œ ë°”ë€Œì–´ë„ íŠ¸ë¦¬ êµ¬ì¡°ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”."

> "ë‹¤ìŒ ì‹œê°„ì—ëŠ” ì´ ì•½ì ì„ ë³´ì™„í•œ 'ëœë¤í¬ë ˆìŠ¤íŠ¸'ë¥¼ ë°°ì›ë‹ˆë‹¤. ì—¬ëŸ¬ ê°œì˜ ë‚˜ë¬´ë¥¼ ëª¨ì•„ì„œ ìˆ²ì„ ë§Œë“œëŠ” ê±°ì£ . ì•™ìƒë¸” í•™ìŠµì´ë¼ê³  í•©ë‹ˆë‹¤."

> "ì˜¤ëŠ˜ ìˆ˜ì—… ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!"

---

## â“ ì˜ˆìƒ ì§ˆë¬¸ ë° ë‹µë³€

### Q1: ì§€ë‹ˆ ë¶ˆìˆœë„ì™€ ì—”íŠ¸ë¡œí”¼ ì¤‘ ì–´ë–¤ ê±¸ ì¨ì•¼ í•˜ë‚˜ìš”?

> "ì‹¤ì œë¡œ í° ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì¸ ì§€ë‹ˆë¥¼ ì“°ì‹œë©´ ë©ë‹ˆë‹¤. ì—”íŠ¸ë¡œí”¼ëŠ” ê³„ì‚°ì´ ì¡°ê¸ˆ ë” ëŠë¦°ë°, ê²°ê³¼ëŠ” ë¹„ìŠ·í•©ë‹ˆë‹¤."

### Q2: max_depthë¥¼ ëª‡ìœ¼ë¡œ í•´ì•¼ í•˜ë‚˜ìš”?

> "ë°ì´í„°ë§ˆë‹¤ ë‹¤ë¦…ë‹ˆë‹¤. ë³´í†µ 3~10 ì‚¬ì´ì—ì„œ êµì°¨ê²€ì¦ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤. 15ì°¨ì‹œì—ì„œ GridSearchCVë¡œ ìë™ìœ¼ë¡œ ì°¾ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."

### Q3: íŠ¹ì„± ì¤‘ìš”ë„ê°€ 0ì¸ íŠ¹ì„±ì€ ì œê±°í•´ë„ ë˜ë‚˜ìš”?

> "ë„¤, ì œê±°í•´ë„ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ëª¨ë¸ì—ì„œëŠ” ê·¸ íŠ¹ì„±ì´ ì¤‘ìš”í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ìµœì¢… ê²°ì • ì „ì— ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ í™•ì¸í•´ë³´ì„¸ìš”."

### Q4: ì˜ì‚¬ê²°ì •ë‚˜ë¬´ê°€ ì™œ ë¶ˆì•ˆì •í•œê°€ìš”?

> "íŠ¸ë¦¬ê°€ íƒìš•ì (greedy)ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê° ë‹¨ê³„ì—ì„œ ìµœì„ ì„ ì„ íƒí•˜ëŠ”ë°, ë°ì´í„°ê°€ ì¡°ê¸ˆ ë°”ë€Œë©´ ì²« ë²ˆì§¸ ë¶„í• ì´ ë‹¬ë¼ì§€ê³ , ê·¸ëŸ¬ë©´ ì „ì²´ íŠ¸ë¦¬ê°€ ë°”ë€ë‹ˆë‹¤."

### Q5: ì—°ì†í˜• ë³€ìˆ˜ëŠ” ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?

> "ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì´ ëª¨ë“  ê°€ëŠ¥í•œ ë¶„í• ì ì„ ê²€í† í•´ì„œ ê°€ì¥ ì¢‹ì€ ì ì„ ì°¾ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'ì˜¨ë„ â‰¤ 87.5'ì²˜ëŸ¼ ìµœì ì˜ ì„ê³„ê°’ì„ ì°¾ì•„ì¤ë‹ˆë‹¤."

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [sklearn DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
- [sklearn tree visualization](https://scikit-learn.org/stable/modules/tree.html#tree)

### ì¶”ì²œ ìë£Œ
- "í†µê³„ì  í•™ìŠµì˜ ì›ë¦¬" - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì´ë¡ 
- "í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹" - 6ì¥ ì˜ì‚¬ê²°ì •ë‚˜ë¬´

### ê´€ë ¨ ì°¨ì‹œ
- 11ì°¨ì‹œ: ë¨¸ì‹ ëŸ¬ë‹ ì†Œê°œì™€ ë¬¸ì œ ìœ í˜•
- 13ì°¨ì‹œ: ë¶„ë¥˜ ëª¨ë¸ - ëœë¤í¬ë ˆìŠ¤íŠ¸
- 15ì°¨ì‹œ: ëª¨ë¸ í‰ê°€ì™€ ë°˜ë³µ ê²€ì¦

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ìˆ˜ì—… ì „:
- [ ] sklearn, matplotlib ì„¤ì¹˜ í™•ì¸
- [ ] ì˜ˆì œ ì½”ë“œ í…ŒìŠ¤íŠ¸
- [ ] íŠ¸ë¦¬ ì‹œê°í™” í™•ì¸

ìˆ˜ì—… ì¤‘:
- [ ] ìŠ¤ë¬´ê³ ê°œ ë¹„ìœ ë¡œ ì›ë¦¬ ì„¤ëª…
- [ ] ì§€ë‹ˆ ë¶ˆìˆœë„ ê°œë… ì„¤ëª…
- [ ] max_depth ê³¼ëŒ€ì í•© ì‹¤í—˜
- [ ] íŠ¹ì„± ì¤‘ìš”ë„ í•´ì„ ì—°ìŠµ
- [ ] ì‹¤ì œ ì˜ˆì¸¡ ì‹œì—°

ìˆ˜ì—… í›„:
- [ ] ì‹¤ìŠµ ì½”ë“œ ë°°í¬
- [ ] ëœë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆê³ 
