# [16ì°¨ì‹œ] ëª¨ë¸ í‰ê°€ì™€ ë°˜ë³µ ê²€ì¦ - ê°•ì‚¬ ìŠ¤í¬ë¦½íŠ¸

## ğŸ“‹ ìˆ˜ì—… ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì°¨ì‹œ | 16ì°¨ì‹œ |
| ì£¼ì œ | ëª¨ë¸ í‰ê°€ì™€ ë°˜ë³µ ê²€ì¦ |
| ì‹œê°„ | 30ë¶„ (ì´ë¡  15ë¶„ + ì‹¤ìŠµ 13ë¶„ + ì •ë¦¬ 2ë¶„) |
| í•™ìŠµ ëª©í‘œ | êµì°¨ê²€ì¦ ì›ë¦¬, ê³¼ëŒ€/ê³¼ì†Œì í•© ì§„ë‹¨, í‰ê°€ ì§€í‘œ í™œìš© |

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

1. êµì°¨ê²€ì¦ì˜ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤
2. ê³¼ëŒ€ì í•©/ê³¼ì†Œì í•©ì„ ì§„ë‹¨í•œë‹¤
3. ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¥¼ í™œìš©í•œë‹¤

---

## ğŸ• ì‹œê°„ ë°°ë¶„

| êµ¬ê°„ | ì‹œê°„ | ë‚´ìš© |
|------|------|------|
| ë„ì… | 2ë¶„ | ë³µìŠµ ë° í•™ìŠµëª©í‘œ |
| ëŒ€ì£¼ì œ 1 | 5ë¶„ | êµì°¨ê²€ì¦ì˜ ì›ë¦¬ |
| ëŒ€ì£¼ì œ 2 | 5ë¶„ | ê³¼ëŒ€ì í•©/ê³¼ì†Œì í•© ì§„ë‹¨ |
| ëŒ€ì£¼ì œ 3 | 5ë¶„ | í‰ê°€ ì§€í‘œ í™œìš© |
| ì‹¤ìŠµ | 11ë¶„ | êµì°¨ê²€ì¦ ë° í‰ê°€ ì‹¤ìŠµ |
| ì •ë¦¬ | 2ë¶„ | ìš”ì•½ ë° ë‹¤ìŒ ì°¨ì‹œ ì˜ˆê³  |

---

## ğŸ“ ìƒì„¸ ìŠ¤í¬ë¦½íŠ¸

### ë„ì…ë¶€ (2ë¶„)

#### ìŠ¬ë¼ì´ë“œ 1-2: ë³µìŠµ

> "ì§€ë‚œ ì‹œê°„ì— ì„ í˜•íšŒê·€ì™€ ë‹¤í•­íšŒê·€ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤. RÂ² ì ìˆ˜ë¡œ ëª¨ë¸ì„ í‰ê°€í–ˆëŠ”ë°, í˜¹ì‹œ ì´ í‰ê°€ê°€ ì •ë§ ë¯¿ì„ ë§Œí• ê¹Œìš”?"

> "í•œ ë²ˆì˜ train_test_splitìœ¼ë¡œ í‰ê°€í•œ ì ìˆ˜ê°€ ìš°ì—°íˆ ì¢‹ê±°ë‚˜ ë‚˜ë¹´ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 3-4: í•™ìŠµ ëª©í‘œ

> "ì˜¤ëŠ˜ì˜ í•™ìŠµ ëª©í‘œëŠ” ì„¸ ê°€ì§€ì…ë‹ˆë‹¤. êµì°¨ê²€ì¦ìœ¼ë¡œ ì•ˆì •ì ì¸ í‰ê°€ë¥¼ í•˜ê³ , ê³¼ëŒ€ì í•©ê³¼ ê³¼ì†Œì í•©ì„ ì§„ë‹¨í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê³ , ë¶„ë¥˜ì™€ íšŒê·€ ê°ê°ì— ë§ëŠ” í‰ê°€ ì§€í‘œë¥¼ í™œìš©í•©ë‹ˆë‹¤."

---

### ëŒ€ì£¼ì œ 1: êµì°¨ê²€ì¦ì˜ ì›ë¦¬ (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 5-7: ë‹¨ì¼ ë¶„í• ì˜ ë¬¸ì œ

> "train_test_splitì„ í•œ ë²ˆë§Œ í•˜ë©´ ì–´ë–¤ ë¬¸ì œê°€ ìˆì„ê¹Œìš”?"

> "ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë‚˜ë‰˜ëƒì— ë”°ë¼ ì ìˆ˜ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. random_stateë¥¼ ë°”ê¿”ê°€ë©° ì‹¤í—˜í•´ë³´ë©´ ì ìˆ˜ê°€ 0.75ê°€ ë‚˜ì˜¬ ë•Œë„ ìˆê³ , 0.85ê°€ ë‚˜ì˜¬ ë•Œë„ ìˆì–´ìš”."

> "ì´ë ‡ê²Œ ë¶ˆì•ˆì •í•œ í‰ê°€ë¡œ ëª¨ë¸ì„ ì„ íƒí•˜ë©´ ìœ„í—˜í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ ë°°í¬í–ˆì„ ë•Œ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì„±ëŠ¥ì´ ë‚˜ì˜¬ ìˆ˜ ìˆì£ ."

---

#### ìŠ¬ë¼ì´ë“œ 8-10: K-Fold êµì°¨ê²€ì¦

> "í•´ê²°ì±…ì´ K-Fold êµì°¨ê²€ì¦ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ Kê°œì˜ ì¡°ê°(Fold)ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."

> "ì²« ë²ˆì§¸ ì‹¤í—˜: 1ë²ˆ í´ë“œë¥¼ í…ŒìŠ¤íŠ¸ë¡œ, ë‚˜ë¨¸ì§€ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ì‹¤í—˜: 2ë²ˆ í´ë“œë¥¼ í…ŒìŠ¤íŠ¸ë¡œ. ì´ë ‡ê²Œ Kë²ˆ ë°˜ë³µí•©ë‹ˆë‹¤."

> "ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ê°€ í•œ ë²ˆì”©ì€ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë©ë‹ˆë‹¤. Kê°œì˜ ì ìˆ˜ê°€ ë‚˜ì˜¤ê³ , ì´ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ë´…ë‹ˆë‹¤."

**[ì˜ˆì‹œ]**
```
5-Fold êµì°¨ê²€ì¦ ê²°ê³¼:
Fold 1: 0.82
Fold 2: 0.85
Fold 3: 0.80
Fold 4: 0.83
Fold 5: 0.84
í‰ê· : 0.828 (Â±0.018)
```

> "í‘œì¤€í¸ì°¨ê°€ ì‘ìœ¼ë©´ ëª¨ë¸ì´ ì•ˆì •ì ì´ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 11-13: sklearn cross_val_score

> "sklearnì—ì„œëŠ” cross_val_score í•¨ìˆ˜ í•˜ë‚˜ë¡œ êµì°¨ê²€ì¦ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"í‰ê· : {scores.mean():.3f} (Â±{scores.std():.3f})")
```

> "cv=5ë©´ 5-Foldì…ë‹ˆë‹¤. ë³´í†µ 5 ë˜ëŠ” 10ì„ ë§ì´ ì”ë‹ˆë‹¤."

> "ë°ì´í„°ê°€ ì ìœ¼ë©´ Kë¥¼ í¬ê²Œ, ë§ìœ¼ë©´ 5 ì •ë„ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 14-15: StratifiedKFold

> "ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì£¼ì˜í•  ì ì´ ìˆìŠµë‹ˆë‹¤. í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë¶ˆê· í˜•í•˜ë©´ ì–´ë–¤ í´ë“œì—ëŠ” íŠ¹ì • í´ë˜ìŠ¤ê°€ ì—†ì„ ìˆ˜ë„ ìˆì–´ìš”."

> "StratifiedKFoldëŠ” ê° í´ë“œì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” cross_val_scoreê°€ ìë™ìœ¼ë¡œ ì´ê±¸ ì‚¬ìš©í•©ë‹ˆë‹¤."

---

### ëŒ€ì£¼ì œ 2: ê³¼ëŒ€ì í•©/ê³¼ì†Œì í•© ì§„ë‹¨ (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 16-18: ê³¼ëŒ€ì í•©ì´ë€

> "ê³¼ëŒ€ì í•©ì€ í•™ìŠµ ë°ì´í„°ë¥¼ 'ì™¸ì›Œë²„ë¦°' ìƒíƒœì…ë‹ˆë‹¤."

> "ì¦ìƒì€? í•™ìŠµ ì ìˆ˜ëŠ” ì•„ì£¼ ë†’ì€ë° í…ŒìŠ¤íŠ¸ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤. í•™ìŠµ 99%, í…ŒìŠ¤íŠ¸ 70% ì´ëŸ° ì‹ì´ì£ ."

> "ì›ì¸ì€ ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•˜ê±°ë‚˜, í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ë…¸ì´ì¦ˆê¹Œì§€ í•™ìŠµí•œ ê²½ìš°ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 19-21: ê³¼ì†Œì í•©ì´ë€

> "ê³¼ì†Œì í•©ì€ ë°˜ëŒ€ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì œëŒ€ë¡œ ëª» ì¡ëŠ” ê±°ì˜ˆìš”."

> "í•™ìŠµ ì ìˆ˜ë„ ë‚®ê³  í…ŒìŠ¤íŠ¸ ì ìˆ˜ë„ ë‚®ìŠµë‹ˆë‹¤. í•™ìŠµ 60%, í…ŒìŠ¤íŠ¸ 58% ì´ëŸ° ê²½ìš°ì£ ."

> "í•´ê²°ì±…ì€ ë” ë³µì¡í•œ ëª¨ë¸ì„ ì“°ê±°ë‚˜, íŠ¹ì„±ì„ ì¶”ê°€í•˜ê±°ë‚˜, í•™ìŠµì„ ë” ì‹œí‚¤ëŠ” ê²ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 22-24: ì§„ë‹¨ ë°©ë²• - ê°­ ë¶„ì„

> "ê°€ì¥ ê°„ë‹¨í•œ ì§„ë‹¨ë²•ì€ í•™ìŠµ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ì˜ ê°­ì„ ë³´ëŠ” ê²ë‹ˆë‹¤."

**[í‘œ: ì§„ë‹¨ ê¸°ì¤€]**
| í•™ìŠµ ì ìˆ˜ | í…ŒìŠ¤íŠ¸ ì ìˆ˜ | ê°­ | ì§„ë‹¨ |
|-----------|-------------|-----|------|
| ë†’ìŒ (0.95) | ë‚®ìŒ (0.70) | í¼ | ê³¼ëŒ€ì í•© |
| ë‚®ìŒ (0.60) | ë‚®ìŒ (0.58) | ì‘ìŒ | ê³¼ì†Œì í•© |
| ë†’ìŒ (0.85) | ë†’ìŒ (0.82) | ì‘ìŒ | ì ì ˆ |

> "ì´ìƒì ì¸ ìƒíƒœëŠ” ë‘˜ ë‹¤ ë†’ìœ¼ë©´ì„œ ê°­ì´ ì‘ì€ ê²ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 25-27: í•™ìŠµ ê³¡ì„  (Learning Curve)

> "ë” ì •ë°€í•œ ì§„ë‹¨ì€ í•™ìŠµ ê³¡ì„ ì„ ê·¸ë¦¬ëŠ” ê²ë‹ˆë‹¤."

> "Xì¶•ì€ í•™ìŠµ ë°ì´í„° ì–‘, Yì¶•ì€ ì ìˆ˜ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì ì  ëŠ˜ë ¤ê°€ë©° í•™ìŠµ ì ìˆ˜ì™€ ê²€ì¦ ì ìˆ˜ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."

```python
from sklearn.model_selection import learning_curve

train_sizes, train_scores, val_scores = learning_curve(
    model, X, y, cv=5, train_sizes=[0.2, 0.4, 0.6, 0.8, 1.0]
)
```

> "ê³¼ëŒ€ì í•©ì´ë©´: í•™ìŠµ ê³¡ì„ ì€ ë†’ê³ , ê²€ì¦ ê³¡ì„ ì€ ë‚®ê³ , ë‘˜ ì‚¬ì´ ê°­ì´ í½ë‹ˆë‹¤."

> "ê³¼ì†Œì í•©ì´ë©´: ë‘˜ ë‹¤ ë‚®ê³  ìˆ˜ë ´í•©ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 28-29: ê²€ì¦ ê³¡ì„  (Validation Curve)

> "í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë°”ê¿”ê°€ë©° ì ìˆ˜ë¥¼ ê·¸ë¦° ê²Œ ê²€ì¦ ê³¡ì„ ì…ë‹ˆë‹¤."

> "ì˜ˆë¥¼ ë“¤ì–´ max_depthë¥¼ 1ë¶€í„° 10ê¹Œì§€ ë°”ê¿”ê°€ë©° í•™ìŠµ/ê²€ì¦ ì ìˆ˜ë¥¼ ë´…ë‹ˆë‹¤. ìµœì ì˜ ê°’ì„ ì°¾ì„ ìˆ˜ ìˆì–´ìš”."

```python
from sklearn.model_selection import validation_curve

train_scores, val_scores = validation_curve(
    model, X, y, param_name="max_depth", param_range=[1,3,5,7,10], cv=5
)
```

---

### ëŒ€ì£¼ì œ 3: í‰ê°€ ì§€í‘œ í™œìš© (5ë¶„)

#### ìŠ¬ë¼ì´ë“œ 30-32: ë¶„ë¥˜ í‰ê°€ - í˜¼ë™í–‰ë ¬

> "ë¶„ë¥˜ ëª¨ë¸ì€ ì •í™•ë„ë§Œ ë³´ë©´ ì•ˆ ë©ë‹ˆë‹¤. íŠ¹íˆ í´ë˜ìŠ¤ê°€ ë¶ˆê· í˜•í•  ë•Œìš”."

> "í˜¼ë™í–‰ë ¬ì€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ 4ê°€ì§€ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."

**[í˜¼ë™í–‰ë ¬ ì„¤ëª…]**
```
                ì˜ˆì¸¡
              ì–‘ì„±  ìŒì„±
ì‹¤ì œ ì–‘ì„±    TP    FN
ì‹¤ì œ ìŒì„±    FP    TN
```

> "TPëŠ” ì–‘ì„±ì„ ì–‘ì„±ìœ¼ë¡œ ë§ì¶˜ ê²ƒ, FNì€ ì–‘ì„±ì„ ìŒì„±ìœ¼ë¡œ í‹€ë¦° ê²ƒ, FPëŠ” ìŒì„±ì„ ì–‘ì„±ìœ¼ë¡œ í‹€ë¦° ê²ƒ, TNì€ ìŒì„±ì„ ìŒì„±ìœ¼ë¡œ ë§ì¶˜ ê²ƒì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 33-35: ì •ë°€ë„, ì¬í˜„ìœ¨, F1

> "ì •ë°€ë„(Precision)ëŠ” ì–‘ì„± ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì–‘ì„±ì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤. 'ë‚´ê°€ ë¶ˆëŸ‰ì´ë¼ê³  í•œ ê²ƒ ì¤‘ ì§„ì§œ ë¶ˆëŸ‰ì€?'"

> "ì¬í˜„ìœ¨(Recall)ì€ ì‹¤ì œ ì–‘ì„± ì¤‘ ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤. 'ì‹¤ì œ ë¶ˆëŸ‰ ì¤‘ ë‚´ê°€ ì¡ì•„ë‚¸ ë¹„ìœ¨ì€?'"

> "F1 ScoreëŠ” ë‘˜ì˜ ì¡°í™”í‰ê· ì…ë‹ˆë‹¤. ë‘˜ ë‹¤ ë†’ì•„ì•¼ F1ë„ ë†’ìŠµë‹ˆë‹¤."

**[ì˜ˆì‹œ: ì œì¡° ë¶ˆëŸ‰ ê²€ì¶œ]**
> "ë¶ˆëŸ‰ì„ ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ìƒí™©ì´ë¼ë©´ ì¬í˜„ìœ¨ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì •ìƒì„ ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ëª» íŒë‹¨í•˜ëŠ” ë¹„ìš©ì´ í¬ë‹¤ë©´ ì •ë°€ë„ê°€ ì¤‘ìš”í•˜ì£ ."

---

#### ìŠ¬ë¼ì´ë“œ 36-38: sklearn classification_report

> "sklearnì˜ classification_reportë¡œ í•œë²ˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

```python
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))
```

**[ì¶œë ¥ ì˜ˆì‹œ]**
```
              precision    recall  f1-score   support
      ì •ìƒ       0.92      0.95      0.93       180
      ë¶ˆëŸ‰       0.85      0.78      0.81        70
  accuracy                           0.90       250
 macro avg       0.88      0.86      0.87       250
```

> "supportëŠ” ì‹¤ì œ ìƒ˜í”Œ ìˆ˜ì…ë‹ˆë‹¤. ë¶ˆëŸ‰ì´ 70ê°œë°–ì— ì—†ë„¤ìš”. ë¶ˆê· í˜• ë°ì´í„°ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 39-41: íšŒê·€ í‰ê°€ ì§€í‘œ

> "íšŒê·€ ëª¨ë¸ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ë‹ˆê¹Œ ë‹¤ë¥¸ ì§€í‘œë¥¼ ì”ë‹ˆë‹¤."

| ì§€í‘œ | ì˜ë¯¸ | í•´ì„ |
|------|------|------|
| MSE | í‰ê·  ì œê³± ì˜¤ì°¨ | ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ, ì´ìƒì¹˜ì— ë¯¼ê° |
| RMSE | MSEì˜ ì œê³±ê·¼ | ì›ë˜ ë‹¨ìœ„ì™€ ê°™ì•„ í•´ì„ ì‰¬ì›€ |
| MAE | í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ | ì´ìƒì¹˜ì— ëœ ë¯¼ê° |
| RÂ² | ê²°ì •ê³„ìˆ˜ | 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ |

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
```

---

#### ìŠ¬ë¼ì´ë“œ 42-44: ì–¸ì œ ì–´ë–¤ ì§€í‘œë¥¼ ì“¸ê¹Œ

> "ë¶„ë¥˜ì—ì„œ í´ë˜ìŠ¤ê°€ ê· í˜•í•˜ë©´ ì •í™•ë„ë„ ê´œì°®ìŠµë‹ˆë‹¤. ë¶ˆê· í˜•í•˜ë©´ F1ì´ë‚˜ ì¬í˜„ìœ¨ì„ ë´ì•¼ í•©ë‹ˆë‹¤."

> "íšŒê·€ì—ì„œ ì´ìƒì¹˜ê°€ ë§ìœ¼ë©´ MAEê°€ ë” ì•ˆì •ì ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” RMSEì™€ RÂ²ë¥¼ ê°™ì´ ë´…ë‹ˆë‹¤."

> "ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì–´ë–¤ ì˜¤ë¥˜ê°€ ë” ì¹˜ëª…ì ì¸ì§€ ìƒê°í•˜ê³  ì§€í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”."

---

### ì‹¤ìŠµí¸ (11ë¶„)

#### ìŠ¬ë¼ì´ë“œ 45-47: ì‹¤ìŠµ í™˜ê²½ ì¤€ë¹„

> "í’ˆì§ˆ ì˜ˆì¸¡ ë°ì´í„°ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤."

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# ë°ì´í„° ìƒì„±
np.random.seed(42)
n = 500
df = pd.DataFrame({
    'temperature': np.random.normal(85, 5, n),
    'pressure': np.random.normal(100, 10, n),
    'vibration': np.random.normal(0.5, 0.1, n)
})

# ë¶ˆëŸ‰ ì¡°ê±´
df['defect'] = ((df['temperature'] > 88) |
               (df['vibration'] > 0.6)).astype(int)
```

---

#### ìŠ¬ë¼ì´ë“œ 48-50: êµì°¨ê²€ì¦ ì‹¤ìŠµ

> "ë¨¼ì € ë‹¨ì¼ ë¶„í• ê³¼ êµì°¨ê²€ì¦ì„ ë¹„êµí•©ë‹ˆë‹¤."

```python
X = df[['temperature', 'pressure', 'vibration']]
y = df['defect']

# ë‹¨ì¼ ë¶„í•  (ì—¬ëŸ¬ ë²ˆ)
for i in range(5):
    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=i)
    model = RandomForestClassifier(random_state=42)
    model.fit(X_tr, y_tr)
    print(f"ì‹œë„ {i+1}: {model.score(X_te, y_te):.3f}")

# êµì°¨ê²€ì¦
model = RandomForestClassifier(random_state=42)
scores = cross_val_score(model, X, y, cv=5)
print(f"êµì°¨ê²€ì¦: {scores.mean():.3f} (Â±{scores.std():.3f})")
```

> "ë‹¨ì¼ ë¶„í• ì€ ì ìˆ˜ê°€ ë“¤ì­‰ë‚ ì­‰í•˜ì§€ë§Œ, êµì°¨ê²€ì¦ì€ ì•ˆì •ì ì¸ í‰ê· ì„ ì¤ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 51-53: ê³¼ëŒ€ì í•© ì‹¤í—˜

> "max_depthë¥¼ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ì—¬ì„œ ê³¼ëŒ€ì í•©ì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤."

```python
from sklearn.tree import DecisionTreeClassifier

# ê³¼ëŒ€ì í•© ëª¨ë¸
model_overfit = DecisionTreeClassifier(max_depth=None)  # ì œí•œ ì—†ìŒ
model_overfit.fit(X_train, y_train)
print(f"í•™ìŠµ: {model_overfit.score(X_train, y_train):.3f}")
print(f"í…ŒìŠ¤íŠ¸: {model_overfit.score(X_test, y_test):.3f}")

# ì ì ˆí•œ ëª¨ë¸
model_good = DecisionTreeClassifier(max_depth=5)
model_good.fit(X_train, y_train)
print(f"í•™ìŠµ: {model_good.score(X_train, y_train):.3f}")
print(f"í…ŒìŠ¤íŠ¸: {model_good.score(X_test, y_test):.3f}")
```

> "max_depth=Noneì´ë©´ í•™ìŠµ ì ìˆ˜ 1.0ì´ ë‚˜ì˜¤ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” ë–¨ì–´ì§‘ë‹ˆë‹¤. ì „í˜•ì ì¸ ê³¼ëŒ€ì í•©ì´ì—ìš”."

---

#### ìŠ¬ë¼ì´ë“œ 54-56: í•™ìŠµ ê³¡ì„  ì‹œê°í™”

> "í•™ìŠµ ê³¡ì„ ì„ ê·¸ë ¤ì„œ ì‹œê°ì ìœ¼ë¡œ ì§„ë‹¨í•©ë‹ˆë‹¤."

```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt

train_sizes, train_scores, val_scores = learning_curve(
    RandomForestClassifier(random_state=42), X, y, cv=5,
    train_sizes=[0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
)

plt.plot(train_sizes, train_scores.mean(axis=1), label='í•™ìŠµ')
plt.plot(train_sizes, val_scores.mean(axis=1), label='ê²€ì¦')
plt.xlabel('í•™ìŠµ ë°ì´í„° ìˆ˜')
plt.ylabel('ì ìˆ˜')
plt.legend()
plt.title('í•™ìŠµ ê³¡ì„ ')
```

> "ë‘ ê³¡ì„ ì´ ìˆ˜ë ´í•˜ë©´ì„œ ë†’ìœ¼ë©´ ì¢‹ì€ ëª¨ë¸ì…ë‹ˆë‹¤."

---

#### ìŠ¬ë¼ì´ë“œ 57-59: ë¶„ë¥˜ ë³´ê³ ì„œ ì‹¤ìŠµ

> "í˜¼ë™í–‰ë ¬ê³¼ ë¶„ë¥˜ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."

```python
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# í˜¼ë™í–‰ë ¬
print("í˜¼ë™í–‰ë ¬:")
print(confusion_matrix(y_test, y_pred))

# ë¶„ë¥˜ ë³´ê³ ì„œ
print("\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_test, y_pred, target_names=['ì •ìƒ', 'ë¶ˆëŸ‰']))
```

> "ì •ë°€ë„, ì¬í˜„ìœ¨, F1ì„ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶ˆëŸ‰ ì¬í˜„ìœ¨ì´ ë‚®ìœ¼ë©´ ì‹¤ì œ ë¶ˆëŸ‰ì„ ë§ì´ ë†“ì¹˜ê³  ìˆë‹¤ëŠ” ëœ»ì´ì—ìš”."

---

### ì •ë¦¬ (2ë¶„)

#### ìŠ¬ë¼ì´ë“œ 60-61: í•µì‹¬ ì •ë¦¬

> "ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤."

> "êµì°¨ê²€ì¦ì€ K-Foldë¡œ ì—¬ëŸ¬ ë²ˆ í‰ê°€í•´ì„œ í‰ê· ì„ ëƒ…ë‹ˆë‹¤. cross_val_score í•¨ìˆ˜ í•˜ë‚˜ë¡œ ë©ë‹ˆë‹¤."

> "ê³¼ëŒ€ì í•©ì€ í•™ìŠµ ì ìˆ˜ëŠ” ë†’ê³  í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” ë‚®ì€ ìƒíƒœì…ë‹ˆë‹¤. í•™ìŠµ ê³¡ì„ ìœ¼ë¡œ ì§„ë‹¨í•˜ì„¸ìš”."

> "ë¶„ë¥˜ëŠ” ì •ë°€ë„, ì¬í˜„ìœ¨, F1ì„ ë´ì•¼ í•©ë‹ˆë‹¤. classification_reportë¡œ í•œë²ˆì— ì¶œë ¥ë©ë‹ˆë‹¤."

> "íšŒê·€ëŠ” MSE, RMSE, MAE, RÂ²ë¥¼ ì”ë‹ˆë‹¤. ìƒí™©ì— ë§ëŠ” ì§€í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”."

---

#### ìŠ¬ë¼ì´ë“œ 62-63: ë‹¤ìŒ ì°¨ì‹œ ì˜ˆê³ 

> "ë‹¤ìŒ ì‹œê°„ì—ëŠ” ëª¨ë¸ ì„¤ì •ê°’ ìµœì í™”ë¥¼ ë°°ì›ë‹ˆë‹¤. max_depthë‚˜ n_estimators ê°™ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” GridSearchCVë¥¼ ë‹¤ë£¹ë‹ˆë‹¤."

> "ì˜¤ëŠ˜ ìˆ˜ì—… ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!"

---

## â“ ì˜ˆìƒ ì§ˆë¬¸ ë° ë‹µë³€

### Q1: K-Foldì—ì„œ KëŠ” ëª‡ìœ¼ë¡œ í•´ì•¼ í•˜ë‚˜ìš”?

> "ë³´í†µ 5 ë˜ëŠ” 10ì„ ì”ë‹ˆë‹¤. ë°ì´í„°ê°€ ì ìœ¼ë©´ Kë¥¼ í¬ê²Œ í•˜ê³ (Leave-One-Outê¹Œì§€), ë°ì´í„°ê°€ ë§ìœ¼ë©´ 5ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤. Kê°€ í¬ë©´ ê³„ì‚° ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤."

### Q2: êµì°¨ê²€ì¦ì„ í•˜ë©´ train_test_splitì€ ì•ˆ í•´ë„ ë˜ë‚˜ìš”?

> "êµì°¨ê²€ì¦ë§Œìœ¼ë¡œ í‰ê°€ëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ, ìµœì¢… ëª¨ë¸ì„ ë§Œë“¤ ë•ŒëŠ” ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œëŠ” êµì°¨ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì„ íƒ í›„, ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤."

### Q3: ì •í™•ë„ê°€ 95%ì¸ë° ì™œ ë¬¸ì œê°€ ë˜ë‚˜ìš”?

> "í´ë˜ìŠ¤ê°€ ë¶ˆê· í˜•í•˜ë©´ ì •í™•ë„ê°€ ë†’ì•„ë„ ì˜ë¯¸ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ìƒì´ 95%, ë¶ˆëŸ‰ì´ 5%ì¸ ë°ì´í„°ì—ì„œ ëª¨ë‘ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡í•´ë„ ì •í™•ë„ 95%ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë¶ˆëŸ‰ì€ í•˜ë‚˜ë„ ëª» ì¡ì•˜ì£ ."

### Q4: F1 Scoreê°€ ì •ë°€ë„, ì¬í˜„ìœ¨ë³´ë‹¤ ì¢‹ì€ ê±´ê°€ìš”?

> "í•­ìƒ ê·¸ë ‡ì§„ ì•ŠìŠµë‹ˆë‹¤. F1ì€ ë‘˜ì˜ ê· í˜•ì„ ë³´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì— ë”°ë¼ ì •ë°€ë„ê°€ ë” ì¤‘ìš”í•˜ê±°ë‚˜ ì¬í˜„ìœ¨ì´ ë” ì¤‘ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶ˆëŸ‰ ê²€ì¶œì—ì„œëŠ” ë³´í†µ ì¬í˜„ìœ¨ì„ ë” ë´…ë‹ˆë‹¤."

### Q5: í•™ìŠµ ê³¡ì„ ì—ì„œ ê°­ì´ ì•ˆ ì¤„ì–´ë“¤ë©´ìš”?

> "ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•˜ë‹¤ëŠ” ì‹ í˜¸ì…ë‹ˆë‹¤. ëª¨ë¸ ë³µì¡ë„ë¥¼ ë‚®ì¶”ê±°ë‚˜(max_depth ì¤„ì´ê¸°), ì •ê·œí™”ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. ë°ì´í„°ë¥¼ ë” ëª¨ìœ¼ëŠ” ê²ƒë„ ë°©ë²•ì…ë‹ˆë‹¤."

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [sklearn cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)
- [sklearn learning_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html)
- [sklearn classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)

### ê´€ë ¨ ì°¨ì‹œ
- 14ì°¨ì‹œ: ì„ í˜•/ë‹¤í•­íšŒê·€ (í‰ê°€ ì§€í‘œ ê¸°ì´ˆ)
- 16ì°¨ì‹œ: ëª¨ë¸ ì„¤ì •ê°’ ìµœì í™” (GridSearchCV)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ìˆ˜ì—… ì „:
- [ ] cross_val_score ì˜ˆì œ í…ŒìŠ¤íŠ¸
- [ ] learning_curve ì‹œê°í™” í™•ì¸
- [ ] ë¶ˆê· í˜• ë°ì´í„° ì˜ˆì œ ì¤€ë¹„

ìˆ˜ì—… ì¤‘:
- [ ] K-Fold ê°œë… ì‹œê°ì  ì„¤ëª…
- [ ] ê³¼ëŒ€ì í•©/ê³¼ì†Œì í•© ê°­ ë¹„êµ
- [ ] í˜¼ë™í–‰ë ¬ í•´ì„
- [ ] ì •ë°€ë„ vs ì¬í˜„ìœ¨ ìƒí™©ë³„ ì„¤ëª…

ìˆ˜ì—… í›„:
- [ ] ì‹¤ìŠµ ì½”ë“œ ë°°í¬
- [ ] GridSearchCV ì˜ˆê³ 
