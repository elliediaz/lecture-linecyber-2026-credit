# 번외D: ML 워크플로우 종합 실습 - 강사 스크립트

## 개요
- **총 시간**: 30분
- **구성**: 이론 10분 + 실습 20분
- **난이도**: 초급 (복습 중심)
- **데이터셋**: Titanic (seaborn 내장)

---

## Part 1: 문제 정의 (3분)

### 슬라이드 1-3: 도입 (1분)

> "오늘은 지금까지 배운 머신러닝 내용을 **처음부터 끝까지 한 번에** 경험해보겠습니다."

> "각 단계는 알지만 전체 흐름이 연결이 안 된다는 분들이 많습니다. 오늘 실습을 통해 그 흐름을 잡아봅시다."

### 슬라이드 4-5: 문제 유형 판단 (2분)

> "머신러닝의 첫 단계는 **문제 유형 판단**입니다. 분류인가요, 회귀인가요?"

> "타이타닉 생존 예측은 '생존했다/사망했다'를 맞추는 것이므로 **이진 분류** 문제입니다."

**예상 질문**: "분류와 회귀를 어떻게 구분하나요?"
**답변**: "예측 대상이 범주(카테고리)면 분류, 숫자(연속값)면 회귀입니다."

---

## Part 2: 데이터 탐색 (5분)

### 슬라이드 6-8: 데이터 로드 및 구조 (2분)

> "먼저 데이터를 로드하고 어떤 정보가 있는지 확인합니다."

```python
import seaborn as sns
df = sns.load_dataset('titanic')
df.info()
```

> "891명의 승객 데이터, 15개 컬럼이 있네요. 나이에 결측치가 있습니다."

### 슬라이드 9-12: 탐색적 분석 (3분)

> "성별에 따른 생존율을 보면, 여성이 74%, 남성이 19%입니다. 큰 차이가 있죠?"

> "객실 등급도 마찬가지입니다. 1등석 63%, 3등석 24%."

> "이런 탐색을 통해 **어떤 특성이 예측에 유용할지** 감을 잡습니다."

---

## Part 3: 데이터 전처리 (7분)

### 슬라이드 13-15: 결측치 처리 (3분)

> "모델은 결측치를 처리하지 못합니다. 반드시 처리해야 합니다."

> "나이는 중앙값으로 대체합니다. 왜 평균이 아닌 중앙값인가요?"

> "나이에 80세 같은 이상치가 있으면 평균이 왜곡됩니다. 중앙값이 더 안정적입니다."

```python
df['age'].fillna(df['age'].median(), inplace=True)
```

### 슬라이드 16-18: 인코딩 (2분)

> "성별이 male, female 문자열이죠? 모델은 숫자만 이해합니다."

> "get_dummies로 원-핫 인코딩합니다. sex_male 컬럼이 생기고 1이면 남성입니다."

```python
df = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)
```

### 슬라이드 19-20: 데이터 분할 (2분)

> "전처리가 끝나면 학습용과 테스트용으로 나눕니다. 80:20이 일반적입니다."

> "stratify=y는 중요합니다. 원본의 생존:사망 비율을 학습/테스트에도 유지합니다."

---

## Part 4: 모델 학습 (5분)

### 슬라이드 21-24: 3가지 모델 비교 (5분)

> "이제 3가지 모델을 비교해봅니다. Logistic, DecisionTree, RandomForest."

```python
for name, model in models.items():
    model.fit(X_train, y_train)
    print(f"{name}: {model.score(X_test, y_test):.3f}")
```

> "결과를 보면 RandomForest가 82.1%로 가장 높습니다."

> "실무에서도 이렇게 여러 모델을 비교하고 가장 좋은 것을 선택합니다."

**예상 질문**: "항상 RandomForest가 좋은가요?"
**답변**: "아닙니다. 데이터에 따라 다릅니다. 그래서 비교가 필요합니다."

---

## Part 5: 모델 평가 (5분)

### 슬라이드 25-28: 평가 지표 (5분)

> "정확도 82%면 좋은 건가요? 상황에 따라 다릅니다."

> "혼동 행렬을 보면, 실제 생존자 69명 중 42명만 찾았습니다. 재현율 61%입니다."

> "제조업에서 불량품 탐지라면 재현율이 중요합니다. 불량을 놓치면 안 되니까요."

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
```

---

## Part 6: 결과 해석 (5분)

### 슬라이드 29-33: 특성 중요도 (3분)

> "RandomForest는 특성 중요도를 알려줍니다. 어떤 특성이 예측에 가장 중요했는지."

> "성별이 28%, 요금 26%, 나이 24%입니다."

> "이것이 **비즈니스 인사이트**입니다. '여성이 생존에 유리했다'는 것을 데이터로 확인한 거죠."

### 슬라이드 34-37: 정리 (2분)

> "오늘 전체 워크플로우를 한 번에 경험했습니다."

> "문제 정의 → EDA → 전처리 → 학습 → 평가 → 해석. 이 흐름을 기억하세요."

---

## 실습 안내 (10분)

> "이제 직접 해봅시다. code.py 파일을 열고 한 단계씩 실행해보세요."

### 실습 체크포인트

1. 데이터 로드 및 info() 확인 (2분)
2. 결측치 처리 (2분)
3. 인코딩 및 분할 (2분)
4. 3가지 모델 학습 및 비교 (2분)
5. classification_report 출력 (2분)

---

## 마무리

> "오늘 배운 워크플로우는 12-17차시에서 각 단계를 더 자세히 배울 예정입니다."

> "다음 번외 E에서는 특성 공학을 배워 더 좋은 특성을 만들어봅니다."

---

## 예상 Q&A

**Q1**: "결측치를 삭제하면 안 되나요?"
**A1**: "가능하지만 데이터가 줄어듭니다. 17%가 결측이면 삭제보다 대체가 낫습니다."

**Q2**: "왜 drop_first=True를 쓰나요?"
**A2**: "male=0이면 female이라는 걸 알 수 있으니 하나만 있어도 됩니다. 다중공선성도 줄어듭니다."

**Q3**: "stratify는 항상 써야 하나요?"
**A3**: "클래스 불균형이 있을 때 특히 중요합니다. 습관적으로 쓰는 것이 좋습니다."

**Q4**: "실무에서는 몇 개 모델을 비교하나요?"
**A4**: "보통 3-5개 정도 비교하고, 가장 좋은 모델을 튜닝합니다."
