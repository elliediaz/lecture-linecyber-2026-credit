---
marp: true
theme: default
paginate: true
header: '제조 AI 과정 | 4차시'
footer: '공개 데이터셋 확보 및 데이터 생태계 이해'
style: |
  section {
    font-family: 'Malgun Gothic', 'Apple SD Gothic Neo', sans-serif;
    background-color: #f8fafc;
  }
  h1 { color: #1e40af; font-size: 2.2em; }
  h2 { color: #2563eb; font-size: 1.6em; }
  h3 { color: #3b82f6; }
  code { background-color: #e2e8f0; padding: 2px 6px; border-radius: 4px; }
  pre { background-color: #1e293b; color: #e2e8f0; }
  table { font-size: 0.9em; }
  .highlight { background-color: #fef3c7; padding: 2px 6px; }
---

# 공개 데이터셋 확보 및 데이터 생태계 이해

## 4차시 | Part I. AI 윤리와 환경 구축

**AI 학습의 기반: 데이터 생태계와 공개 데이터 활용 전략**

---

# 학습목표

이 차시를 마치면 다음을 할 수 있습니다:

1. **공공데이터**의 법적 정의와 활용 목적을 이해한다
2. **주요 데이터 포털**의 특성과 차이점을 비교한다
3. **데이터셋 구조**와 관련 용어를 정확히 이해한다
4. **실제 데이터**를 다운로드하고 구조를 확인한다

---

# 오늘의 진행 순서

## 이론 (15분) + 실습 (15분)

| 순서 | 학습내용 | 시간 |
|------|----------|------|
| 1 | **공공데이터의 정의와 활용** | 5분 |
| 2 | **주요 데이터 포털의 특성** | 5분 |
| 3 | **데이터셋 구조와 용어** | 5분 |
| 4 | **실습: 공개 데이터 다운로드** | 15분 |

---

<!-- _class: lead -->

# 1. 공공데이터의 정의와 활용

## 공공데이터란 무엇이며, AI 학습에 어떻게 활용되는가?

---

# 공공데이터의 법적 정의

## 공공데이터법 제2조

> **"공공데이터"**란 데이터베이스, 전자화된 파일 등 **공공기관이 법령 등에서 정하는 목적을 위하여 생성 또는 취득하여 관리하고 있는 전자적 방식**으로 처리된 자료 또는 정보

## 핵심 3요소
| 요소 | 설명 | 예시 |
|------|------|------|
| **생성 주체** | 공공기관 | 정부, 지자체, 공기업 |
| **형태** | 전자적 방식 | CSV, API, DB |
| **목적** | 공공 목적 | 통계, 행정, 서비스 |

---

# 공공기관의 범위

## 공공데이터를 제공하는 기관 (890개+)

| 구분 | 예시 | 데이터 특성 |
|------|------|------------|
| **국가기관** | 행정부처, 국회, 법원 | 정책, 법률 데이터 |
| **지방자치단체** | 광역시도, 시군구 | 지역 행정 데이터 |
| **공공기관** | 한국전력, 건강보험공단 | 산업, 의료 데이터 |
| **지방공기업** | 도시공사, 도시철도공사 | 인프라 데이터 |
| **특수법인** | KOTRA, 중진공 | 무역, 중소기업 데이터 |

---

# 공공데이터의 종류

## 형태별 분류

| 유형 | 형식 | 접근 방식 | 활용 예 |
|------|------|----------|---------|
| **파일 데이터** | CSV, Excel, JSON | 다운로드 | 통계 분석 |
| **오픈 API** | REST/SOAP | 실시간 호출 | 앱 연동 |
| **표준 데이터** | 공통 규격 | 다운로드/API | 주소, 법인 |
| **링크드 데이터** | RDF, LOD | SPARQL | 지식 그래프 |

> AI 학습에는 **파일 데이터(CSV)** 또는 **API** 형태 주로 활용

---

# 공공데이터 제공 원칙

## 공공데이터법의 5대 원칙

```
┌─────────────────────────────────────────────────────────────┐
│                   공공데이터 제공 5대 원칙                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1️⃣ 무료 제공      실비 외 무료로 제공                        │
│                                                              │
│  2️⃣ 기계 판독      CSV, JSON 등 개방형 포맷                   │
│                                                              │
│  3️⃣ 최신성 유지    정기적 업데이트 의무                        │
│                                                              │
│  4️⃣ 정확성 확보    오류 최소화, 품질 관리                      │
│                                                              │
│  5️⃣ 재이용 허용    상업적 이용 가능 (별도 제한 시 명시)         │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

---

# AI 학습에서 공공데이터의 역할

## 데이터 파이프라인에서의 위치

```
┌─────────────────────────────────────────────────────────────┐
│                    AI 학습 데이터 파이프라인                    │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   [공공데이터]  +  [민간데이터]  +  [자체생성]  = AI 학습셋     │
│       │              │               │                       │
│   인프라정보      기업데이터      센서수집                     │
│   통계자료        고객데이터      실험데이터                   │
│   환경정보        거래데이터      라벨링데이터                 │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

---

# 공공데이터 활용 사례

## 제조업 AI 프로젝트 활용 예시

| 프로젝트 | 사용 공공데이터 | 활용 방법 |
|----------|----------------|----------|
| **품질 예측** | 기상청 날씨 데이터 | 환경 요인으로 품질 영향 분석 |
| **수요 예측** | 통계청 경기지수 | 외부 경제 지표 반영 |
| **물류 최적화** | 도로교통 혼잡도 | 배송 경로 예측 |
| **에너지 관리** | 전력거래소 요금 | 피크 시간 예측 |
| **설비 관리** | 공단 설비 이력 | 유사 설비 고장 패턴 |

---

# 공공데이터 활용의 장단점

## 장점과 주의점

| 장점 | 주의점 |
|------|--------|
| ✅ **무료** 또는 저렴한 비용 | ⚠️ 갱신 주기가 느릴 수 있음 |
| ✅ **법적 근거** 있는 신뢰성 | ⚠️ 형식이 통일되지 않음 |
| ✅ **대량 데이터** 확보 가능 | ⚠️ AI용 라벨이 없는 경우 많음 |
| ✅ **상업적 이용** 가능 | ⚠️ 개인정보 비식별화 확인 필요 |
| ✅ **표준 API** 제공 | ⚠️ API 호출 제한 있음 |

---

<!-- _class: lead -->

# 2. 주요 데이터 포털의 특성

## 어떤 포털에서 어떤 데이터를 찾을 수 있는가?

---

# 국내 4대 데이터 포털

## 핵심 플랫폼 비교

| 포털 | 운영 | 규모 | 특화 분야 |
|------|------|------|----------|
| **공공데이터포털** | 행정안전부 | 45만+ | 정부 공식 데이터 |
| **AI 허브** | NIA | 700+ | AI 학습용 데이터 |
| **Kaggle** | Google | 20만+ | 글로벌 ML 데이터 |
| **통계청 KOSIS** | 통계청 | 100만+ | 국가 공식 통계 |

---

# 공공데이터포털 (data.go.kr)

## 플랫폼 특성

- **운영**: 행정안전부
- **규모**: **45만+ 데이터셋**, 일일 **3,000만+ API 호출**
- **특징**: 대한민국 공식 공공데이터 게이트웨이

## 데이터 구성
| 유형 | 건수 | 접근 방법 |
|------|------|----------|
| 파일 데이터 | 38만+ | 웹 다운로드 |
| 오픈 API | 7만+ | API 키 발급 |
| 표준 데이터 | 300+ | 표준 규격 준수 |

---

# 공공데이터포털 - 제조 관련 데이터

## 제조업에서 활용 가능한 데이터

| 분류 | 데이터 예시 | 활용 사례 |
|------|------------|----------|
| **산업통계** | 광업제조업조사, 산업생산지수 | 시장 분석 |
| **품질안전** | 제품안전정보, 리콜현황 | 품질 예측 |
| **에너지** | 산업용 전력, 가스사용량 | 비용 최적화 |
| **환경** | 대기배출량, 폐기물 | 환경 규제 대응 |
| **물류** | 수출입통계, 물동량 | 공급망 분석 |
| **인력** | 고용동향, 임금 | 인력 계획 |

---

# 공공데이터포털 - 파일 형식

## 제공되는 데이터 포맷

| 형식 | 확장자 | 특성 | AI 활용도 |
|------|--------|------|----------|
| **CSV** | .csv | 범용, 경량, 구조화 | ⭐⭐⭐ 최고 |
| **JSON** | .json | 계층 구조, API 친화 | ⭐⭐⭐ |
| **XML** | .xml | 문서형, 레거시 호환 | ⭐⭐ |
| **Excel** | .xlsx | 편집 용이 | ⭐⭐ |
| **PDF/HWP** | .pdf/.hwp | 문서 보고서 | ⭐ |

> AI 학습용으로는 **CSV** 또는 **JSON** 형태 권장

---

# AI 허브 (aihub.or.kr)

## 플랫폼 특성

- **운영**: 한국지능정보사회진흥원(NIA)
- **규모**: **700+ AI 학습 데이터셋**
- **특징**: **고품질 라벨링** 포함, AI 모델 학습 전용

## 데이터 카테고리
| 분야 | 데이터 형태 | 예시 |
|------|------------|------|
| **시각지능** | 이미지, 영상 | 불량 이미지, CCTV |
| **언어지능** | 텍스트, 음성 | 제조 매뉴얼, 음성명령 |
| **융합** | 센서, 시계열 | 설비 진동, 공정 데이터 |

---

# AI 허브 - 제조 분야 데이터셋

## 주요 제조 AI 데이터셋

| 데이터셋 | 규모 | 라벨 유형 | 활용 모델 |
|----------|------|----------|----------|
| **제조 공정 이상탐지** | 10만+ | 이상/정상 | 이상탐지 |
| **용접 결함 이미지** | 5만+ | 바운딩박스 | 객체탐지 |
| **설비 진동 센서** | 100만+ | 고장/정상 | 시계열 예측 |
| **PCB 불량 이미지** | 3만+ | 분류 라벨 | 이미지 분류 |
| **반도체 공정 데이터** | 50만+ | 품질 등급 | 품질 예측 |

> 회원가입 후 무료 다운로드 (일부 승인 필요)

---

# AI 허브 - 데이터 패키지 구조

## 제공 파일 구성

```
AI_HUB_DATASET/
├── 01_원천데이터/           # 실제 데이터
│   ├── images/             # 이미지 파일
│   └── sensor_data/        # 센서 CSV
├── 02_라벨링데이터/         # 라벨 정보
│   ├── annotations.json    # JSON 라벨
│   └── labels.csv          # CSV 라벨
├── 03_메타데이터/           # 데이터 설명
│   └── metadata.json
└── README.md               # 활용 가이드
```

---

# Kaggle (kaggle.com)

## 플랫폼 특성

- **운영**: Google
- **규모**: **20만+ 데이터셋**, **1,600만+ 사용자**
- **특징**: 글로벌 커뮤니티, 경진대회, 노트북 공유

## 핵심 기능
| 기능 | 설명 | 장점 |
|------|------|------|
| **Datasets** | 무료 데이터셋 | 다양한 분야 |
| **Competitions** | 상금 경진대회 | 실력 검증 |
| **Notebooks** | 코드 공유/실행 | 바로 학습 |
| **Discussions** | 커뮤니티 Q&A | 문제 해결 |

---

# Kaggle - 제조 관련 데이터셋

## 인기 제조 데이터셋

| 데이터셋 | 크기 | 용도 | 인기도 |
|----------|------|------|--------|
| **Predictive Maintenance** | 10K+ | 설비 고장 예측 | ⭐⭐⭐ |
| **Steel Defect Detection** | 12K img | 철강 결함 탐지 | ⭐⭐⭐ |
| **Semiconductor Yield** | 1K+ | 반도체 수율 | ⭐⭐ |
| **Engine Degradation** | 100K+ | 엔진 열화 | ⭐⭐ |
| **Bosch Production Line** | 1M+ | 생산라인 품질 | ⭐⭐⭐ |

---

# UCI ML Repository

## 플랫폼 특성

- **운영**: UC Irvine 대학
- **규모**: **600+ ML 벤치마크 데이터셋**
- **특징**: 학술 연구 표준, 논문 인용 다수

## 제조 관련 데이터셋
| 데이터셋 | ID | 샘플 수 | 용도 |
|----------|-----|--------|------|
| Steel Plates Faults | 198 | 1,941 | 결함 분류 |
| SECOM | 179 | 1,567 | 반도체 불량 |
| Gas Sensor | 224 | 13,910 | 가스 분류 |

---

# 포털별 특성 비교

## 종합 비교표

| 항목 | 공공데이터포털 | AI 허브 | Kaggle | UCI |
|------|---------------|---------|--------|-----|
| **언어** | 한국어 | 한국어 | 영어 | 영어 |
| **라벨링** | 없음 | 고품질 | 다양 | 있음 |
| **제조특화** | 통계위주 | 제조AI특화 | 범용 | 학술 |
| **API** | 풍부 | 일부 | 없음 | 없음 |
| **커뮤니티** | 약함 | 보통 | 매우활발 | 약함 |
| **노트북** | 없음 | 일부 | 풍부 | 없음 |

---

# 포털 선택 가이드

## 상황별 추천 포털

| 목적 | 1순위 | 2순위 | 이유 |
|------|-------|-------|------|
| **제조 AI 모델 학습** | AI 허브 | Kaggle | 라벨링 데이터 |
| **경제/산업 분석** | 공공데이터포털 | 통계청 | 공식 통계 |
| **ML 알고리즘 학습** | UCI | Kaggle | 벤치마크 |
| **실시간 데이터 연동** | 공공데이터포털 | - | API 제공 |
| **글로벌 트렌드 파악** | Kaggle | - | 커뮤니티 |

---

<!-- _class: lead -->

# 3. 데이터셋 구조와 용어

## 데이터를 다루기 위한 기본 용어 이해

---

# 테이블 형태 데이터의 구조

## 기본 구성 요소

```
           열(Column) = 변수(Variable) = 특성(Feature)
              ↓         ↓         ↓         ↓
            ┌───────┬───────┬───────┬───────┐
            │온도   │습도   │압력   │불량여부│ ← 헤더(Header)
            ├───────┼───────┼───────┼───────┤
 행(Row)  → │85.2   │52     │1.01   │0      │ ← 레코드(Record)
 = 관측치   │87.5   │48     │1.03   │0      │   = 샘플(Sample)
 = 인스턴스 │92.1   │55     │0.98   │1      │   = 관찰(Observation)
            └───────┴───────┴───────┴───────┘
                 ↑                       ↑
             독립변수(X)              종속변수(y)
             = 입력(Input)           = 타겟(Target)
```

---

# 용어 정리: 행과 열

## Row (행) 관련 용어

| 용어 | 영어 | 설명 |
|------|------|------|
| **행** | Row | 표의 가로 한 줄 |
| **레코드** | Record | 하나의 데이터 항목 |
| **샘플** | Sample | ML에서 하나의 데이터 |
| **관측치** | Observation | 통계에서 하나의 측정 |
| **인스턴스** | Instance | 객체 지향에서 하나의 객체 |

> 모두 같은 개념, 문맥에 따라 다른 용어 사용

---

# 용어 정리: 행과 열

## Column (열) 관련 용어

| 용어 | 영어 | 설명 |
|------|------|------|
| **열** | Column | 표의 세로 한 줄 |
| **변수** | Variable | 변할 수 있는 값 |
| **특성** | Feature | ML에서 입력 속성 |
| **속성** | Attribute | 데이터의 특성 |
| **필드** | Field | DB에서 열 |

---

# 변수의 역할에 따른 분류

## 독립변수 vs 종속변수

| 구분 | 이름들 | 역할 | 예시 |
|------|--------|------|------|
| **입력** | 독립변수, X, Feature, Input, 설명변수 | 예측에 사용 | 온도, 습도, 압력 |
| **출력** | 종속변수, y, Target, Label, 반응변수 | 예측 대상 | 불량여부, 생산량 |

```python
# pandas에서의 표현
X = df[['온도', '습도', '압력']]   # 독립변수 (Features)
y = df['불량여부']                  # 종속변수 (Target)
```

---

# 변수의 데이터 타입

## 수치형 vs 범주형

| 대분류 | 소분류 | 설명 | 예시 |
|--------|--------|------|------|
| **수치형** | 연속형 | 무한히 많은 값 | 온도(85.234°C) |
| (Numerical) | 이산형 | 정수값만 | 불량개수(0,1,2) |
| **범주형** | 명목형 | 순서 없음 | 라인(A,B,C) |
| (Categorical) | 순서형 | 순서 있음 | 등급(상>중>하) |
| | 이진형 | 두 가지만 | 불량(0/1) |

---

# 데이터 품질 용어

## 주요 품질 이슈

| 용어 | 영어 | 설명 | 처리 방법 |
|------|------|------|----------|
| **결측치** | Missing Value | 값이 없음 (NaN) | 삭제/대체 |
| **이상치** | Outlier | 비정상적 값 | 제거/변환 |
| **중복** | Duplicate | 동일 레코드 반복 | 삭제 |
| **노이즈** | Noise | 의미없는 변동 | 스무딩 |
| **불균형** | Imbalance | 클래스 비율 불균형 | 샘플링 |

---

# 데이터셋 분할 용어

## ML에서의 데이터 분할

```
                 전체 데이터셋 (100%)
                        │
      ┌─────────────────┼─────────────────┐
      ▼                 ▼                 ▼
 훈련 세트          검증 세트          테스트 세트
 (Training)       (Validation)        (Test)
    70%               15%               15%
      │                 │                 │
 모델 학습        하이퍼파라미터       최종 성능
                    튜닝             (1회 사용)
```

---

# 파일 형식별 용어

## CSV, JSON의 핵심 용어

| 형식 | 용어 | 설명 | 예시 |
|------|------|------|------|
| **CSV** | Delimiter | 구분자 | 쉼표(,), 탭(\t) |
| | Header | 첫 행 (열 이름) | 온도,습도,압력 |
| | Encoding | 문자 인코딩 | UTF-8, CP949 |
| **JSON** | Key | 키 (열 이름) | "temperature" |
| | Value | 값 | 85.2 |
| | Nested | 중첩 구조 | {"sensor": {"temp": 85}} |

---

# 메타데이터란?

## 데이터에 대한 데이터

```json
{
  "name": "제조공정_품질데이터",
  "version": "1.0",
  "created": "2024-01-15",
  "rows": 10000,
  "columns": 15,
  "source": "스마트공장 A",
  "license": "CC-BY",
  "description": "생산라인 센서 데이터",
  "schema": [
    {"name": "temperature", "type": "float", "unit": "°C"},
    {"name": "defect", "type": "int", "values": [0, 1]}
  ]
}
```

---

# 라이선스 용어

## 데이터 이용 조건

| 라이선스 | 상업이용 | 수정 | 출처표시 |
|----------|---------|------|---------|
| **CC0 (퍼블릭도메인)** | O | O | X |
| **CC-BY** | O | O | O |
| **CC-BY-NC** | X | O | O |
| **공공누리 1유형** | O | O | O |
| **공공누리 4유형** | X | X | O |

> 데이터 사용 전 **라이선스 반드시 확인**

---

# 용어 종합 정리표

## 자주 혼동되는 용어

| 한국어 | 영어 | 동의어 |
|--------|------|--------|
| 행 | Row | Record, Sample, Instance |
| 열 | Column | Feature, Variable, Field |
| 독립변수 | X | Feature, Input, Predictor |
| 종속변수 | y | Target, Label, Output |
| 결측치 | Missing | NaN, Null, NA |
| 훈련데이터 | Training Set | Train Data |
| 테스트데이터 | Test Set | Holdout Set |

---

<!-- _class: lead -->

# - 실습편 -

## 4차시

**실제 데이터 포털에서 데이터 다운로드하기**

---

# 실습 개요

## 오늘의 실습 (15분)

1. **공공데이터포털**에서 CSV 다운로드 (5분)
2. **AI 허브/Kaggle**에서 데이터 확보 (5분)
3. 다운로드한 데이터 **구조 확인** (5분)

## 준비물
- Python 환경 (Jupyter Notebook)
- 웹 브라우저 (포털 접속용)
- 각 포털 회원가입 (사전 준비)

---

# 실습 1: 공공데이터포털 - 파일 다운로드

## 단계별 진행

```python
# === 공공데이터포털 파일 데이터 다운로드 ===

# 1. data.go.kr 접속
# 2. 검색창에 "제조업" 또는 "스마트공장" 입력
# 3. 왼쪽 필터에서 "파일데이터" 선택
# 4. CSV 형식 데이터 선택 → 다운로드

# 다운로드 후 Python에서 로드
import pandas as pd

# 한글 인코딩 주의 (CP949 또는 UTF-8)
df = pd.read_csv('다운로드파일.csv', encoding='cp949')
# 또는
df = pd.read_csv('다운로드파일.csv', encoding='utf-8')

print("데이터 로드 완료!")
print(f"크기: {df.shape}")
```

---

# 실습 1: 공공데이터포털 - API 호출

## API 키 발급 및 사용

```python
import requests

# 1. data.go.kr → 로그인 → API 활용 신청
# 2. 승인 후 API 키 확인

API_KEY = "YOUR_API_KEY_HERE"

# API 호출 예시
url = "http://apis.data.go.kr/B552015/..."
params = {
    "serviceKey": API_KEY,
    "pageNo": 1,
    "numOfRows": 100,
    "resultType": "json"
}

response = requests.get(url, params=params)
data = response.json()
print("API 응답:", data.keys())
```

---

# 실습 2: AI 허브 - 제조 데이터

## 다운로드 및 구조 확인

```python
# 1. aihub.or.kr 접속 → 로그인
# 2. 데이터 → 제조 카테고리 선택
# 3. 원하는 데이터셋 다운로드 신청

import os
import json

# 다운로드 폴더 구조 확인
data_dir = "./aihub_download/"

for root, dirs, files in os.walk(data_dir):
    level = root.replace(data_dir, '').count(os.sep)
    indent = '  ' * level
    print(f'{indent}{os.path.basename(root)}/')
    for file in files[:3]:  # 파일 3개만 표시
        print(f'{indent}  {file}')
```

---

# 실습 2: AI 허브 - 라벨 데이터 확인

## JSON 라벨 파일 분석

```python
import json

# 라벨 파일 로드
with open('label_sample.json', 'r', encoding='utf-8') as f:
    label = json.load(f)

# 구조 확인
print("=== 라벨 파일 구조 ===")
print(f"키 목록: {list(label.keys())}")

# 라벨 정보 출력
if 'annotations' in label:
    print(f"라벨 개수: {len(label['annotations'])}")
    print(f"첫 번째 라벨: {label['annotations'][0]}")
```

---

# 실습 3: Kaggle - 데이터셋 다운로드

## 웹에서 다운로드

```python
# 1. kaggle.com → 로그인
# 2. Datasets → "predictive maintenance" 검색
# 3. Download 클릭 → ZIP 파일 저장

import zipfile
import pandas as pd

# 압축 해제
with zipfile.ZipFile('archive.zip', 'r') as z:
    z.extractall('./kaggle_data/')

# 데이터 로드
df = pd.read_csv('./kaggle_data/predictive_maintenance.csv')
print(f"Kaggle 데이터: {df.shape}")
print(df.head())
```

---

# 실습 4: 데이터 구조 종합 확인

## 체크리스트 함수

```python
def check_dataset(df, name="Dataset"):
    """데이터셋 구조 확인 함수"""
    print("=" * 50)
    print(f"📊 {name}")
    print("=" * 50)

    # 기본 정보
    print(f"\n1. 크기: {df.shape[0]:,}행 × {df.shape[1]}열")

    # 데이터 타입
    print(f"\n2. 데이터 타입:")
    for dtype, count in df.dtypes.value_counts().items():
        print(f"   {dtype}: {count}개")

    # 결측치
    missing = df.isnull().sum().sum()
    print(f"\n3. 결측치: {missing:,}개 ({missing/df.size*100:.1f}%)")
```

---

# 실습 4: 데이터 구조 종합 확인 (계속)

## 체크리스트 함수 (계속)

```python
def check_dataset(df, name="Dataset"):
    # (앞 부분 계속)

    # 컬럼 목록
    print(f"\n4. 컬럼 목록:")
    for i, col in enumerate(df.columns):
        dtype = df[col].dtype
        print(f"   {i+1}. {col} ({dtype})")

    # 수치형 통계
    print(f"\n5. 수치형 변수 요약:")
    print(df.describe().round(2))

    print("\n" + "=" * 50)

# 사용
check_dataset(df, "제조 품질 데이터")
```

---

# 실습 결과 정리

## 다운로드 데이터 비교

```python
# 각 포털에서 받은 데이터 비교
datasets = {
    "공공데이터포털": pd.read_csv("public.csv", encoding='cp949'),
    "AI 허브": pd.read_csv("aihub.csv"),
    "Kaggle": pd.read_csv("kaggle.csv")
}

# 비교표 생성
comparison = []
for name, df in datasets.items():
    comparison.append({
        "포털": name,
        "행": len(df),
        "열": len(df.columns),
        "결측률(%)": round(df.isnull().mean().mean()*100, 1)
    })

print(pd.DataFrame(comparison).to_string(index=False))
```

---

# 핵심 요약

## 4차시 학습내용 정리

### 1. 공공데이터의 정의와 활용
- 공공기관이 생성/관리하는 전자적 자료
- 무료 제공, 기계판독 가능, 재이용 허용 원칙
- AI 학습의 기반 데이터로 활용

### 2. 주요 데이터 포털의 특성
- **공공데이터포털**: 정부 공식, API 풍부
- **AI 허브**: AI 학습 특화, 고품질 라벨
- **Kaggle**: 글로벌, 커뮤니티, 노트북

---

# 핵심 요약 (계속)

### 3. 데이터셋 구조와 용어
- **행(Row)** = 레코드 = 샘플 = 관측치
- **열(Column)** = 변수 = 특성 = 필드
- **X(독립변수)** = 입력 = Feature
- **y(종속변수)** = 타겟 = Label
- **결측치, 이상치, 불균형** 등 품질 이슈

---

# 다음 차시 예고

## 5차시: 기초 기술통계량과 탐색적 시각화

- 대표값: 평균, 중앙값, 최빈값
- 퍼짐: 표준편차, 분산, 범위
- 시각화: 히스토그램, 상자그림, 산점도

> 오늘 확보한 데이터를 분석하고 시각화합니다!

---

# 감사합니다

## 4차시: 공개 데이터셋 확보 및 데이터 생태계 이해

**제조데이터를 활용한 AI 이해와 예측 모델 구축**

수고하셨습니다!
