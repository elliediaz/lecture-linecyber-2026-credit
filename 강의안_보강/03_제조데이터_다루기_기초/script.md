# [3차시] 제조 데이터 다루기 기초 - 강사 스크립트 (보강판)

## 강의 정보
- **차시**: 3차시 (25-30분)
- **유형**: 이론 + 실습
- **구성**: 이론 10분 + 실습 15-20분
- **대상**: 비전공자, AI 입문자, 제조업 종사자

---

## 시간 배분

| 섹션 | 내용 | 시간 |
|------|------|------|
| 1 | 도입 및 NumPy 소개 | 4분 |
| 2 | Pandas DataFrame 기초 | 4분 |
| 3 | 실습: 센서 데이터 분석 | 6분 |
| 4 | 실습: 생산 데이터 분석 | 8분 |
| 5 | 정리 및 Q&A | 3분 |

---

## 도입부 (4분)

### 인사 및 지난 시간 복습 [1min]

> 안녕하세요, 3차시를 시작하겠습니다.
>
> 지난 시간에는 Python 기초를 배웠죠?
> 변수, 자료형, 조건문, 반복문을 익혔습니다.
>
> 오늘은 Python의 가장 강력한 무기인 **NumPy와 Pandas**를 배웁니다.
> 이 두 라이브러리가 있어야 본격적인 데이터 분석이 가능해요.

### 학습목표 안내 [1min]

> 오늘 수업을 마치면 다음을 할 수 있습니다.
>
> **첫째**, NumPy 배열의 개념과 기본 연산을 이해합니다.
> 센서 데이터 같은 숫자 데이터를 빠르게 처리할 수 있어요.
>
> **둘째**, Pandas DataFrame으로 표 형태 데이터를 다룹니다.
> Excel처럼 행과 열로 구성된 데이터를 다룰 수 있어요.
>
> **셋째**, CSV 파일을 불러오고 제조 데이터를 탐색합니다.
> 실제 데이터 파일을 읽고 분석하는 방법을 배워요.

### 왜 NumPy와 Pandas인가? [2min]

> 왜 NumPy와 Pandas가 필요할까요?
>
> 지난 시간에 리스트로 평균을 구했죠?
> for문 돌면서 합계 구하고, 개수로 나누고...
>
> NumPy를 쓰면 이게 딱 한 줄이에요.
>
> ```python
> average = production.mean()
> ```
>
> 그리고 속도가 **100배** 빠릅니다.
> 데이터가 수만 건, 수십만 건일 때 이 차이는 어마어마해요.
>
> Pandas는 Excel처럼 표 형태 데이터를 다룹니다.
> 생산일지, 센서 로그, 품질 데이터... 전부 표 형태잖아요?
> Pandas가 이런 데이터를 아주 쉽게 처리해줍니다.

---

## NumPy 소개 (3min)

### NumPy란? [1min]

> NumPy는 **Numerical Python**의 줄임말입니다.
> 숫자 계산에 특화된 라이브러리예요.
>
> 핵심은 **ndarray**라는 배열 객체입니다.
> Python 리스트보다 훨씬 빠르고 강력해요.
>
> ```python
> import numpy as np
> temps = np.array([82, 85, 88, 95, 84])
> ```
>
> 이렇게 배열을 만들면 통계 함수를 바로 쓸 수 있어요.

### 벡터화 연산 [1min]

> NumPy의 가장 큰 장점은 **벡터화 연산**입니다.
>
> 모든 요소에 연산이 한 번에 적용돼요.
>
> ```python
> temps + 10        # 모든 온도에 10 더하기
> temps * 1.1       # 모든 온도에 1.1 곱하기
> temps > 90        # 각 온도가 90 초과인지 확인
> ```
>
> for문 없이 이런 계산이 가능합니다.
> 코드도 간결하고 속도도 빠르고요.

### 통계 함수 [1min]

> NumPy에는 통계 함수가 내장되어 있습니다.
>
> ```python
> temps.mean()      # 평균
> temps.std()       # 표준편차
> temps.max()       # 최대값
> temps.min()       # 최소값
> temps.sum()       # 합계
> ```
>
> 제조 현장에서 평균 온도, 최대 온도, 편차 등을 바로 계산할 수 있어요.
>
> 특히 조건 필터링이 강력합니다.
>
> ```python
> temps[temps > 90]  # 90도 초과인 값만 추출
> ```
>
> 경고 기준을 초과한 데이터만 뽑아내는 게 이렇게 간단해요.

---

## Pandas 소개 (3min)

### Pandas란? [1min]

> Pandas는 표 형태 데이터의 표준 도구입니다.
>
> 핵심 객체가 두 가지예요.
> - **DataFrame**: 2차원 표 (Excel 시트 같은 것)
> - **Series**: 1차원 데이터 (DataFrame의 한 열)
>
> 생산일지, 센서 로그, 품질 데이터...
> 이런 표 형태 데이터는 전부 DataFrame으로 다룹니다.

### DataFrame 생성 [1min]

> DataFrame은 딕셔너리로 쉽게 만들 수 있어요.
>
> ```python
> data = {
>     "제품코드": ["SM-001", "SM-002"],
>     "생산량": [1200, 1150],
>     "불량수": [24, 35]
> }
> df = pd.DataFrame(data)
> ```
>
> 열 이름이 키가 되고, 값들이 행으로 들어갑니다.
>
> CSV 파일에서 읽어오는 것도 간단해요.
>
> ```python
> df = pd.read_csv("production.csv")
> ```

### 데이터 탐색 [1min]

> 데이터를 불러오면 먼저 탐색을 해야 해요.
>
> ```python
> df.head()      # 처음 5행 보기
> df.shape       # 크기 확인 (행, 열)
> df.info()      # 데이터 타입, 결측치
> df.describe()  # 기본 통계
> ```
>
> 이 네 가지만 실행해도 데이터가 어떻게 생겼는지 파악됩니다.
>
> 특히 `describe()`는 수치형 열의 평균, 표준편차, 최솟값, 최댓값을
> 한 번에 보여줘서 아주 유용해요.

---

## 실습편 (15-20분)

### 실습 환경 확인 [1min]

> 이제 실습 시간입니다.
>
> Jupyter Notebook을 열고 새 노트북을 만드세요.
>
> 먼저 라이브러리를 임포트합니다.
>
> ```python
> import numpy as np
> import pandas as pd
> ```
>
> 에러 없이 실행되면 준비 완료입니다!

### 실습 1: NumPy 센서 데이터 분석 [4min]

> 첫 번째 실습입니다. 24시간 온도 데이터를 분석해봅시다.
>
> ```python
> temps = np.array([
>     82, 84, 85, 87, 88, 90, 92, 95,
>     93, 91, 89, 86, 85, 84, 83, 82,
>     81, 80, 79, 80, 81, 82, 83, 84
> ])
>
> print(f"평균 온도: {temps.mean():.1f}도")
> print(f"최고 온도: {temps.max()}도")
> print(f"최저 온도: {temps.min()}도")
> print(f"표준편차: {temps.std():.2f}")
> ```
>
> 평균이 85도 정도, 최고가 95도, 최저가 79도로 나옵니다.
>
> 이제 90도 초과 경고를 분석해봅시다.
>
> ```python
> warnings = temps[temps > 90]
> print(f"경고 횟수: {len(warnings)}회")
> print(f"경고 값: {warnings}")
> ```
>
> 90도를 초과한 시간대가 몇 번인지, 그 값이 뭔지 바로 알 수 있어요.

### 실습 2: DataFrame 생성 [3min]

> 두 번째 실습입니다. 일주일 생산 데이터를 만들어봅시다.
>
> ```python
> data = {
>     "날짜": pd.date_range("2024-12-09", periods=7),
>     "라인": [1, 2, 1, 2, 1, 2, 1],
>     "생산량": [1200, 1150, 1300, 1180, 1250, 1220, 1280],
>     "불량수": [24, 35, 26, 42, 25, 30, 22]
> }
>
> df = pd.DataFrame(data)
> print(df)
> ```
>
> 이렇게 표 형태의 데이터가 만들어집니다.
>
> `df.head()`, `df.info()`, `df.describe()`를 실행해서
> 데이터를 파악해보세요.

### 실습 3: 불량률 계산 [3min]

> 세 번째 실습입니다. 불량률을 계산해봅시다.
>
> ```python
> df["불량률"] = df["불량수"] / df["생산량"]
> df["불량률_%"] = (df["불량률"] * 100).round(2)
> print(df[["날짜", "생산량", "불량수", "불량률_%"]])
> ```
>
> 새 열을 추가하는 게 이렇게 간단해요.
> 계산식을 쓰면 모든 행에 자동 적용됩니다.
>
> 등급도 분류해봅시다.
>
> ```python
> df["등급"] = df["불량률"].apply(
>     lambda x: "A" if x <= 0.02 else ("B" if x <= 0.03 else "C")
> )
> ```
>
> 2% 이하면 A등급, 3% 이하면 B등급, 그 외 C등급입니다.

### 실습 4: 조건 필터링 [3min]

> 네 번째 실습입니다. 원하는 데이터만 뽑아봅시다.
>
> ```python
> # 불량률 3% 초과
> high_defect = df[df["불량률"] > 0.03]
> print(high_defect)
>
> # 1번 라인만
> line1 = df[df["라인"] == 1]
> print(line1)
>
> # A등급이면서 생산량 1200 이상
> excellent = df[(df["등급"] == "A") & (df["생산량"] >= 1200)]
> print(excellent)
> ```
>
> 주의할 점! 복합 조건에서는 **&** 와 **|** 를 쓰고,
> 각 조건을 **괄호**로 감싸야 합니다.

### 실습 5: 그룹별 집계 [3min]

> 다섯 번째 실습입니다. 라인별 통계를 내봅시다.
>
> ```python
> line_stats = df.groupby("라인").agg({
>     "생산량": ["count", "mean", "sum"],
>     "불량률": "mean"
> })
> print(line_stats)
> ```
>
> groupby를 쓰면 라인별로 묶어서 통계를 낼 수 있어요.
>
> 가장 성과가 좋은 라인도 찾아봅시다.
>
> ```python
> best = df.groupby("라인")["불량률"].mean().idxmin()
> print(f"최우수 라인: {best}번")
> ```
>
> idxmin()은 가장 작은 값의 인덱스(라인 번호)를 반환합니다.

### 실습 6: 종합 보고서 [3min]

> 마지막 종합 실습입니다. 품질 보고서를 만들어봅시다.
>
> ```python
> print("=" * 40)
> print("       주간 품질 리포트")
> print("=" * 40)
> print(f"총 생산량: {df['생산량'].sum():,}개")
> print(f"총 불량수: {df['불량수'].sum():,}개")
> print(f"평균 불량률: {df['불량률'].mean()*100:.2f}%")
> print("-" * 40)
> for line in df["라인"].unique():
>     rate = df[df["라인"]==line]["불량률"].mean()*100
>     print(f"  {line}번 라인: {rate:.2f}%")
> print("=" * 40)
> ```
>
> 지금까지 배운 걸 다 활용한 보고서입니다.
> 실무에서 이런 형태로 자동 리포트를 만들 수 있어요.

---

## 정리 (3분)

### 자주 하는 실수 [1min]

> 초보자가 자주 하는 실수를 정리합니다.
>
> **첫째**, 단일 열 vs 다중 열 선택
> `df["생산량"]`은 Series, `df[["생산량"]]`은 DataFrame입니다.
>
> **둘째**, 조건 연결에서 and/or 사용
> Python의 and, or 말고 **&**, **|** 를 써야 해요.
>
> **셋째**, 조건마다 괄호 필수
> `(조건1) & (조건2)` 형태로 각 조건을 괄호로 감싸세요.
>
> **넷째**, loc과 iloc 혼동
> loc은 끝 포함, iloc은 끝 미포함입니다.

### 핵심 요약 [1min]

> 오늘 배운 내용을 정리합니다.
>
> **NumPy**: 빠른 수치 계산
> - np.array()로 배열 생성
> - mean, max, min, std 통계 함수
> - arr[arr > 값]으로 조건 필터링
>
> **Pandas**: 표 데이터 처리
> - pd.DataFrame()으로 테이블 생성
> - head, info, describe로 탐색
> - groupby로 그룹별 집계

### 다음 차시 예고 [0.5min]

> 다음 4차시에서는 **공개 데이터셋 확보**를 배웁니다.
>
> 공공데이터포털, AI 허브, Kaggle 등
> 다양한 데이터 플랫폼을 알아보고,
> 실제 데이터를 다운로드해볼 거예요.
>
> 오늘 배운 Pandas로 그 데이터를 분석하게 됩니다!

### 마무리 [0.5min]

> 오늘 NumPy와 Pandas의 기초를 배웠습니다.
>
> 이 두 라이브러리는 앞으로 모든 차시에서 사용됩니다.
> 오늘 배운 코드를 꼭 복습해주세요.
>
> 수고하셨습니다!

---

## 강의 노트

### 준비물
- PPT 슬라이드 (slides.md)
- 실습 코드 파일 (code.py)
- Anaconda/Jupyter Notebook

### 실습 환경 체크리스트
- [ ] NumPy 설치 확인 (`import numpy`)
- [ ] Pandas 설치 확인 (`import pandas`)
- [ ] Jupyter Notebook 실행 확인

### 예상 질문 및 답변

**Q1: NumPy와 Pandas 차이가 뭔가요?**
> NumPy는 숫자 배열 전용, Pandas는 표 형태(열 이름 있는) 데이터 전용입니다. NumPy가 더 빠르고, Pandas가 더 편리해요. 실무에서는 둘 다 씁니다.

**Q2: DataFrame에서 열을 선택할 때 대괄호 하나와 두 개 차이는?**
> 대괄호 하나 `df["열"]`은 Series를 반환하고, 두 개 `df[["열"]]`은 DataFrame을 반환합니다. 여러 열을 선택하려면 두 개를 써야 해요.

**Q3: loc과 iloc 언제 쓰나요?**
> loc은 라벨(이름) 기반, iloc은 정수 위치 기반입니다. 보통 iloc을 더 많이 씁니다. 주의할 점은 loc은 끝을 포함하고 iloc은 안 포함해요.

**Q4: groupby 결과를 DataFrame으로 쓰고 싶어요**
> `.reset_index()`를 붙이면 됩니다. `df.groupby("라인")["생산량"].mean().reset_index()`

### 시간 조절 팁

**시간 부족 시**:
- 실습 6(종합 보고서) 간략히
- 결측치 처리 생략

**시간 여유 시**:
- CSV 파일 읽기/쓰기 추가 실습
- 정렬(sort_values) 추가 설명
