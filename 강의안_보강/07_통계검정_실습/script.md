# [7차시] 통계 검정 실습 - 강사 스크립트

## 강의 정보
- **차시**: 7차시 (42분)
- **유형**: 이론 + 실습
- **구성**: 이론 30분 + 실습 10분 + 정리 2분
- **대상**: 비전공자, AI 입문자, 제조업 종사자

---

## 시간 배분

| 구간 | 내용 | 시간 | 누적 |
|------|------|------|------|
| 도입 | 복습 및 학습목표 | 2분 | 2분 |
| Part 1 | 가설검정 기초 (p-value, 유의수준) | 10분 | 12분 |
| Part 2 | 모수 검정 (t-검정, ANOVA) | 10분 | 22분 |
| Part 3 | 범주형 검정 (카이제곱) | 5분 | 27분 |
| Part 4 | 비모수 검정 | 5분 | 32분 |
| 실습 | 종합 실습 | 8분 | 40분 |
| 정리 | 요약 및 Q&A | 2분 | 42분 |

---

## 도입 (2분)

### 인사 및 지난 시간 복습 [1분]

> 안녕하세요, 7차시를 시작하겠습니다.
>
> 지난 시간에 확률분포와 Z-score를 배웠습니다. 정규분포의 68-95-99.7 규칙으로 데이터가 정상 범위인지 판단하고, Z-score로 이상치를 탐지하는 방법을 익혔죠.
>
> 오늘은 한 단계 더 나아가서, **"두 그룹이 정말 다른가?"**, **"이 차이가 우연인가, 실제인가?"**를 통계적으로 검증하는 방법을 배웁니다.

### 학습목표 안내 [1분]

> 오늘 수업을 마치면 다음 네 가지를 할 수 있습니다.
>
> 첫째, 가설검정의 기본 개념과 p-value를 이해합니다.
> 둘째, t-검정과 ANOVA로 집단 간 평균을 비교합니다.
> 셋째, 카이제곱 검정으로 범주형 변수의 관계를 분석합니다.
> 넷째, 비모수 검정이 필요한 상황을 판단합니다.
>
> 이 네 가지가 제조 현장에서 데이터 기반 의사결정을 할 때 꼭 필요한 핵심 역량입니다.

---

## Part 1: 가설검정 기초 (10분)

### 왜 통계 검정이 필요한가? [1.5분]

> 먼저, 왜 통계 검정을 알아야 할까요?
>
> 제조 현장에서 이런 질문들 많이 하시죠?
>
> "A라인과 B라인 불량률이 정말 다른가?"
> "새 공정으로 품질이 실제로 좋아졌는가?"
> "교대 시간과 불량률은 관련이 있는가?"
> "교육 후 작업 효율이 정말 올랐는가?"
>
> 눈으로 보기엔 차이가 있어 보여도, 그게 **우연히 생긴 차이**인지, **실제로 의미 있는 차이**인지 알아야 합니다.
>
> 감으로 판단하면 틀릴 수 있어요. 통계 검정은 **데이터로 근거를 만드는 방법**입니다.

### 가설검정이란? [1.5분]

> 가설검정은 **데이터를 바탕으로 주장을 검증하는 절차**입니다.
>
> 예를 들어볼게요.
>
> 누군가 "이 공정 개선으로 불량률이 줄었다"고 주장합니다.
> 정말 그런가요? 우연히 그렇게 보이는 건 아닌가요?
>
> 가설검정은 이 질문에 답하기 위해 네 단계를 거칩니다.
>
> 첫째, 가설 설정 - 주장을 수학적으로 표현합니다.
> 둘째, 데이터 수집 - 실제 측정값을 모읍니다.
> 셋째, 검정 통계량 계산 - 수식으로 차이를 정량화합니다.
> 넷째, p-value로 판단 - 이 차이가 우연인지 아닌지 결론 내립니다.

### 귀무가설과 대립가설 [2분]

> 가설검정에서 가장 중요한 개념이 **귀무가설**과 **대립가설**입니다.
>
> 귀무가설, 영어로 Null Hypothesis, 기호로 H0라고 씁니다.
> 뜻은 **"아무 일도 일어나지 않았다"**, **"차이가 없다"**입니다.
>
> 예를 들어:
> - 두 공정의 불량률은 **같다**
> - 교육 전후 생산성은 **차이 없다**
> - A라인과 B라인 품질은 **동일하다**
>
> 대립가설, H1 또는 Ha라고 씁니다.
> 뜻은 **"실제로 차이가 있다"**, **"효과가 있다"**입니다.
> 연구자가 입증하고 싶은 가설이에요.
>
> 예를 들어:
> - 두 공정의 불량률은 **다르다**
> - 교육 후 생산성이 **높아졌다**
> - A라인과 B라인 품질은 **다르다**
>
> 가설검정의 핵심 논리는 **귀무가설을 기각하는 것**입니다.
> "차이가 없다"는 가정 하에 데이터를 분석해서, 이 가정이 맞지 않으면 기각합니다.

### p-value란? [2.5분]

> 자, 이제 가장 중요한 개념입니다. **p-value**.
>
> p-value의 정의는 이렇습니다.
> **"귀무가설이 참일 때, 현재 관측된 결과 또는 더 극단적인 결과가 나올 확률"**
>
> 어렵게 들리죠? 쉽게 설명할게요.
>
> 귀무가설은 "차이가 없다"잖아요.
> 그런데 실제 데이터를 보니까 차이가 보입니다.
>
> p-value가 뭐냐면, "정말 차이가 없는데, 우연히 이 정도 차이가 나올 확률"입니다.
>
> p-value가 작으면? 우연히 이런 결과가 나올 확률이 매우 낮다는 뜻이에요.
> 그러니까 "차이가 없다"는 가정이 틀렸을 가능성이 높죠.
> 그래서 귀무가설을 기각합니다.
>
> p-value가 크면? 우연히도 충분히 나올 수 있는 결과입니다.
> 그러니까 "차이가 없다"는 가정을 굳이 기각할 이유가 없어요.
>
> 예를 들어 p = 0.02라면?
> "귀무가설이 참일 때, 이런 결과가 나올 확률이 2%"라는 뜻입니다.
> 2%면 너무 희귀하죠? 그래서 귀무가설을 기각합니다.

### p-value 해석 주의사항 [1분]

> p-value 해석할 때 자주 하는 실수가 있어요.
>
> 첫째, "p-value가 H0가 참일 확률"이라고 해석하는 것. 틀린 해석입니다.
> p-value는 "H0가 참일 때 이 결과가 나올 확률"이에요. 순서가 다릅니다.
>
> 둘째, p-value가 작으면 효과가 크다고 생각하는 것. 이것도 틀립니다.
> p-value는 통계적 유의성만 말해줍니다. 효과 크기는 별도로 확인해야 해요.
>
> p-value는 **증거의 강도**를 나타냅니다.
> 실제 **효과가 얼마나 큰지**는 따로 봐야 합니다.

### 유의수준 (Alpha) [1.5분]

> 그럼 p-value가 얼마나 작아야 귀무가설을 기각할까요?
> 그 기준이 **유의수준**, 영어로 Alpha(알파), 기호로 alpha입니다.
>
> 표준적으로 쓰는 기준이 세 가지 있어요.
>
> alpha = 0.05, 5%. 가장 보편적인 기준입니다. 일반적인 연구에서 사용합니다.
> alpha = 0.01, 1%. 더 엄격한 기준이 필요할 때 씁니다.
> alpha = 0.10, 10%. 탐색적 분석에서 쓰기도 합니다.
>
> 판단 규칙은 간단합니다.
>
> p < alpha면 귀무가설 기각. **"통계적으로 유의하다"**고 말합니다.
> p >= alpha면 귀무가설 기각 못함. **"통계적으로 유의하지 않다"**고 말합니다.
>
> 왜 0.05인지 궁금하시죠?
> 통계학자 로널드 피셔가 제안한 건데, "20번 중 1번 정도는 우연으로 발생 가능하다"는 의미에요.
> 이 정도 위험은 감수할 수 있다는 관례적 합의입니다.
>
> 주의할 점은, 0.05가 절대적 기준은 아니라는 거예요.
> 상황에 따라 0.01이나 0.10을 쓸 수도 있습니다.

---

## Part 2: 모수 검정 - t-검정, ANOVA (10분)

### 모수 검정이란? [1분]

> 이제 구체적인 검정 방법을 배워봅시다.
>
> 먼저 **모수 검정**입니다.
> 모수 검정은 **데이터가 정규분포를 따른다고 가정**하는 검정 방법입니다.
>
> 대표적인 검정이 세 가지 있어요.
>
> 독립표본 t-검정: 서로 다른 두 그룹의 평균 비교
> 대응표본 t-검정: 같은 대상의 전후 평균 비교
> 일원분산분석(ANOVA): 세 개 이상 그룹의 평균 비교
>
> 제조업에서 가장 많이 쓰는 검정들입니다.

### 독립표본 t-검정 [2.5분]

> 첫 번째, **독립표본 t-검정**입니다.
>
> 언제 쓰냐면, **서로 다른 두 그룹**의 평균을 비교할 때 씁니다.
> 핵심은 "독립"이에요. 두 그룹이 서로 관련 없는 다른 대상이어야 합니다.
>
> 제조업 예시를 들어볼게요.
> - A라인 vs B라인 품질
> - 신규 설비 vs 기존 설비 생산량
> - 공급사A vs 공급사B 원료 품질
>
> 이런 경우에 독립표본 t-검정을 씁니다.
>
> 오늘 실습에서는 **Iris 데이터셋**을 사용합니다.
> Iris는 붓꽃 150송이의 꽃잎, 꽃받침 크기를 측정한 유명한 데이터예요.
> 세 가지 품종이 있는데, 품종별로 꽃잎 길이가 다른지 t-검정으로 확인해봅시다.
>
> 코드는 간단합니다.
>
> ```python
> from scipy import stats
> t_stat, p_value = stats.ttest_ind(setosa, versicolor)
> ```
>
> `ttest_ind`의 ind가 independent, 독립이라는 뜻이에요.
> 결과로 t-통계량과 p-value가 나옵니다.
>
> 실제 결과를 보면 p-value가 1.08e-31, 거의 0에 가깝습니다.
> 이건 "우연히 이런 차이가 날 확률이 거의 0"이라는 뜻이에요.
> 그래서 귀무가설을 기각하고, "두 품종의 꽃잎 길이는 통계적으로 유의하게 다르다"고 결론 내립니다.

### 대응표본 t-검정 [1.5분]

> 두 번째, **대응표본 t-검정**입니다.
>
> 언제 쓰냐면, **같은 대상**을 두 번 측정해서 비교할 때 씁니다.
> 핵심은 "대응", 즉 "쌍"이에요. 데이터가 1:1로 연결되어 있어야 합니다.
>
> 제조업 예시:
> - 같은 작업자의 교육 전후 생산성
> - 같은 설비의 개선 전후 불량률
> - 같은 라인의 여름/겨울 품질
>
> 코드는 비슷한데 함수만 다릅니다.
>
> ```python
> t_stat, p_value = stats.ttest_rel(before, after)
> ```
>
> `ttest_rel`의 rel이 related, 관련된이라는 뜻이에요.
>
> 독립표본과 대응표본을 헷갈리는 분들이 많은데, 구분법은 간단해요.
>
> **"같은 대상을 두 번 측정했는가?"**
> YES면 대응표본 t-검정 (`ttest_rel`)
> NO면 독립표본 t-검정 (`ttest_ind`)

### ANOVA (일원분산분석) [2.5분]

> 세 번째, **ANOVA**, 일원분산분석입니다.
>
> 언제 쓰냐면, 비교할 그룹이 **3개 이상**일 때 씁니다.
>
> "그냥 t-검정을 여러 번 하면 안 되나요?" 라고 물으실 수 있어요.
> 안 됩니다. t-검정을 여러 번 하면 1종 오류가 증가해요.
> 예를 들어 3그룹을 비교하면 t-검정을 3번 해야 하는데, 그러면 잘못 기각할 확률이 늘어납니다.
> ANOVA는 한 번에 비교해서 이 문제를 해결합니다.
>
> 가설은 이렇습니다.
> H0: 모든 그룹의 평균이 같다 (mu1 = mu2 = mu3 = ...)
> H1: 적어도 하나의 그룹 평균이 다르다
>
> 제조업 예시:
> - 3개 라인의 품질 비교
> - 4개 교대조의 생산성 비교
> - 5개 공급사 원료의 품질 비교
>
> 오늘 실습에서는 **Wine Quality 데이터셋**을 사용합니다.
> UCI에서 제공하는 와인 품질 데이터인데, 품질 등급별로 알코올 함량이 다른지 확인해봅시다.
>
> 코드입니다.
>
> ```python
> f_stat, p_value = stats.f_oneway(q3, q4, q5, q6, q7, q8)
> ```
>
> `f_oneway`가 일원분산분석 함수예요.
> 결과로 F-통계량과 p-value가 나옵니다.
>
> 주의할 점이 있어요.
> ANOVA는 "차이가 있다/없다"만 알려줍니다.
> **어느 그룹 간에** 차이가 있는지는 **사후분석**이 필요해요.
> Tukey HSD 같은 방법으로 추가 분석해야 합니다.

### 모수 검정 정리 [0.5분]

> 모수 검정을 정리하면:
>
> 두 독립 그룹 비교: `ttest_ind()`
> 전후 비교: `ttest_rel()`
> 3개 이상 그룹: `f_oneway()`
>
> 모두 `from scipy import stats` 후에 `stats.함수명()`으로 사용합니다.

### 실습 데모: t-검정 [2분]

> 잠깐 실습을 보여드릴게요.
>
> Iris 데이터에서 setosa와 versicolor의 꽃잎 길이를 비교합니다.
>
> 먼저 데이터를 확인하면, setosa 평균이 1.46cm, versicolor가 4.26cm입니다.
> 눈으로 봐도 차이가 크죠?
>
> t-검정을 실행하면 p-value가 1.08e-31입니다.
> 이건 0.00000000000000000000000000000001 정도의 확률이에요.
> 거의 0입니다.
>
> 결론: "두 품종의 꽃잎 길이는 통계적으로 매우 유의한 차이가 있다."
>
> 시각화를 보면 두 분포가 완전히 분리되어 있어요.
> 겹치는 부분이 거의 없으니까 당연히 p-value가 극도로 작겠죠.

---

## Part 3: 범주형 검정 - 카이제곱 (5분)

### 카이제곱 검정이란? [1.5분]

> 이제 **범주형 데이터** 검정을 배워봅시다.
>
> 앞에서 배운 t-검정, ANOVA는 **연속형 변수**의 평균을 비교했어요.
> 하지만 데이터가 범주형이면 어떻게 할까요?
>
> 예를 들어:
> - 성별(남/여)과 생존 여부(생존/사망)의 관계
> - 교대조(주간/야간)와 불량 발생(발생/미발생)의 관계
> - 경력(신입/경력)과 사고 발생의 관계
>
> 이런 **범주형 변수 간의 관계**를 분석할 때 **카이제곱 검정**을 씁니다.
>
> 카이제곱 검정의 가설은:
> H0: 두 변수는 독립이다 (관련 없다)
> H1: 두 변수는 독립이 아니다 (관련 있다)

### Titanic 데이터로 실습 [2분]

> 오늘 실습에서는 **Titanic 데이터셋**을 사용합니다.
> 타이타닉호 생존자 데이터인데, 성별과 생존 여부의 관계를 분석해봅시다.
>
> 먼저 **교차표**를 만듭니다.
>
> ```python
> crosstab = pd.crosstab(titanic['sex'], titanic['survived'])
> ```
>
> 결과를 보면:
> 여성: 81명 사망, 233명 생존 → 생존율 74%
> 남성: 468명 사망, 109명 생존 → 생존율 19%
>
> 눈으로 보면 성별에 따라 생존율이 크게 다르죠?
> 여성이 훨씬 많이 살아남았어요.
>
> 이 차이가 통계적으로 유의한지 카이제곱 검정으로 확인합니다.
>
> ```python
> chi2, p_value, dof, expected = stats.chi2_contingency(crosstab)
> ```
>
> 결과: chi2 = 260.72, p ≈ 1.2e-58
>
> p-value가 거의 0입니다.
> 결론: "성별과 생존 여부는 통계적으로 매우 유의한 관계가 있다."

### 카이제곱 검정 해석 [1.5분]

> 카이제곱 검정을 해석할 때 **기대 빈도**라는 개념을 알아야 해요.
>
> 기대 빈도는 "두 변수가 독립이라면 예상되는 빈도"입니다.
>
> 만약 성별과 생존이 정말 관련 없다면?
> 남녀 모두 비슷한 비율로 생존했을 거예요.
>
> 그런데 실제 관측 빈도를 보면 기대 빈도와 많이 다릅니다.
> 여성은 기대보다 훨씬 많이 생존했고, 남성은 훨씬 적게 생존했어요.
>
> 카이제곱 통계량은 이 차이를 수치화한 겁니다.
> 차이가 클수록 카이제곱 값이 커지고, p-value가 작아집니다.
>
> 제조업에서 활용 예시:
> - 교대조별 불량 발생 여부가 다른가?
> - 라인별 불량 유형 분포가 다른가?
> - 원료 공급사와 불량 유형이 관련 있는가?

---

## Part 4: 비모수 검정 (5분)

### 비모수 검정이 필요한 경우 [1.5분]

> 마지막으로 **비모수 검정**을 배워봅시다.
>
> 비모수 검정은 **정규분포를 가정하지 않는** 검정입니다.
>
> 언제 써야 할까요?
>
> 첫째, 데이터가 **정규분포를 따르지 않을 때**
> 둘째, **표본 크기가 작을 때** (n < 30)
> 셋째, **순서형 데이터**일 때 (1등, 2등, 3등 같은 순위)
> 넷째, **이상치가 많을 때**
>
> 비모수 검정의 장점은 분포 가정이 필요 없고, 이상치에 강건하다는 거예요.
> 단점은 모수 검정보다 검정력이 낮습니다. 같은 데이터로도 유의한 결과를 못 찾을 수 있어요.
>
> 정규성 검정은 **Shapiro-Wilk 검정**으로 합니다.
>
> ```python
> stat, p_value = stats.shapiro(data)
> ```
>
> p < 0.05면 정규분포를 따르지 않는다고 판단합니다.

### 비모수 검정 종류 [2분]

> 비모수 검정과 모수 검정은 1:1로 대응됩니다.
>
> | 모수 검정 | 비모수 검정 |
> |----------|------------|
> | 독립표본 t-검정 | Mann-Whitney U |
> | 대응표본 t-검정 | Wilcoxon 부호순위 |
> | ANOVA | Kruskal-Wallis |
>
> **Mann-Whitney U 검정**은 두 독립 그룹의 **순위**를 비교합니다.
>
> ```python
> u_stat, p_value = stats.mannwhitneyu(group1, group2)
> ```
>
> **Wilcoxon 검정**은 전후 차이의 **부호와 순위**를 기반으로 합니다.
>
> ```python
> stat, p_value = stats.wilcoxon(before, after)
> ```
>
> **Kruskal-Wallis 검정**은 3개 이상 그룹의 순위 분포를 비교합니다.
>
> ```python
> h_stat, p_value = stats.kruskal(g1, g2, g3)
> ```

### 검정 선택 기준 [1.5분]

> 그럼 언제 모수 검정을 쓰고, 언제 비모수 검정을 쓸까요?
>
> 선택 기준은 간단합니다.
>
> **1단계: 변수 유형 확인**
> - 연속형 변수 → 평균 비교 (t-검정, ANOVA, 비모수)
> - 범주형 변수 → 카이제곱 검정
>
> **2단계: 그룹 수 확인**
> - 2개 그룹 → t-검정 또는 Mann-Whitney
> - 3개 이상 → ANOVA 또는 Kruskal-Wallis
>
> **3단계: 정규성 검정**
> - 정규분포 따름 → 모수 검정
> - 정규분포 안 따름 → 비모수 검정
>
> 실무 팁을 드리자면, 표본이 30개 이상이면 중심극한정리에 의해 모수 검정을 써도 대부분 괜찮습니다.
> 표본이 작거나, 데이터가 심하게 비대칭이면 비모수 검정을 쓰세요.

---

## 실습편 (8분)

### 실습 환경 설정 [1분]

> 이제 실습 시간입니다.
>
> 오늘 배운 검정 방법들을 직접 실행해봅시다.
>
> 먼저 환경을 설정합니다.
>
> ```python
> import numpy as np
> import pandas as pd
> from scipy import stats
> from scipy.stats import ttest_ind, ttest_rel, f_oneway
> from scipy.stats import chi2_contingency, mannwhitneyu, shapiro
> import seaborn as sns
> from sklearn.datasets import load_iris
> import matplotlib.pyplot as plt
> ```
>
> scipy가 설치 안 됐으면 `pip install scipy`로 설치하세요.
> seaborn도 필요합니다. `pip install seaborn`

### 실습 1: Iris t-검정 [2분]

> 첫 번째 실습입니다.
>
> Iris 데이터에서 versicolor와 virginica의 꽃잎 너비를 비교합니다.
>
> 먼저 데이터를 로드하고 분리합니다.
>
> ```python
> iris = load_iris()
> df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)
> df_iris['species'] = iris.target_names[iris.target]
>
> versicolor = df_iris[df_iris['species'] == 'versicolor']['petal width (cm)']
> virginica = df_iris[df_iris['species'] == 'virginica']['petal width (cm)']
> ```
>
> 기술통계를 확인하고, 정규성 검정을 한 후, t-검정을 실행합니다.
>
> 결과를 보고 p-value가 0.05보다 작은지 확인하세요.
> 결론을 문장으로 작성해보세요.

### 실습 2: Wine Quality ANOVA [2분]

> 두 번째 실습입니다.
>
> Wine Quality 데이터에서 품질 그룹별 산도(volatile acidity)를 비교합니다.
>
> 품질을 Low(3-4), Medium(5-6), High(7-8)로 나눕니다.
>
> ```python
> wine['quality_group'] = pd.cut(wine['quality'],
>                                 bins=[2, 4, 6, 8],
>                                 labels=['Low', 'Medium', 'High'])
> ```
>
> 그룹별로 데이터를 분리하고 `f_oneway()`로 ANOVA를 실행합니다.
>
> p-value를 확인하고, 유의하다면 "품질에 따라 산도에 차이가 있다"고 결론 내립니다.
>
> 참고로, 저품질 와인일수록 휘발성 산도가 높은 경향이 있어요.
> 와인 품질 판정의 중요한 요소입니다.

### 실습 3: Titanic 카이제곱 검정 [2분]

> 세 번째 실습입니다.
>
> Titanic 데이터에서 객실 등급(class)과 생존의 관계를 분석합니다.
>
> ```python
> titanic = sns.load_dataset('titanic')
> crosstab = pd.crosstab(titanic['class'], titanic['survived'])
> chi2, p_value, dof, expected = chi2_contingency(crosstab)
> ```
>
> 교차표를 먼저 확인하세요.
> 1등석, 2등석, 3등석의 생존율이 어떻게 다른지 보입니다.
>
> 카이제곱 검정 결과 p-value가 0.05보다 작으면,
> "객실 등급과 생존 여부는 통계적으로 유의한 관계가 있다"고 결론 내립니다.
>
> 1등석 승객의 생존율이 가장 높았어요.
> 역사적으로도 "여자와 어린이 먼저" 원칙이 적용되었고, 1등석이 구명보트에 가까웠습니다.

### 실습 4: 비모수 검정 비교 [1분]

> 네 번째 실습입니다.
>
> 비정규 분포 데이터를 만들어서 모수 검정과 비모수 검정 결과를 비교합니다.
>
> ```python
> group_a = np.random.exponential(scale=10, size=30)  # 지수분포
> group_b = np.random.exponential(scale=15, size=30)
> ```
>
> 지수분포는 정규분포가 아니에요.
> Shapiro-Wilk 검정으로 확인해보세요.
>
> t-검정과 Mann-Whitney U 검정을 둘 다 실행하고 결과를 비교합니다.
> 정규성이 위반된 경우 비모수 검정 결과를 더 신뢰해야 합니다.

---

## 정리 및 마무리 (2분)

### 핵심 요약 [1분]

> 오늘 배운 내용을 정리하겠습니다.
>
> **Part 1: 가설검정 기초**
> - 귀무가설(H0): "차이 없다"
> - 대립가설(H1): "차이 있다"
> - p < 0.05 → 통계적으로 유의함
>
> **Part 2: 모수 검정**
> - 두 그룹 비교: t-검정 (`ttest_ind`, `ttest_rel`)
> - 3개 이상 그룹: ANOVA (`f_oneway`)
>
> **Part 3: 카이제곱 검정**
> - 범주형 변수 간 관계: `chi2_contingency`
>
> **Part 4: 비모수 검정**
> - 정규성 위반 시: `mannwhitneyu`, `wilcoxon`, `kruskal`

### 다음 차시 예고 및 마무리 [1분]

> 다음 8차시에서는 **상관분석과 예측의 기초**를 배웁니다.
>
> 상관계수로 두 변수의 관계를 수치화하고,
> 선형회귀로 예측 모델을 만들어봅니다.
>
> 오늘 배운 "차이가 있는가?"에서 다음 주는 "관계가 있는가?", "예측할 수 있는가?"로 나아갑니다.
>
> 오늘 배운 검정 방법들, 특히 p-value 해석은 앞으로 계속 쓰니까 꼭 복습해주세요.
>
> 수고하셨습니다. 다음 시간에 뵙겠습니다!

---

## 예상 질문 및 답변

### Q1: p-value가 0.051이면 유의하지 않은 건가요? 0.049랑 큰 차이가 없는데...

> 좋은 질문입니다.
>
> 원칙적으로 0.05를 기준으로 하면 0.051은 "유의하지 않음"입니다.
> 하지만 현실에서 0.049와 0.051은 거의 차이가 없죠.
>
> 그래서 최근에는 "유의하다/유의하지 않다"의 이분법보다
> p-value 자체를 보고하고 맥락에서 해석하는 방향으로 가고 있어요.
>
> 또한, 효과 크기(effect size)도 함께 봐야 합니다.
> p-value가 0.05 근처이고 효과 크기도 작다면, 실무적으로 중요하지 않을 수 있어요.
> p-value가 0.06이어도 효과 크기가 크다면 주목할 가치가 있습니다.
>
> 0.05는 관례적 기준일 뿐, 절대적 경계선이 아닙니다.

### Q2: t-검정과 ANOVA 결과가 다르게 나올 수 있나요?

> 두 그룹만 비교하면 t-검정과 ANOVA 결과는 동일합니다.
>
> 정확히 말하면, t^2 = F입니다.
> t-통계량을 제곱하면 F-통계량이 나와요.
> p-value도 같습니다.
>
> 그래서 두 그룹만 비교할 때는 t-검정을 쓰는 게 일반적입니다.
> 세 그룹 이상일 때만 ANOVA를 씁니다.

### Q3: 카이제곱 검정에서 기대 빈도가 5 미만이면 어떻게 하나요?

> 카이제곱 검정의 중요한 전제 조건이 있어요.
> 모든 셀의 기대 빈도가 5 이상이어야 합니다.
>
> 기대 빈도가 5 미만인 셀이 있으면:
> 1. **피셔의 정확 검정(Fisher's exact test)** 사용
> 2. 범주를 합쳐서 기대 빈도를 높임
>
> scipy에서 피셔 검정은 `stats.fisher_exact(crosstab)` 입니다.
> 2x2 표에서만 사용 가능해요.

### Q4: 모수 검정과 비모수 검정 결과가 다르면 뭘 믿어야 하나요?

> 정규성 검정 결과에 따라 판단합니다.
>
> 정규성이 위반되었다면 → **비모수 검정** 결과를 채택
> 정규성이 만족된다면 → **모수 검정** 결과를 채택
>
> 두 결과가 비슷하다면 어느 쪽을 보고해도 괜찮습니다.
> 결론이 같으니까요.
>
> 두 결과가 다르다면 더 보수적인 결론을 택하거나,
> 데이터 특성을 고려해서 적합한 방법을 선택합니다.

### Q5: 표본 크기가 크면 뭐든 유의하게 나오지 않나요?

> 맞습니다. 매우 중요한 포인트예요.
>
> 표본 크기가 매우 크면 아주 작은 차이도 통계적으로 유의하게 나옵니다.
> 예를 들어 n=10,000이면 평균 차이 0.01도 p < 0.05가 될 수 있어요.
>
> 그래서 **통계적 유의성**과 **실제적 유의성**을 구분해야 합니다.
>
> 통계적으로 유의해도, 효과 크기가 너무 작으면 실무적으로 의미 없을 수 있어요.
> 반대로, 표본이 작아서 유의하지 않아도 효과 크기가 크면 주목해야 합니다.
>
> 항상 **효과 크기(Cohen's d, 평균 차이 등)**를 함께 보고해야 합니다.

### Q6: 사후분석(Post-hoc)은 뭔가요?

> ANOVA에서 "차이가 있다"고 나왔을 때,
> **어느 그룹 간에** 차이가 있는지 알아보는 추가 분석입니다.
>
> ANOVA는 "적어도 하나의 그룹이 다르다"만 알려줘요.
> A-B가 다른지, B-C가 다른지, A-C가 다른지는 모릅니다.
>
> 대표적인 사후분석 방법:
> - Tukey HSD: 가장 많이 쓰임
> - Bonferroni: 보수적인 방법
> - Scheffé: 더 보수적
>
> scipy에서는 `stats.tukey_hsd(g1, g2, g3)`를 쓸 수 있습니다.

---

## 참고 자료

### 데이터셋
- [Iris Dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset) - sklearn 내장
- [Titanic Dataset](https://github.com/mwaskom/seaborn-data) - seaborn 내장
- [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) - UCI Repository

### 학습 자료
- [scipy.stats 공식 문서](https://docs.scipy.org/doc/scipy/reference/stats.html)
- [통계적 가설검정 개요](https://ko.wikipedia.org/wiki/가설검정)
- [Khan Academy: 가설 검정](https://ko.khanacademy.org/math/statistics-probability)

### 추천 도서
- "통계학 입문" - 제조 데이터 분석을 위한 기초 통계
- "파이썬으로 배우는 통계학" - Python 실습 중심

---

## 체크리스트

### 수업 전
- [ ] 슬라이드(slides.md) 확인
- [ ] 실습 코드(code.py) 테스트 실행
- [ ] scipy, seaborn, sklearn 설치 확인
- [ ] Wine Quality 데이터셋 다운로드 확인 (인터넷 연결 필요)
- [ ] 학생들 환경 설정 안내 준비

### 수업 중
- [ ] p-value 개념을 다양한 예시로 설명
- [ ] 귀무가설/대립가설 구분 강조
- [ ] 각 검정 방법의 적용 상황 명확히 구분
- [ ] 실습 시 코드 실행 결과 확인
- [ ] 학생들이 결론을 문장으로 작성하게 유도

### 수업 후
- [ ] 학생 질문 정리
- [ ] 실습 코드 최종 버전 공유
- [ ] 다음 차시(상관분석) 연결점 확인
- [ ] 추가 학습 자료 안내

---

## 강의 노트

### 시간 관리 팁
- Part 1(가설검정 기초)은 개념이 어려우니 충분히 시간 투자
- p-value 설명에서 학생들이 이해했는지 확인 질문 하기
- 실습 시간이 부족하면 실습 4(비모수 검정)는 생략 가능
- Wine Quality 데이터는 인터넷에서 로드하므로 연결 상태 확인

### 학생 수준별 대응
- **기초 학생**: p-value가 0.05보다 작으면 "차이 있음"으로 단순화
- **중급 학생**: 효과 크기, 검정력 개념 추가 설명
- **고급 학생**: 베이지안 접근법, 다중검정 보정 등 심화 주제 소개

### 자주 발생하는 문제
- Wine Quality URL 접속 불가 시: 로컬 CSV 파일 준비
- seaborn 버전에 따라 titanic 데이터 컬럼명 다를 수 있음
- ttest_ind에서 equal_var 옵션 설명 (등분산 가정)
